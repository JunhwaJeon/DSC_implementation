{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "import scipy.linalg as sci\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Learning parameters\n",
    "initial_run = 1 #1: starts training from scratch; 0: resumes training \n",
    "n_epochs = 5000 #Number of training epochs, for observing the current performance set it to 0\n",
    "learning_rate = 0.0005 #Learning rate\n",
    "\n",
    "batch_size = 1024 #Mini-batch size\n",
    "test_size = 10000 #Size of the validation/test set\n",
    "batch_per_epoch = 20 #Numbers of mini-batches per epoch\n",
    "\n",
    "anneal_param = 1.0 #Initial annealing parmeter\n",
    "annealing_rate = 1.001 #Annealing rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [],
   "source": [
    "## System parameters\n",
    "M = 64 #Number of BS antennas\n",
    "P = 1 #Power\n",
    "K =  2 #Number of users\n",
    "L = 8 #Number of pilots\n",
    "Lp = 2 #Number of paths\n",
    "B = 30 #Number of feedback bits per user\n",
    "\n",
    "## Limited scattering channel parameters\n",
    "LSF_UE = np.array([0.0,0.0],dtype=np.float32) #Mean of path gains for K users\n",
    "Mainlobe_UE= np.array([0,0],dtype=np.float32) #Center of the AoD range for K users\n",
    "HalfBW_UE = np.array([30.0,30.0],dtype=np.float32) #Half of the AoD range for K users\n",
    "\n",
    "# SNR\n",
    "snr_dl = 10 #SNR in dB\n",
    "noise_std_dl = np.float32(np.sqrt(1/2)*np.sqrt(P/10**(snr_dl/10))) #STD of the Gaussian noise (per real dim.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pilot Sequence 초기화 -- DFT Matrix 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [],
   "source": [
    "DFT_Matrix = sci.dft(M) \n",
    "X_init = DFT_Matrix[0::int(np.ceil(M/L)),:] \n",
    "Xp_init = np.sqrt(P/M)*X_init\n",
    "Xp_r_init = torch.Tensor(np.float32(np.real(Xp_init))).to(device)\n",
    "Xp_i_init = torch.Tensor(np.float32(np.imag(Xp_init))).to(device)\n",
    "## Pilot sequence cuda 지정 완료"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix 연산 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mult_mod(M, N, left_right):\n",
    "    tensor_shape = M.shape\n",
    "    dims = N.shape \n",
    "\n",
    "    if left_right == 'r':\n",
    "        # M: (batch_size, n, m) N: (m, p)\n",
    "        n = tensor_shape[1]\n",
    "        m = dims[0]\n",
    "        p = dims[1]\n",
    "\n",
    "        # PyTorch의 행렬 곱\n",
    "        y = torch.reshape(torch.matmul(M.view(-1, m), N), (-1, n, p))\n",
    "\n",
    "    elif left_right == 'l':\n",
    "        # M: (batch_size, n, m)\n",
    "        # N: (p, n)\n",
    "        m = tensor_shape[2]\n",
    "        p = dims[0]\n",
    "        n = dims[1]\n",
    "\n",
    "        # PyTorch에서는 `permute()`로 전치 가능\n",
    "        MT = torch.Tensor(M).permute(0, 2, 1)  # (batch_size, m, n)\n",
    "        NT = N.T  # (n, p)\n",
    "\n",
    "        MTNT = torch.reshape(torch.matmul(MT.view(-1, n), NT), (-1, m, p))\n",
    "        y = MTNT.permute(0, 2, 1)  # (batch_size, n, p)로 변환\n",
    "\n",
    "    return y.to(device)\n",
    "\n",
    "def mult_mod_complex(Mr, Mi, Nr, Ni, left_right):\n",
    "    yr = mult_mod(Mr, Nr, left_right) - mult_mod(Mi, Ni, left_right)\n",
    "    yi = mult_mod(Mr, Ni, left_right) + mult_mod(Mi, Nr, left_right)\n",
    "    return yr.to(device), yi.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch data 생성 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 리스트 인덱싱은 [층, 행, 열], [행, 열]임!\n",
    "def generate_batch_data(batch_size,M,K,\n",
    "                        Lp,#number of paths\n",
    "                        LSF_UE #Mean of path gains for K users\n",
    "                        ,Mainlobe_UE #Center of the AoD range for K users\n",
    "                        ,HalfBW_UE #Half of the AoD range for K users\n",
    "                        ):\n",
    "    alphaR_input = np.zeros((batch_size,Lp,K))\n",
    "    alphaI_input = np.zeros((batch_size,Lp,K))\n",
    "    theta_input = np.zeros((batch_size,Lp,K))\n",
    "    for kk in range(K): # for the number of users\n",
    "        alphaR_input[:,:,kk] = np.random.normal(loc=LSF_UE[kk], scale=1.0/np.sqrt(2), size=[batch_size,Lp])\n",
    "        alphaI_input[:,:,kk] = np.random.normal(loc=LSF_UE[kk], scale=1.0/np.sqrt(2), size=[batch_size,Lp])\n",
    "        theta_input[:,:,kk] = np.random.uniform(low=Mainlobe_UE[kk]-HalfBW_UE[kk], high=Mainlobe_UE[kk]+HalfBW_UE[kk], size=[batch_size,Lp])\n",
    " \n",
    "    #### Actual Channel\n",
    "    from0toM = np.float32(np.arange(0, M, 1))\n",
    "    alpha_act = alphaR_input + 1j*alphaI_input\n",
    "    theta_act = (np.pi/180)*theta_input\n",
    "    \n",
    "    h_act = np.complex64(np.zeros((batch_size,M,K)))\n",
    "    hR_act = np.float32(np.zeros((batch_size,M,K)))\n",
    "    hI_act = np.float32(np.zeros((batch_size,M,K)))\n",
    "    \n",
    "    for kk in range(K):\n",
    "        for ll in range(Lp):\n",
    "            theta_act_expanded_temp = np.tile(np.reshape(theta_act[:,ll,kk],[-1,1]),(1,M))\n",
    "            response_temp = np.exp(1j*np.pi*np.multiply(np.sin(theta_act_expanded_temp),from0toM))\n",
    "            alpha_temp = np.reshape(alpha_act[:,ll,kk],[-1,1])\n",
    "            h_act[:,:,kk] += (1/np.sqrt(Lp))*alpha_temp*response_temp\n",
    "        hR_act[:,:,kk] = np.real(h_act[:,:,kk])\n",
    "        hI_act[:,:,kk] = np.imag(h_act[:,:,kk])\n",
    "        \n",
    "    h_act = torch.tensor(h_act).to(device)\n",
    "    hR_act = torch.tensor(hR_act).to(device)\n",
    "    hI_act = torch.tensor(hI_act).to(device)\n",
    "        \n",
    "    return(h_act, hR_act, hI_act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력 데이터 텐서\n",
    "hR = torch.randn((batch_size, M, K), dtype=torch.float32)  # 실수 채널 행렬\n",
    "hI = torch.randn((batch_size, M, K), dtype=torch.float32)  # 허수 채널 행렬"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downlink Pilot Training -- Pilot Sequence as DNN parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [],
   "source": [
    "## hR, hI 만 cuda로 들어가면 됨됨\n",
    "class DLTrainingPhase(nn.Module):\n",
    "    def __init__(self, P, noise_std_dl):\n",
    "        super(DLTrainingPhase, self).__init__()\n",
    "        \n",
    "        # noise/annealing parameter\n",
    "        self.noise_std = torch.tensor(noise_std_dl, dtype=torch.float32).to(device)\n",
    "        self.aneal = torch.tensor(1.0, dtype=torch.float32).to(device)\n",
    "        \n",
    "        # Pilot sequence - Use pre-initialized values\n",
    "        self.Xp_r = nn.Parameter(Xp_r_init.clone().to(device))\n",
    "        self.Xp_i = nn.Parameter(Xp_i_init.clone().to(device))\n",
    "        \n",
    "        # Power normalizing\n",
    "        self.P = P\n",
    "        self.normalize_pilot()\n",
    "        \n",
    "    def normalize_pilot(self):\n",
    "        # Function : Normalizing the pilot sequence vectors\n",
    "        norm_X = torch.sqrt(torch.sum(self.Xp_r**2 + self.Xp_i**2, dim = 1, keepdim = True)) # (. , * , . ) *에 대해 sum 수행\n",
    "        self.Xp_r.data = torch.sqrt(torch.tensor(self.P)) * (self.Xp_r / norm_X)   \n",
    "        self.Xp_i.data = torch.sqrt(torch.tensor(self.P)) * (self.Xp_i / norm_X)\n",
    "        \n",
    "    def forward(self, hR, hI, K, M, L):\n",
    "        y_nless = {}\n",
    "        y_noisy = {}\n",
    "        \n",
    "        for kk in range(K):\n",
    "            hR_temp = hR[:, :, kk].reshape(-1, M, 1) # 차원 (batch_size, M)\n",
    "            hI_temp = hI[:, :, kk].reshape(-1, M, 1)\n",
    "\n",
    "            # 복소수 행렬 곱 수행\n",
    "            y_nless_r, y_nless_i = mult_mod_complex(hR_temp, hI_temp, self.Xp_r, self.Xp_i, 'l')\n",
    "\n",
    "            # 실수 및 허수 결합 -> 복소수로 결합 아니고 real representation\n",
    "            y_nless[kk] = torch.cat([y_nless_r.view(-1, L), y_nless_i.view(-1, L)], dim=1)\n",
    "\n",
    "            # 가우시안 노이즈 추가\n",
    "            noise = torch.randn_like(y_nless[kk]) * self.noise_std\n",
    "            y_noisy[kk] = y_nless[kk] + noise\n",
    "        \n",
    "        return y_noisy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UE side DNN - Quantizer for CSI feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UE_DNN(nn.Module):\n",
    "    def __init__(self, L, B, K, anneal = 1.0):\n",
    "        super(UE_DNN, self).__init__()\n",
    "        self.anneal = anneal\n",
    "        self.input_dim = 2*L\n",
    "        self.K=K\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            nn.BatchNorm1d(self.input_dim),\n",
    "            nn.Linear(self.input_dim, 1024),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Linear(256, B)\n",
    "        )\n",
    "        self.model.to(device)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        InfoBits = {0:0}\n",
    "        for kk in range(self.K):\n",
    "            InfoBits_linear = self.model(x[kk])  # 신경망을 통과한 값\n",
    "\n",
    "            # Straight-Through Estimator (STE) 적용\n",
    "            InfoBits_tanh = torch.tanh(self.anneal * InfoBits_linear)\n",
    "            InfoBits_sign = torch.sign(InfoBits_linear)\n",
    "\n",
    "            # Forward: Sign 값을 사용, Backward: Tanh gradient 사용\n",
    "            InfoBits[kk] = InfoBits_tanh + (InfoBits_sign - InfoBits_tanh).detach()\n",
    "        \n",
    "        return InfoBits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BS side DNN - Seperately estimating channel hhat_k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### [1] Precoder, Rate 계산 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Precoder\n",
    "## 주의 : 입력을 H^H로 받았다고 취급함! \n",
    "def ZF_Precoding(h_hat):\n",
    "    H_hat = h_hat\n",
    "    V = torch.zeros((H_hat.shape[0], H_hat.shape[1], H_hat.shape[2]), dtype=torch.complex64)\n",
    "    \n",
    "    for i in range(H_hat.shape[0]):\n",
    "        V[i, :, :] = torch.linalg.pinv(H_hat[i, :, :].T)\n",
    "        V[i, :, :] = V[i, :, :] / torch.sqrt(torch.trace(V[i, :, :] @ (V[i, :, :].H)))\n",
    "    \n",
    "    return V.to(device)\n",
    "    \n",
    "def MRT_Precoding(h_hat):\n",
    "    H_hat = h_hat\n",
    "    V = torch.zeros((H_hat.shape[0], H_hat.shape[1], H_hat.shape[2]), dtype=torch.complex64)\n",
    "    \n",
    "    for i in range(H_hat.shape[0]):\n",
    "        V[i, :, :] = H_hat[i, :, :].conj()\n",
    "        V[i, :, :] = V[i, :, :] / torch.sqrt(torch.trace(V[i, :, :] @ (V[i, :, :].H)))\n",
    "    \n",
    "    return V.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rate_calc(h_act_user, M, K, k_idx, V, noise_std):\n",
    "    H_act = h_act_user\n",
    "    nom_plus_denom = torch.zeros((H_act.shape[0], 1)).to(device) + torch.tensor(2 * noise_std ** 2).to(device)\n",
    "    \n",
    "    for kk in range(K):\n",
    "        product = torch.bmm(H_act.clone().unsqueeze(-1).permute(0, 2, 1), V[:, :, kk].clone().unsqueeze(-1)).squeeze(-1)\n",
    "        norm2 = torch.abs(product) ** 2\n",
    "        norm2.to(device)\n",
    "        \n",
    "        if kk == k_idx:\n",
    "            nom = norm2 # Wanted signal power\n",
    "        nom_plus_denom += norm2\n",
    "        \n",
    "    denom = nom_plus_denom - nom\n",
    "    rate = torch.mean(torch.log2(1 + (nom / denom)))\n",
    "    \n",
    "    return rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### [2] Single BS DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SSC_BS_Independent_NN(nn.Module):\n",
    "    def __init__(self, B, M):\n",
    "        super(SSC_BS_Independent_NN, self).__init__()\n",
    "        self.input_dim = B\n",
    "        self.M = M\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.BatchNorm1d(self.input_dim),\n",
    "            nn.Linear(self.input_dim, 1024),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Linear(256, 2*M)          \n",
    "        )\n",
    "        self.model.to(device)\n",
    "        \n",
    "    def forward(self, q):\n",
    "        hhat_k_R = self.model(q)[:, :self.M]\n",
    "        hhat_k_I = self.model(q)[:, self.M:]\n",
    "        hhat_k = torch.tensor(hhat_k_R + 1j* hhat_k_I).to(device)\n",
    "        return hhat_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SSC_BS_DNN(nn.Module):\n",
    "    def __init__(self, B, K, M):\n",
    "        super(SSC_BS_DNN, self).__init__()\n",
    "        self.num_users = K\n",
    "        self.quant_bit = B\n",
    "        self.tantenna = M\n",
    "        \n",
    "        self.dnn_list = nn.ModuleList([\n",
    "            SSC_BS_Independent_NN(self.quant_bit, self.tantenna) for _ in range(self.num_users)\n",
    "        ])\n",
    "        \n",
    "    def forward(self, Q, h_test, noise_std, MRT = True):\n",
    "        hhat_k = [self.dnn_list[i](Q[i]) for i in range(self.num_users)]\n",
    "        Hhat = torch.stack(hhat_k, dim=1) # (batch, M, K) 차원으로 concatenate\n",
    "        \n",
    "        rate= {}\n",
    "        \n",
    "        if MRT == True:\n",
    "            for kk in range(self.num_users):\n",
    "                rate[kk] = self.compute_rate_MRT(Hhat, h_test[:, :, kk], self.num_users, kk, noise_std)\n",
    "        else:\n",
    "            for kk in range(self.num_users):\n",
    "                rate[kk] = self.compute_rate_ZF(Hhat, h_test[:, :, kk], self.num_users, kk, noise_std)\n",
    "            \n",
    "        return rate\n",
    "    \n",
    "    def compute_rate_ZF(self, Hhat, h_act_kk, K, k_idx, noise_std):\n",
    "        V = torch.zeros((Hhat.shape[0], Hhat.shape[2], Hhat.shape[1]), dtype = torch.complex64).to(device)\n",
    "        for i in range(Hhat.shape[0]):\n",
    "            V[i, :, :] = torch.linalg.pinv(Hhat[i, :, :])\n",
    "            V[i, :, :] = V[i, :, :] / torch.sqrt(torch.trace(V[i, :, :].H @ V[i, :, :]))\n",
    "            \n",
    "        nom_plus_denom = torch.zeros((h_act_kk.shape[0], 1)).to(device) + torch.tensor(2 * noise_std ** 2).to(device)    \n",
    "        for kk in range(K):\n",
    "            product = torch.bmm(h_act_kk.clone().unsqueeze(-1).permute(0, 2, 1), V[:, :, kk].clone().unsqueeze(-1)).squeeze(-1)\n",
    "            norm2 = torch.abs(product) ** 2\n",
    "            norm2.to(device)\n",
    "            \n",
    "            if kk == k_idx:\n",
    "                nom = norm2\n",
    "            nom_plus_denom += norm2\n",
    "            \n",
    "        denom = nom_plus_denom - nom\n",
    "        rate = torch.log2(1+ (nom / denom))\n",
    "        \n",
    "        return -rate\n",
    "            \n",
    "    def compute_rate_MRT(self, Hhat, h_act_kk, K, k_idx, noise_std):\n",
    "        V = torch.zeros((Hhat.shape[0], Hhat.shape[1], Hhat.shape[2]), dtype = torch.complex64).to(device)\n",
    "        for i in range(Hhat.shape[0]):\n",
    "            V[i, :, :] = Hhat[i, :, :]\n",
    "            V[i, :, :] = V[i, :, :] / torch.sqrt(torch.trace(V[i, :, :].H @ V[i, :, :]))\n",
    "            \n",
    "        nom_plus_denom = torch.zeros((h_act_kk.shape[0], 1)).to(device) + torch.tensor(2 * noise_std ** 2).to(device)    \n",
    "        for kk in range(K):\n",
    "            product = torch.bmm(h_act_kk.clone().unsqueeze(-1).permute(0, 2, 1).conj(), V[:, :, kk].clone().unsqueeze(-1)).squeeze(-1)\n",
    "            norm2 = torch.abs(product) ** 2\n",
    "            norm2.to(device)\n",
    "            \n",
    "            if kk == k_idx:\n",
    "                nom = norm2\n",
    "            nom_plus_denom += norm2\n",
    "            \n",
    "        denom = nom_plus_denom - nom\n",
    "        rate = torch.log2(1+ (nom / denom))\n",
    "        \n",
    "        return -rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 학습하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [],
   "source": [
    "pilot_train = DLTrainingPhase(P, noise_std_dl)\n",
    "ue_dnn = UE_DNN(L, B, K, annealing_rate)\n",
    "bs_dnn = SSC_BS_DNN(B, K, M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLoss(nn.Module):\n",
    "    def __init__(self, K):\n",
    "        super(CustomLoss, self).__init__()\n",
    "        self.K = K\n",
    "        \n",
    "    def forward(self, rate):\n",
    "        rate_total = sum(rate[k] for k in range(self.K))\n",
    "        loss = torch.mean(rate_total)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "Lossfunc = CustomLoss(K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(list(pilot_train.parameters())+list(ue_dnn.parameters())+list(bs_dnn.parameters())\n",
    "                       , lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test set 생성\n",
    "h_test, hR_test, hI_test = generate_batch_data(test_size, M, K, Lp, LSF_UE, Mainlobe_UE, HalfBW_UE)\n",
    "h_test = h_test.requires_grad_(True)\n",
    "\n",
    "\n",
    "# Tensor 변환 후 GPU 할당\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "hR_test = hR_test.clone().detach().to(device, dtype=torch.float32)\n",
    "hI_test = hI_test.clone().detach().to(device, dtype=torch.float32)\n",
    "noise_std_test = torch.tensor(noise_std_dl).clone().detach().to(device, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [],
   "source": [
    "AA = sio.loadmat('Data_test_K2M64Lp2L8_withParams.mat') # -> 학습이 끝난 후 loss를 계산하기 위한 data\n",
    "hR_test_Final = AA['hR_act_test_Final']\n",
    "hI_test_Final = AA['hI_act_test_Final']\n",
    "h_test_Final = AA['h_act_test_Final']\n",
    "\n",
    "hR_test_Final = torch.tensor(hR_test_Final, dtype=torch.float32).to(device)\n",
    "hI_test_Final = torch.tensor(hI_test_Final, dtype=torch.float32).to(device)\n",
    "h_test_Final = torch.tensor(h_test_Final, dtype=torch.complex64).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000, 64, 2])\n"
     ]
    }
   ],
   "source": [
    "print(h_test.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 초기 모델 저장 경로 설정\n",
    "save_path = './params.pth'\n",
    "\n",
    "# 모델 불러오기 (처음 실행 여부 확인)\n",
    "initial_run = 1\n",
    "if initial_run == 0:\n",
    "    checkpoint = torch.load(save_path)\n",
    "    pilot_train.load_state_dict(checkpoint['pilot_train'])\n",
    "    bs_dnn.load_state_dict(checkpoint['bs_dnn'])\n",
    "    ue_dnn.load_state_dict(checkpoint['ue_dnn'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    best_loss = checkpoint['best_loss']\n",
    "    print(\"✅ 모델 파라미터 불러오기 완료!\")\n",
    "else:\n",
    "    best_loss = float('inf')  # 초기 Best Loss 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\unist\\AppData\\Local\\Temp\\ipykernel_45992\\1883434635.py:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  hhat_k = torch.tensor(hhat_k_R + 1j* hhat_k_I).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model saved at epoch 0, Loss: -1.86619\n",
      "epoch 0  anneal_param:1.0161\n",
      "         loss_test:1.86619   best_test:1.86619\n",
      "✅ Model saved at epoch 10, Loss: -1.88536\n",
      "epoch 10  anneal_param:1.0161\n",
      "         loss_test:1.88536   best_test:1.88536\n",
      "epoch 20  anneal_param:1.0171\n",
      "         loss_test:1.87854   best_test:1.88536\n",
      "epoch 30  anneal_param:1.0182\n",
      "         loss_test:1.86746   best_test:1.88536\n",
      "epoch 40  anneal_param:1.0192\n",
      "         loss_test:1.88228   best_test:1.88536\n",
      "epoch 50  anneal_param:1.0202\n",
      "         loss_test:1.87547   best_test:1.88536\n",
      "epoch 60  anneal_param:1.0212\n",
      "         loss_test:1.85930   best_test:1.88536\n",
      "epoch 70  anneal_param:1.0222\n",
      "         loss_test:1.87419   best_test:1.88536\n",
      "epoch 80  anneal_param:1.0233\n",
      "         loss_test:1.87098   best_test:1.88536\n",
      "epoch 90  anneal_param:1.0243\n",
      "         loss_test:1.86506   best_test:1.88536\n",
      "epoch 100  anneal_param:1.0253\n",
      "         loss_test:1.86934   best_test:1.88536\n",
      "epoch 110  anneal_param:1.0263\n",
      "         loss_test:1.88506   best_test:1.88536\n",
      "epoch 120  anneal_param:1.0274\n",
      "         loss_test:1.85784   best_test:1.88536\n",
      "epoch 130  anneal_param:1.0284\n",
      "         loss_test:1.86629   best_test:1.88536\n",
      "epoch 140  anneal_param:1.0294\n",
      "         loss_test:1.86815   best_test:1.88536\n",
      "epoch 150  anneal_param:1.0304\n",
      "         loss_test:1.86284   best_test:1.88536\n",
      "epoch 160  anneal_param:1.0315\n",
      "         loss_test:1.88097   best_test:1.88536\n",
      "epoch 170  anneal_param:1.0325\n",
      "         loss_test:1.85370   best_test:1.88536\n",
      "epoch 180  anneal_param:1.0335\n",
      "         loss_test:1.87808   best_test:1.88536\n",
      "✅ Model saved at epoch 190, Loss: -1.88607\n",
      "epoch 190  anneal_param:1.0335\n",
      "         loss_test:1.88607   best_test:1.88607\n",
      "epoch 200  anneal_param:1.0346\n",
      "         loss_test:1.87419   best_test:1.88607\n",
      "epoch 210  anneal_param:1.0356\n",
      "         loss_test:1.87065   best_test:1.88607\n",
      "epoch 220  anneal_param:1.0366\n",
      "         loss_test:1.87063   best_test:1.88607\n",
      "epoch 230  anneal_param:1.0377\n",
      "         loss_test:1.86990   best_test:1.88607\n",
      "epoch 240  anneal_param:1.0387\n",
      "         loss_test:1.87080   best_test:1.88607\n",
      "epoch 250  anneal_param:1.0398\n",
      "         loss_test:1.85294   best_test:1.88607\n",
      "epoch 260  anneal_param:1.0408\n",
      "         loss_test:1.87661   best_test:1.88607\n",
      "epoch 270  anneal_param:1.0418\n",
      "         loss_test:1.87337   best_test:1.88607\n",
      "epoch 280  anneal_param:1.0429\n",
      "         loss_test:1.87539   best_test:1.88607\n",
      "epoch 290  anneal_param:1.0439\n",
      "         loss_test:1.87367   best_test:1.88607\n",
      "epoch 300  anneal_param:1.0450\n",
      "         loss_test:1.88145   best_test:1.88607\n",
      "epoch 310  anneal_param:1.0460\n",
      "         loss_test:1.86806   best_test:1.88607\n",
      "epoch 320  anneal_param:1.0471\n",
      "         loss_test:1.88241   best_test:1.88607\n",
      "epoch 330  anneal_param:1.0481\n",
      "         loss_test:1.88514   best_test:1.88607\n",
      "epoch 340  anneal_param:1.0491\n",
      "         loss_test:1.86680   best_test:1.88607\n",
      "✅ Model saved at epoch 350, Loss: -1.89119\n",
      "epoch 350  anneal_param:1.0491\n",
      "         loss_test:1.89119   best_test:1.89119\n",
      "epoch 360  anneal_param:1.0502\n",
      "         loss_test:1.86653   best_test:1.89119\n",
      "epoch 370  anneal_param:1.0512\n",
      "         loss_test:1.86423   best_test:1.89119\n",
      "epoch 380  anneal_param:1.0523\n",
      "         loss_test:1.86781   best_test:1.89119\n",
      "epoch 390  anneal_param:1.0533\n",
      "         loss_test:1.87062   best_test:1.89119\n",
      "epoch 400  anneal_param:1.0544\n",
      "         loss_test:1.87874   best_test:1.89119\n",
      "epoch 410  anneal_param:1.0555\n",
      "         loss_test:1.87720   best_test:1.89119\n",
      "epoch 420  anneal_param:1.0565\n",
      "         loss_test:1.85871   best_test:1.89119\n",
      "epoch 430  anneal_param:1.0576\n",
      "         loss_test:1.88445   best_test:1.89119\n",
      "epoch 440  anneal_param:1.0586\n",
      "         loss_test:1.88185   best_test:1.89119\n",
      "epoch 450  anneal_param:1.0597\n",
      "         loss_test:1.87017   best_test:1.89119\n",
      "epoch 460  anneal_param:1.0607\n",
      "         loss_test:1.86538   best_test:1.89119\n",
      "epoch 470  anneal_param:1.0618\n",
      "         loss_test:1.87038   best_test:1.89119\n",
      "epoch 480  anneal_param:1.0629\n",
      "         loss_test:1.85471   best_test:1.89119\n",
      "epoch 490  anneal_param:1.0639\n",
      "         loss_test:1.87597   best_test:1.89119\n",
      "epoch 500  anneal_param:1.0650\n",
      "         loss_test:1.86428   best_test:1.89119\n",
      "epoch 510  anneal_param:1.0661\n",
      "         loss_test:1.86526   best_test:1.89119\n",
      "epoch 520  anneal_param:1.0671\n",
      "         loss_test:1.87559   best_test:1.89119\n",
      "epoch 530  anneal_param:1.0682\n",
      "         loss_test:1.85428   best_test:1.89119\n",
      "epoch 540  anneal_param:1.0693\n",
      "         loss_test:1.88001   best_test:1.89119\n",
      "epoch 550  anneal_param:1.0703\n",
      "         loss_test:1.86665   best_test:1.89119\n",
      "epoch 560  anneal_param:1.0714\n",
      "         loss_test:1.88710   best_test:1.89119\n",
      "epoch 570  anneal_param:1.0725\n",
      "         loss_test:1.86555   best_test:1.89119\n",
      "epoch 580  anneal_param:1.0735\n",
      "         loss_test:1.86510   best_test:1.89119\n",
      "epoch 590  anneal_param:1.0746\n",
      "         loss_test:1.87093   best_test:1.89119\n",
      "epoch 600  anneal_param:1.0757\n",
      "         loss_test:1.87240   best_test:1.89119\n",
      "epoch 610  anneal_param:1.0768\n",
      "         loss_test:1.86914   best_test:1.89119\n",
      "epoch 620  anneal_param:1.0778\n",
      "         loss_test:1.85450   best_test:1.89119\n",
      "epoch 630  anneal_param:1.0789\n",
      "         loss_test:1.86858   best_test:1.89119\n",
      "epoch 640  anneal_param:1.0800\n",
      "         loss_test:1.85060   best_test:1.89119\n",
      "epoch 650  anneal_param:1.0811\n",
      "         loss_test:1.89022   best_test:1.89119\n",
      "epoch 660  anneal_param:1.0822\n",
      "         loss_test:1.85654   best_test:1.89119\n",
      "epoch 670  anneal_param:1.0832\n",
      "         loss_test:1.86671   best_test:1.89119\n",
      "epoch 680  anneal_param:1.0843\n",
      "         loss_test:1.87195   best_test:1.89119\n",
      "epoch 690  anneal_param:1.0854\n",
      "         loss_test:1.86003   best_test:1.89119\n",
      "epoch 700  anneal_param:1.0865\n",
      "         loss_test:1.88635   best_test:1.89119\n",
      "epoch 710  anneal_param:1.0876\n",
      "         loss_test:1.86655   best_test:1.89119\n",
      "epoch 720  anneal_param:1.0887\n",
      "         loss_test:1.88565   best_test:1.89119\n",
      "epoch 730  anneal_param:1.0898\n",
      "         loss_test:1.86567   best_test:1.89119\n",
      "epoch 740  anneal_param:1.0908\n",
      "         loss_test:1.87556   best_test:1.89119\n",
      "epoch 750  anneal_param:1.0919\n",
      "         loss_test:1.88894   best_test:1.89119\n",
      "epoch 760  anneal_param:1.0930\n",
      "         loss_test:1.88354   best_test:1.89119\n",
      "epoch 770  anneal_param:1.0941\n",
      "         loss_test:1.88665   best_test:1.89119\n",
      "epoch 780  anneal_param:1.0952\n",
      "         loss_test:1.86348   best_test:1.89119\n",
      "epoch 790  anneal_param:1.0963\n",
      "         loss_test:1.88570   best_test:1.89119\n",
      "epoch 800  anneal_param:1.0974\n",
      "         loss_test:1.86028   best_test:1.89119\n",
      "epoch 810  anneal_param:1.0985\n",
      "         loss_test:1.86155   best_test:1.89119\n",
      "epoch 820  anneal_param:1.0996\n",
      "         loss_test:1.88306   best_test:1.89119\n",
      "epoch 830  anneal_param:1.1007\n",
      "         loss_test:1.85171   best_test:1.89119\n",
      "epoch 840  anneal_param:1.1018\n",
      "         loss_test:1.87234   best_test:1.89119\n",
      "epoch 850  anneal_param:1.1029\n",
      "         loss_test:1.87494   best_test:1.89119\n",
      "epoch 860  anneal_param:1.1040\n",
      "         loss_test:1.87134   best_test:1.89119\n",
      "epoch 870  anneal_param:1.1051\n",
      "         loss_test:1.86086   best_test:1.89119\n",
      "epoch 880  anneal_param:1.1062\n",
      "         loss_test:1.85581   best_test:1.89119\n",
      "epoch 890  anneal_param:1.1073\n",
      "         loss_test:1.87964   best_test:1.89119\n",
      "epoch 900  anneal_param:1.1084\n",
      "         loss_test:1.86032   best_test:1.89119\n",
      "epoch 910  anneal_param:1.1095\n",
      "         loss_test:1.87665   best_test:1.89119\n",
      "epoch 920  anneal_param:1.1107\n",
      "         loss_test:1.87667   best_test:1.89119\n",
      "epoch 930  anneal_param:1.1118\n",
      "         loss_test:1.86344   best_test:1.89119\n",
      "epoch 940  anneal_param:1.1129\n",
      "         loss_test:1.87591   best_test:1.89119\n",
      "epoch 950  anneal_param:1.1140\n",
      "         loss_test:1.87081   best_test:1.89119\n",
      "epoch 960  anneal_param:1.1151\n",
      "         loss_test:1.87233   best_test:1.89119\n",
      "epoch 970  anneal_param:1.1162\n",
      "         loss_test:1.87177   best_test:1.89119\n",
      "epoch 980  anneal_param:1.1173\n",
      "         loss_test:1.86971   best_test:1.89119\n",
      "epoch 990  anneal_param:1.1185\n",
      "         loss_test:1.86109   best_test:1.89119\n",
      "epoch 1000  anneal_param:1.1196\n",
      "         loss_test:1.85356   best_test:1.89119\n",
      "epoch 1010  anneal_param:1.1207\n",
      "         loss_test:1.89025   best_test:1.89119\n",
      "epoch 1020  anneal_param:1.1218\n",
      "         loss_test:1.85397   best_test:1.89119\n",
      "epoch 1030  anneal_param:1.1229\n",
      "         loss_test:1.84344   best_test:1.89119\n",
      "epoch 1040  anneal_param:1.1241\n",
      "         loss_test:1.86838   best_test:1.89119\n",
      "epoch 1050  anneal_param:1.1252\n",
      "         loss_test:1.87978   best_test:1.89119\n",
      "epoch 1060  anneal_param:1.1263\n",
      "         loss_test:1.85968   best_test:1.89119\n",
      "epoch 1070  anneal_param:1.1274\n",
      "         loss_test:1.86194   best_test:1.89119\n",
      "epoch 1080  anneal_param:1.1286\n",
      "         loss_test:1.87733   best_test:1.89119\n",
      "epoch 1090  anneal_param:1.1297\n",
      "         loss_test:1.86320   best_test:1.89119\n",
      "epoch 1100  anneal_param:1.1308\n",
      "         loss_test:1.83896   best_test:1.89119\n",
      "epoch 1110  anneal_param:1.1319\n",
      "         loss_test:1.86429   best_test:1.89119\n",
      "epoch 1120  anneal_param:1.1331\n",
      "         loss_test:1.87398   best_test:1.89119\n",
      "epoch 1130  anneal_param:1.1342\n",
      "         loss_test:1.85420   best_test:1.89119\n",
      "epoch 1140  anneal_param:1.1353\n",
      "         loss_test:1.85223   best_test:1.89119\n",
      "epoch 1150  anneal_param:1.1365\n",
      "         loss_test:1.85164   best_test:1.89119\n",
      "epoch 1160  anneal_param:1.1376\n",
      "         loss_test:1.86844   best_test:1.89119\n",
      "epoch 1170  anneal_param:1.1388\n",
      "         loss_test:1.87098   best_test:1.89119\n",
      "epoch 1180  anneal_param:1.1399\n",
      "         loss_test:1.88331   best_test:1.89119\n",
      "epoch 1190  anneal_param:1.1410\n",
      "         loss_test:1.87946   best_test:1.89119\n",
      "epoch 1200  anneal_param:1.1422\n",
      "         loss_test:1.88766   best_test:1.89119\n",
      "epoch 1210  anneal_param:1.1433\n",
      "         loss_test:1.88976   best_test:1.89119\n",
      "epoch 1220  anneal_param:1.1445\n",
      "         loss_test:1.86949   best_test:1.89119\n",
      "epoch 1230  anneal_param:1.1456\n",
      "         loss_test:1.88210   best_test:1.89119\n",
      "epoch 1240  anneal_param:1.1467\n",
      "         loss_test:1.87579   best_test:1.89119\n",
      "epoch 1250  anneal_param:1.1479\n",
      "         loss_test:1.88402   best_test:1.89119\n",
      "epoch 1260  anneal_param:1.1490\n",
      "         loss_test:1.87967   best_test:1.89119\n",
      "epoch 1270  anneal_param:1.1502\n",
      "         loss_test:1.86902   best_test:1.89119\n",
      "epoch 1280  anneal_param:1.1513\n",
      "         loss_test:1.85524   best_test:1.89119\n",
      "epoch 1290  anneal_param:1.1525\n",
      "         loss_test:1.86446   best_test:1.89119\n",
      "epoch 1300  anneal_param:1.1536\n",
      "         loss_test:1.85160   best_test:1.89119\n",
      "epoch 1310  anneal_param:1.1548\n",
      "         loss_test:1.85796   best_test:1.89119\n",
      "epoch 1320  anneal_param:1.1560\n",
      "         loss_test:1.87673   best_test:1.89119\n",
      "epoch 1330  anneal_param:1.1571\n",
      "         loss_test:1.87653   best_test:1.89119\n",
      "epoch 1340  anneal_param:1.1583\n",
      "         loss_test:1.86498   best_test:1.89119\n",
      "epoch 1350  anneal_param:1.1594\n",
      "         loss_test:1.86589   best_test:1.89119\n",
      "epoch 1360  anneal_param:1.1606\n",
      "         loss_test:1.85014   best_test:1.89119\n",
      "✅ Model saved at epoch 1370, Loss: -1.89342\n",
      "epoch 1370  anneal_param:1.1606\n",
      "         loss_test:1.89342   best_test:1.89342\n",
      "epoch 1380  anneal_param:1.1617\n",
      "         loss_test:1.87469   best_test:1.89342\n",
      "epoch 1390  anneal_param:1.1629\n",
      "         loss_test:1.87006   best_test:1.89342\n",
      "epoch 1400  anneal_param:1.1641\n",
      "         loss_test:1.87874   best_test:1.89342\n",
      "epoch 1410  anneal_param:1.1652\n",
      "         loss_test:1.87852   best_test:1.89342\n",
      "epoch 1420  anneal_param:1.1664\n",
      "         loss_test:1.87627   best_test:1.89342\n",
      "epoch 1430  anneal_param:1.1676\n",
      "         loss_test:1.85527   best_test:1.89342\n",
      "epoch 1440  anneal_param:1.1687\n",
      "         loss_test:1.87362   best_test:1.89342\n",
      "epoch 1450  anneal_param:1.1699\n",
      "         loss_test:1.87440   best_test:1.89342\n",
      "epoch 1460  anneal_param:1.1711\n",
      "         loss_test:1.86631   best_test:1.89342\n",
      "epoch 1470  anneal_param:1.1722\n",
      "         loss_test:1.87376   best_test:1.89342\n",
      "epoch 1480  anneal_param:1.1734\n",
      "         loss_test:1.84472   best_test:1.89342\n",
      "epoch 1490  anneal_param:1.1746\n",
      "         loss_test:1.87095   best_test:1.89342\n",
      "epoch 1500  anneal_param:1.1758\n",
      "         loss_test:1.86091   best_test:1.89342\n",
      "epoch 1510  anneal_param:1.1769\n",
      "         loss_test:1.87635   best_test:1.89342\n",
      "epoch 1520  anneal_param:1.1781\n",
      "         loss_test:1.85681   best_test:1.89342\n",
      "epoch 1530  anneal_param:1.1793\n",
      "         loss_test:1.86689   best_test:1.89342\n",
      "epoch 1540  anneal_param:1.1805\n",
      "         loss_test:1.87129   best_test:1.89342\n",
      "epoch 1550  anneal_param:1.1817\n",
      "         loss_test:1.88653   best_test:1.89342\n",
      "epoch 1560  anneal_param:1.1828\n",
      "         loss_test:1.87869   best_test:1.89342\n",
      "epoch 1570  anneal_param:1.1840\n",
      "         loss_test:1.86746   best_test:1.89342\n",
      "epoch 1580  anneal_param:1.1852\n",
      "         loss_test:1.86897   best_test:1.89342\n",
      "epoch 1590  anneal_param:1.1864\n",
      "         loss_test:1.85953   best_test:1.89342\n",
      "epoch 1600  anneal_param:1.1876\n",
      "         loss_test:1.87615   best_test:1.89342\n",
      "epoch 1610  anneal_param:1.1888\n",
      "         loss_test:1.88183   best_test:1.89342\n",
      "epoch 1620  anneal_param:1.1900\n",
      "         loss_test:1.88232   best_test:1.89342\n",
      "epoch 1630  anneal_param:1.1911\n",
      "         loss_test:1.84919   best_test:1.89342\n",
      "epoch 1640  anneal_param:1.1923\n",
      "         loss_test:1.86635   best_test:1.89342\n",
      "epoch 1650  anneal_param:1.1935\n",
      "         loss_test:1.84931   best_test:1.89342\n",
      "epoch 1660  anneal_param:1.1947\n",
      "         loss_test:1.87814   best_test:1.89342\n",
      "epoch 1670  anneal_param:1.1959\n",
      "         loss_test:1.86956   best_test:1.89342\n",
      "epoch 1680  anneal_param:1.1971\n",
      "         loss_test:1.86219   best_test:1.89342\n",
      "epoch 1690  anneal_param:1.1983\n",
      "         loss_test:1.87761   best_test:1.89342\n",
      "epoch 1700  anneal_param:1.1995\n",
      "         loss_test:1.87873   best_test:1.89342\n",
      "epoch 1710  anneal_param:1.2007\n",
      "         loss_test:1.87106   best_test:1.89342\n",
      "epoch 1720  anneal_param:1.2019\n",
      "         loss_test:1.87504   best_test:1.89342\n",
      "epoch 1730  anneal_param:1.2031\n",
      "         loss_test:1.86433   best_test:1.89342\n",
      "epoch 1740  anneal_param:1.2043\n",
      "         loss_test:1.86058   best_test:1.89342\n",
      "epoch 1750  anneal_param:1.2055\n",
      "         loss_test:1.86768   best_test:1.89342\n",
      "epoch 1760  anneal_param:1.2067\n",
      "         loss_test:1.88229   best_test:1.89342\n",
      "epoch 1770  anneal_param:1.2079\n",
      "         loss_test:1.88512   best_test:1.89342\n",
      "epoch 1780  anneal_param:1.2091\n",
      "         loss_test:1.87329   best_test:1.89342\n",
      "epoch 1790  anneal_param:1.2103\n",
      "         loss_test:1.86385   best_test:1.89342\n",
      "epoch 1800  anneal_param:1.2116\n",
      "         loss_test:1.87731   best_test:1.89342\n",
      "epoch 1810  anneal_param:1.2128\n",
      "         loss_test:1.88433   best_test:1.89342\n",
      "epoch 1820  anneal_param:1.2140\n",
      "         loss_test:1.87198   best_test:1.89342\n",
      "epoch 1830  anneal_param:1.2152\n",
      "         loss_test:1.86153   best_test:1.89342\n",
      "epoch 1840  anneal_param:1.2164\n",
      "         loss_test:1.85959   best_test:1.89342\n",
      "epoch 1850  anneal_param:1.2176\n",
      "         loss_test:1.86911   best_test:1.89342\n",
      "epoch 1860  anneal_param:1.2188\n",
      "         loss_test:1.86899   best_test:1.89342\n",
      "epoch 1870  anneal_param:1.2201\n",
      "         loss_test:1.88104   best_test:1.89342\n",
      "✅ Model saved at epoch 1880, Loss: -1.89365\n",
      "epoch 1880  anneal_param:1.2201\n",
      "         loss_test:1.89365   best_test:1.89365\n",
      "epoch 1890  anneal_param:1.2213\n",
      "         loss_test:1.85686   best_test:1.89365\n",
      "epoch 1900  anneal_param:1.2225\n",
      "         loss_test:1.86943   best_test:1.89365\n",
      "epoch 1910  anneal_param:1.2237\n",
      "         loss_test:1.86878   best_test:1.89365\n",
      "epoch 1920  anneal_param:1.2249\n",
      "         loss_test:1.87846   best_test:1.89365\n",
      "epoch 1930  anneal_param:1.2262\n",
      "         loss_test:1.85887   best_test:1.89365\n",
      "epoch 1940  anneal_param:1.2274\n",
      "         loss_test:1.88342   best_test:1.89365\n",
      "epoch 1950  anneal_param:1.2286\n",
      "         loss_test:1.87124   best_test:1.89365\n",
      "epoch 1960  anneal_param:1.2299\n",
      "         loss_test:1.85773   best_test:1.89365\n",
      "epoch 1970  anneal_param:1.2311\n",
      "         loss_test:1.88395   best_test:1.89365\n",
      "epoch 1980  anneal_param:1.2323\n",
      "         loss_test:1.86731   best_test:1.89365\n",
      "epoch 1990  anneal_param:1.2335\n",
      "         loss_test:1.86724   best_test:1.89365\n",
      "epoch 2000  anneal_param:1.2348\n",
      "         loss_test:1.86952   best_test:1.89365\n",
      "epoch 2010  anneal_param:1.2360\n",
      "         loss_test:1.86957   best_test:1.89365\n",
      "epoch 2020  anneal_param:1.2373\n",
      "         loss_test:1.87681   best_test:1.89365\n",
      "epoch 2030  anneal_param:1.2385\n",
      "         loss_test:1.88074   best_test:1.89365\n",
      "epoch 2040  anneal_param:1.2397\n",
      "         loss_test:1.85934   best_test:1.89365\n",
      "epoch 2050  anneal_param:1.2410\n",
      "         loss_test:1.87504   best_test:1.89365\n",
      "epoch 2060  anneal_param:1.2422\n",
      "         loss_test:1.86815   best_test:1.89365\n",
      "epoch 2070  anneal_param:1.2435\n",
      "         loss_test:1.88219   best_test:1.89365\n",
      "epoch 2080  anneal_param:1.2447\n",
      "         loss_test:1.88151   best_test:1.89365\n",
      "epoch 2090  anneal_param:1.2459\n",
      "         loss_test:1.87241   best_test:1.89365\n",
      "epoch 2100  anneal_param:1.2472\n",
      "         loss_test:1.88090   best_test:1.89365\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[574], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m y_pilot \u001b[38;5;241m=\u001b[39m pilot_train(hR_batch, hI_batch, K, M, L) \u001b[38;5;66;03m# K user의 파일럿 수신 신호 리스트\u001b[39;00m\n\u001b[0;32m     13\u001b[0m UE_Feedback \u001b[38;5;241m=\u001b[39m ue_dnn(y_pilot)\n\u001b[1;32m---> 14\u001b[0m rate_ZF \u001b[38;5;241m=\u001b[39m \u001b[43mbs_dnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mUE_Feedback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnoise_std_dl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mMRT\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m loss_ZF\u001b[38;5;241m=\u001b[39m Lossfunc(rate_ZF)\n\u001b[0;32m     17\u001b[0m loss_ZF\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\unist\\anaconda3\\envs\\acnl\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\unist\\anaconda3\\envs\\acnl\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[566], line 23\u001b[0m, in \u001b[0;36mSSC_BS_DNN.forward\u001b[1;34m(self, Q, h_test, noise_std, MRT)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m kk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_users):\n\u001b[1;32m---> 23\u001b[0m         rate[kk] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_rate_ZF\u001b[49m\u001b[43m(\u001b[49m\u001b[43mHhat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh_test\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_users\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnoise_std\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m rate\n",
      "Cell \u001b[1;32mIn[566], line 31\u001b[0m, in \u001b[0;36mSSC_BS_DNN.compute_rate_ZF\u001b[1;34m(self, Hhat, h_act_kk, K, k_idx, noise_std)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(Hhat\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[0;32m     30\u001b[0m     V[i, :, :] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mpinv(Hhat[i, :, :])\n\u001b[1;32m---> 31\u001b[0m     V[i, :, :] \u001b[38;5;241m=\u001b[39m V[i, :, :] \u001b[38;5;241m/\u001b[39m torch\u001b[38;5;241m.\u001b[39msqrt(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mV\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mH\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mV\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     33\u001b[0m nom_plus_denom \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros((h_act_kk\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mto(device) \u001b[38;5;241m+\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m noise_std \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)    \n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m kk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(K):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Loop for ZF\n",
    "for epoch in range(n_epochs):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    for _ in range(batch_per_epoch):\n",
    "        # train dataset 생성\n",
    "        h_batch, hR_batch, hI_batch = generate_batch_data(batch_size,M,K,Lp,LSF_UE,Mainlobe_UE,HalfBW_UE)\n",
    "        hR_batch = hR_batch.requires_grad_(True)\n",
    "        hI_batch = hI_batch.requires_grad_(True)\n",
    "        h_batch = h_batch.requires_grad_(True)\n",
    "        \n",
    "        y_pilot = pilot_train(hR_batch, hI_batch, K, M, L) # K user의 파일럿 수신 신호 리스트\n",
    "        UE_Feedback = ue_dnn(y_pilot)\n",
    "        rate_ZF = bs_dnn(UE_Feedback, h_batch, noise_std_dl, MRT=False)\n",
    "        loss_ZF= Lossfunc(rate_ZF)\n",
    "        \n",
    "        loss_ZF.backward()\n",
    "        optimizer.step\n",
    "        \n",
    "    if epoch % 10 == 0:\n",
    "        y_pilot = pilot_train(hR_test, hI_test, K, M, L)\n",
    "        UE_Feedback = ue_dnn(y_pilot)\n",
    "        rate_ZF = bs_dnn(UE_Feedback, h_test, noise_std_dl, MRT = False)\n",
    "        loss_ZF = Lossfunc(rate_ZF)\n",
    "        \n",
    "        if loss_ZF < best_loss:\n",
    "            best_loss = loss_ZF\n",
    "            \n",
    "            torch.save({\n",
    "                'pilot_train' : pilot_train.state_dict(),\n",
    "                'bs_dnn' : bs_dnn.state_dict(),\n",
    "                'ue_dnn' : ue_dnn.state_dict(),\n",
    "                'optimizer' : optimizer.state_dict(),\n",
    "                'best_loss' : best_loss\n",
    "            }, save_path)\n",
    "            \n",
    "            print(f\"✅ Model saved at epoch {epoch}, Loss: {best_loss:.5f}\")\n",
    "        else:\n",
    "            anneal_param = anneal_param*annealing_rate\n",
    "        print('epoch',epoch,' anneal_param:%4.4f'%anneal_param)\n",
    "        print('         loss_test:%2.5f'%-loss_ZF,'  best_test:%2.5f'%-best_loss)\n",
    "        \n",
    "y_pilot = pilot_train(hR_test_Final, hI_test_Final, K, M, L)\n",
    "UE_Feedback = ue_dnn(y_pilot)\n",
    "rate_ZF_Final, _ = bs_dnn(UE_Feedback, h_test_Final, noise_std_dl, MRT = False)\n",
    "loss_ZF_Final = Lossfunc(rate_ZF_Final)\n",
    "\n",
    "print(-loss_ZF_Final)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 초기 모델 저장 경로 설정\n",
    "save_path = './params.pth'\n",
    "\n",
    "# 모델 불러오기 (처음 실행 여부 확인)\n",
    "initial_run = 1\n",
    "if initial_run == 0:\n",
    "    checkpoint = torch.load(save_path)\n",
    "    pilot_train.load_state_dict(checkpoint['pilot_train'])\n",
    "    bs_dnn.load_state_dict(checkpoint['bs_dnn'])\n",
    "    ue_dnn.load_state_dict(checkpoint['ue_dnn'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    best_loss = checkpoint['best_loss']\n",
    "    print(\"✅ 모델 파라미터 불러오기 완료!\")\n",
    "else:\n",
    "    best_loss = float('inf')  # 초기 Best Loss 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\unist\\AppData\\Local\\Temp\\ipykernel_27844\\1883434635.py:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  hhat_k = torch.tensor(hhat_k_R + 1j* hhat_k_I).to(device)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "SSC_BS_DNN.compute_rate_ZF() takes 5 positional arguments but 6 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[113], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m y_pilot \u001b[38;5;241m=\u001b[39m pilot_train(hR_batch, hI_batch, K, M, L) \u001b[38;5;66;03m# K user의 파일럿 수신 신호 리스트\u001b[39;00m\n\u001b[0;32m     10\u001b[0m UE_Feedback \u001b[38;5;241m=\u001b[39m ue_dnn(y_pilot)\n\u001b[1;32m---> 11\u001b[0m _, rate_MRT \u001b[38;5;241m=\u001b[39m \u001b[43mbs_dnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mUE_Feedback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnoise_std_dl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m _, loss_MRT \u001b[38;5;241m=\u001b[39m Lossfunc(_, rate_MRT)\n\u001b[0;32m     14\u001b[0m loss_MRT\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\unist\\anaconda3\\envs\\acnl\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\unist\\anaconda3\\envs\\acnl\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[104], line 20\u001b[0m, in \u001b[0;36mSSC_BS_DNN.forward\u001b[1;34m(self, Q, h_test, noise_std)\u001b[0m\n\u001b[0;32m     17\u001b[0m rate_MRT \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m kk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_users):\n\u001b[1;32m---> 20\u001b[0m     rate_ZF[kk] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_rate_ZF\u001b[49m\u001b[43m(\u001b[49m\u001b[43mHhat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_users\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnoise_std\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m     rate_MRT[kk] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_rate_MRT(Hhat, h_test, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_users, kk, noise_std)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m rate_ZF, rate_MRT\n",
      "\u001b[1;31mTypeError\u001b[0m: SSC_BS_DNN.compute_rate_ZF() takes 5 positional arguments but 6 were given"
     ]
    }
   ],
   "source": [
    "# Loop for MRT\n",
    "for epoch in range(n_epochs):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    for _ in range(batch_per_epoch):\n",
    "        # train dataset 생성\n",
    "        h_batch, hR_batch, hI_batch = generate_batch_data(batch_size,M,K,Lp,LSF_UE,Mainlobe_UE,HalfBW_UE)\n",
    "        \n",
    "        y_pilot = pilot_train(hR_batch, hI_batch, K, M, L) # K user의 파일럿 수신 신호 리스트\n",
    "        UE_Feedback = ue_dnn(y_pilot)\n",
    "        rate_MRT = bs_dnn(UE_Feedback, h_batch, noise_std_dl, MRT = True)\n",
    "        loss_MRT = Lossfunc(rate_MRT)\n",
    "        \n",
    "        loss_MRT.backward()\n",
    "        optimizer.step\n",
    "        \n",
    "        if epoch % 10 == 0:\n",
    "            y_pilot = pilot_train(hR_test, hI_test, K, M, L)\n",
    "            UE_Feedback = ue_dnn(y_pilot)\n",
    "            rate_MRT = bs_dnn(UE_Feedback, h_test, noise_std_dl, MRT = True)\n",
    "            loss_MRT = Lossfunc(rate_MRT)\n",
    "        \n",
    "        if loss_ZF < best_loss:\n",
    "            best_loss = loss_ZF\n",
    "            \n",
    "            torch.save({\n",
    "                'pilot_train' : pilot_train.state_dict(),\n",
    "                'bs_dnn' : bs_dnn.state_dict(),\n",
    "                'ue_dnn' : ue_dnn.state_dict(),\n",
    "                'optimizer' : optimizer.state_dict(),\n",
    "                'best_loss' : best_loss\n",
    "            }, save_path)\n",
    "            \n",
    "            print(f\"✅ Model saved at epoch {epoch}, Loss: {best_loss:.5f}\")\n",
    "        else:\n",
    "            anneal_param = anneal_param*annealing_rate\n",
    "        print('epoch',epoch,' anneal_param:%4.4f'%anneal_param)\n",
    "        print('         loss_test:%2.5f'%-loss_ZF,'  best_test:%2.5f'%-best_loss)\n",
    "        \n",
    "y_pilot = pilot_train(hR_test_Final, hI_test_Final, K, M, L)\n",
    "UE_Feedback = ue_dnn(y_pilot)\n",
    "rate_MRT = bs_dnn(UE_Feedback, h_test_Final, noise_std_dl, MRT = True)\n",
    "loss_MRT = Lossfunc(rate_MRT)\n",
    "\n",
    "print(-loss_ZF_Final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['__header__', '__version__', '__globals__', 'h_act_test_Final', 'hR_act_test_Final', 'hI_act_test_Final', 'alpha_act_test_Final', 'theta_act_test_Final'])\n"
     ]
    }
   ],
   "source": [
    "print(AA.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "acnl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
