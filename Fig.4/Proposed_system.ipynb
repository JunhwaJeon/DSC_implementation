{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "import scipy.linalg as sci\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "## System parameters\n",
    "M = 64 #Number of BS antennas\n",
    "P = 1 #Power\n",
    "K =  2 #Number of users\n",
    "L = 8 #Number of pilots\n",
    "Lp = 2 #Number of paths\n",
    "B = 30 #Number of feedback bits per user\n",
    "\n",
    "## Limited scattering channel parameters\n",
    "LSF_UE = np.array([0.0,0.0],dtype=np.float32) #Mean of path gains for K users\n",
    "Mainlobe_UE= np.array([0,0],dtype=np.float32) #Center of the AoD range for K users\n",
    "HalfBW_UE = np.array([30.0,30.0],dtype=np.float32) #Half of the AoD range for K users\n",
    "\n",
    "# SNR\n",
    "snr_dl = 10 #SNR in dB\n",
    "noise_std_dl = np.float32(np.sqrt(1/2)*np.sqrt(P/10**(snr_dl/10))) #STD of the Gaussian noise (per real dim.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Learning parameters\n",
    "initial_run = 1 #1: starts training from scratch; 0: resumes training \n",
    "n_epochs = 5000 #Number of training epochs, for observing the current performance set it to 0\n",
    "learning_rate = 0.0001 #Learning rate\n",
    "\n",
    "batch_size = 1024 #Mini-batch size\n",
    "test_size = 10000 #Size of the validation/test set\n",
    "batch_per_epoch = 20 #Numbers of mini-batches per epoch\n",
    "\n",
    "anneal_param = 1.0 #Initial annealing parmeter\n",
    "annealing_rate = 1.001 #Annealing rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pilot Sequence 초기화 -- DFT Matrix 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "DFT_Matrix = sci.dft(M) \n",
    "X_init = DFT_Matrix[0::int(np.ceil(M/L)),:] \n",
    "Xp_init = np.sqrt(P/M)*X_init\n",
    "Xp_r_init = torch.Tensor(np.float32(np.real(Xp_init))).to(device)\n",
    "Xp_i_init = torch.Tensor(np.float32(np.imag(Xp_init))).to(device)\n",
    "## Pilot sequence cuda 지정 완료"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix 연산 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mult_mod(M, N, left_right):\n",
    "    tensor_shape = M.shape\n",
    "    dims = N.shape \n",
    "\n",
    "    if left_right == 'r':\n",
    "        # M: (batch_size, n, m) N: (m, p)\n",
    "        n = tensor_shape[1]\n",
    "        m = dims[0]\n",
    "        p = dims[1]\n",
    "\n",
    "        # PyTorch의 행렬 곱\n",
    "        y = torch.reshape(torch.matmul(M.view(-1, m), N), (-1, n, p))\n",
    "\n",
    "    elif left_right == 'l':\n",
    "        # M: (batch_size, n, m)\n",
    "        # N: (p, n)\n",
    "        m = tensor_shape[2]\n",
    "        p = dims[0]\n",
    "        n = dims[1]\n",
    "\n",
    "        # PyTorch에서는 `permute()`로 전치 가능\n",
    "        MT = torch.Tensor(M).permute(0, 2, 1)  # (batch_size, m, n)\n",
    "        NT = N.T  # (n, p)\n",
    "\n",
    "        MTNT = torch.reshape(torch.matmul(MT.view(-1, n), NT), (-1, m, p))\n",
    "        y = MTNT.permute(0, 2, 1)  # (batch_size, n, p)로 변환\n",
    "\n",
    "    return y.to(device)\n",
    "\n",
    "def mult_mod_complex(Mr, Mi, Nr, Ni, left_right):\n",
    "    yr = mult_mod(Mr, Nr, left_right) - mult_mod(Mi, Ni, left_right)\n",
    "    yi = mult_mod(Mr, Ni, left_right) + mult_mod(Mi, Nr, left_right)\n",
    "    return yr.to(device), yi.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch data 생성 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 리스트 인덱싱은 [층, 행, 열], [행, 열]임!\n",
    "def generate_batch_data(batch_size,M,K,\n",
    "                        Lp,#number of paths\n",
    "                        LSF_UE #Mean of path gains for K users\n",
    "                        ,Mainlobe_UE #Center of the AoD range for K users\n",
    "                        ,HalfBW_UE #Half of the AoD range for K users\n",
    "                        ):\n",
    "    alphaR_input = np.zeros((batch_size,Lp,K))\n",
    "    alphaI_input = np.zeros((batch_size,Lp,K))\n",
    "    theta_input = np.zeros((batch_size,Lp,K))\n",
    "    for kk in range(K): # for the number of users\n",
    "        alphaR_input[:,:,kk] = np.random.normal(loc=LSF_UE[kk], scale=1.0/np.sqrt(2), size=[batch_size,Lp])\n",
    "        alphaI_input[:,:,kk] = np.random.normal(loc=LSF_UE[kk], scale=1.0/np.sqrt(2), size=[batch_size,Lp])\n",
    "        theta_input[:,:,kk] = np.random.uniform(low=Mainlobe_UE[kk]-HalfBW_UE[kk], high=Mainlobe_UE[kk]+HalfBW_UE[kk], size=[batch_size,Lp])\n",
    " \n",
    "    #### Actual Channel\n",
    "    from0toM = np.float32(np.arange(0, M, 1))\n",
    "    alpha_act = alphaR_input + 1j*alphaI_input\n",
    "    theta_act = (np.pi/180)*theta_input\n",
    "    \n",
    "    h_act = np.complex128(np.zeros((batch_size,M,K)))\n",
    "    hR_act = np.float32(np.zeros((batch_size,M,K)))\n",
    "    hI_act = np.float32(np.zeros((batch_size,M,K)))\n",
    "    \n",
    "    for kk in range(K):\n",
    "        for ll in range(Lp):\n",
    "            theta_act_expanded_temp = np.tile(np.reshape(theta_act[:,ll,kk],[-1,1]),(1,M))\n",
    "            response_temp = np.exp(1j*np.pi*np.multiply(np.sin(theta_act_expanded_temp),from0toM))\n",
    "            alpha_temp = np.reshape(alpha_act[:,ll,kk],[-1,1])\n",
    "            h_act[:,:,kk] += (1/np.sqrt(Lp))*alpha_temp*response_temp\n",
    "        hR_act[:,:,kk] = np.real(h_act[:,:,kk])\n",
    "        hI_act[:,:,kk] = np.imag(h_act[:,:,kk])\n",
    "        \n",
    "    h_act = torch.tensor(h_act).to(device)\n",
    "    hR_act = torch.tensor(hR_act).to(device)\n",
    "    hI_act = torch.tensor(hI_act).to(device)\n",
    "        \n",
    "    return(h_act, hR_act, hI_act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가중치 초기화 함수 정의 (He 초기화)\n",
    "def he_init(tensor):\n",
    "    init.kaiming_normal_(tensor, mode='fan_in', nonlinearity='relu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력 데이터 텐서\n",
    "hR = torch.randn((batch_size, M, K), dtype=torch.float32)  # 실수 채널 행렬\n",
    "hI = torch.randn((batch_size, M, K), dtype=torch.float32)  # 허수 채널 행렬"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rate 계산 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rate_func(hr, hi, vr, vi, noise_power, K, M, k_index): # 실제 사용 시 k번째 루프 값에 대한 값 입력\n",
    "    ## 채널 입력은 각 user에 대한 것 : (batch_size, M)\n",
    "    ## Precoding matrix 형태로 바꿔주기 (batch_size, M, K)\n",
    "    vr = vr.reshape(-1, M, K) \n",
    "    vi = vi.reshape(-1, M, K)\n",
    "    \n",
    "    nom_denom = torch.zeros_like(torch.tensor(hr[:, :]).clone().detach()).to(device) + torch.tensor(noise_power).to(device)  # 초기화\n",
    "\n",
    "    for kk in range(K): # k번째 user에 대한 power 계산\n",
    "        hrvr = torch.bmm(torch.tensor(hr).clone().unsqueeze(-1).permute(0, 2, 1), vr[:, :, kk].clone().unsqueeze(-1)).squeeze(-1)\n",
    "        hivi = torch.bmm(torch.tensor(hi).clone().unsqueeze(-1).permute(0, 2, 1), vi[:, :, kk].clone().unsqueeze(-1)).squeeze(-1)\n",
    "        hrvi = torch.bmm(torch.tensor(hr).clone().unsqueeze(-1).permute(0, 2, 1), vi[:, :, kk].clone().unsqueeze(-1)).squeeze(-1)\n",
    "        hivr = torch.bmm(torch.tensor(hi).clone().unsqueeze(-1).permute(0, 2, 1), vr[:, :, kk].clone().unsqueeze(-1)).squeeze(-1)\n",
    "\n",
    "        real_part = hrvr - hivi \n",
    "        imag_part = hrvi + hivr\n",
    "        norm2_hv = real_part.abs()**2 + imag_part.abs()**2 \n",
    "\n",
    "        if kk == k_index:\n",
    "            nom = norm2_hv  # Wanted signal power\n",
    "        nom_denom += norm2_hv # Unwanted signal power\n",
    "\n",
    "    denom = nom_denom - nom\n",
    "    rate = torch.log2(1 + (nom / denom))\n",
    "    \n",
    "    return -rate.to(device)  # 손실 최소화를 위해 음수 처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downlink Pilot Training -- Pilot Sequence as DNN parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "## hR, hI 만 cuda로 들어가면 됨됨\n",
    "class DLTrainingPhase(nn.Module):\n",
    "    def __init__(self, P, noise_std_dl):\n",
    "        super(DLTrainingPhase, self).__init__()\n",
    "        \n",
    "        # noise/annealing parameter\n",
    "        self.noise_std = torch.tensor(noise_std_dl, dtype=torch.float32).to(device)\n",
    "        self.aneal = torch.tensor(1.0, dtype=torch.float32).to(device)\n",
    "        \n",
    "        # Pilot sequence - Use pre-initialized values\n",
    "        self.Xp_r = nn.Parameter(Xp_r_init.clone().to(device))\n",
    "        self.Xp_i = nn.Parameter(Xp_i_init.clone().to(device))\n",
    "        \n",
    "        # Power normalizing\n",
    "        self.P = P\n",
    "        self.normalize_pilot()\n",
    "        \n",
    "    def normalize_pilot(self):\n",
    "        # Function : Normalizing the pilot sequence vectors\n",
    "        norm_X = torch.sqrt(torch.sum(self.Xp_r**2 + self.Xp_i**2, dim = 1, keepdim = True)) # (. , * , . ) *에 대해 sum 수행\n",
    "        self.Xp_r.data = torch.sqrt(torch.tensor(self.P)) * (self.Xp_r / norm_X)   \n",
    "        self.Xp_i.data = torch.sqrt(torch.tensor(self.P)) * (self.Xp_i / norm_X)\n",
    "        \n",
    "    def forward(self, hR, hI, K, M, L):\n",
    "        y_nless = {}\n",
    "        y_noisy = {}\n",
    "        \n",
    "        for kk in range(K):\n",
    "            hR_temp = hR[:, :, kk].reshape(-1, M, 1) # 차원 (batch_size, M)\n",
    "            hI_temp = hI[:, :, kk].reshape(-1, M, 1)\n",
    "\n",
    "            # 복소수 행렬 곱 수행\n",
    "            y_nless_r, y_nless_i = mult_mod_complex(hR_temp, hI_temp, self.Xp_r, self.Xp_i, 'l')\n",
    "\n",
    "            # 실수 및 허수 결합 -> 복소수로 결합 아니고 real representation\n",
    "            y_nless[kk] = torch.cat([y_nless_r.view(-1, L), y_nless_i.view(-1, L)], dim=1)\n",
    "\n",
    "            # 가우시안 노이즈 추가\n",
    "            noise = torch.randn_like(y_nless[kk]) * self.noise_std\n",
    "            y_noisy[kk] = y_nless[kk] + noise\n",
    "        \n",
    "        return y_noisy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UE side DNN - Quantizer for CSI feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UE_DNN(nn.Module):\n",
    "    def __init__(self, L, B, K, anneal = 1.0):\n",
    "        super(UE_DNN, self).__init__()\n",
    "        self.anneal = anneal\n",
    "        self.input_dim = 2*L\n",
    "        self.K=K\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            nn.BatchNorm1d(self.input_dim),\n",
    "            nn.Linear(self.input_dim, 1024),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Linear(256, B)\n",
    "        )\n",
    "        self.model.to(device)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        InfoBits = {0:0}\n",
    "        for kk in range(self.K):\n",
    "            InfoBits_linear = self.model(x[kk])  # 신경망을 통과한 값\n",
    "\n",
    "            # Straight-Through Estimator (STE) 적용\n",
    "            InfoBits_tanh = torch.tanh(self.anneal * InfoBits_linear)\n",
    "            InfoBits_sign = torch.sign(InfoBits_linear)\n",
    "\n",
    "            # Forward: Sign 값을 사용, Backward: Tanh gradient 사용\n",
    "            InfoBits[kk] = InfoBits_tanh + (InfoBits_sign - InfoBits_tanh).detach()\n",
    "        \n",
    "        return InfoBits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BS side DNN - Precoder network of DSC structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BS_DNN(nn.Module):\n",
    "    def __init__(self, M, K, B, P):\n",
    "        super(BS_DNN, self).__init__()\n",
    "        self.M = M\n",
    "        self.K = K\n",
    "        self.B = B\n",
    "        self.P = P\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(K * B, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Linear(512, 2* M * K)  # Precoder 출력 (실수 및 허수 파트)\n",
    "        )\n",
    "        \n",
    "        self.model.to(device)\n",
    "    \n",
    "    def forward(self, DNN_input_BS, hR, hI, noise_std):\n",
    "        # DNN_input_BS : UE에서 생성한 정보 입력 - (batch_size, K * B)\n",
    "        # hR, hI : channel matrix - (batch_size, M, K) - real/imag part\n",
    "        \n",
    "        #batch_size = DNN_input_BS[0].shape()\n",
    "        \n",
    "        # 0. Precoder input 생성\n",
    "        for kk in range(self.K):\n",
    "            if kk == 0:\n",
    "                precoder_input = DNN_input_BS[0]\n",
    "            else:\n",
    "                precoder_input = torch.concat((precoder_input, DNN_input_BS[kk]), dim = 1)\n",
    "        \n",
    "        # 1. Generate the precoder\n",
    "        precoder_output = self.model(precoder_input) # (batch_size, 2*M*K)\n",
    "        \n",
    "        # 2. seperate real/imag part\n",
    "        V_r, V_i = torch.chunk(precoder_output, 2, dim=1)\n",
    "        \n",
    "        # 3. power normalization\n",
    "        norm_V = torch.sqrt(torch.sum(V_r**2 + V_i**2, dim=1, keepdim=True))\n",
    "        V_r = np.sqrt(self.P) * (V_r / norm_V)\n",
    "        V_i = np.sqrt(self.P) * (V_i / norm_V)\n",
    "        \n",
    "        # 4. calculate sum rate\n",
    "        rate = {}\n",
    "        for kk in range(self.K):\n",
    "            rate[kk] = self.compute_rate(hR[:, :, kk], hI[:, :, kk], V_r, V_i, 2*noise_std**2, K, M, kk)\n",
    "            \n",
    "        # 5. MRT (Maximum Ratio Transmission) 기반 Baseline 계산\n",
    "        rate_UP = self.compute_mrt_baseline(hR, hI, noise_std)\n",
    "\n",
    "        return rate, rate_UP\n",
    "    \n",
    "    def compute_rate(self, hR_kk, hI_kk, V_r, V_i, noise_power, K, M, kk):\n",
    "        \n",
    "        # 채널 용량(Rate) 계산을 위한 함수\n",
    "        # hR_kk, hI_kk: 특정 사용자 kk에 대한 채널 정보\n",
    "        # V_r, V_i: Precoder의 실수 및 허수 부분\n",
    "        \n",
    "        # 여기에 Rate_func을 PyTorch로 변환하여 사용 가능\n",
    "        return rate_func(hR_kk, hI_kk, V_r, V_i, noise_power, K, M, kk)\n",
    "\n",
    "    def compute_mrt_baseline(self, hR, hI, noise_std):\n",
    "        \"\"\"\n",
    "        MRT (Maximum Ratio Transmission) 기반 Precoder 계산\n",
    "        \"\"\"\n",
    "        #batch_size = hR.shape[0]\n",
    "\n",
    "        # MRT Precoder 계산\n",
    "        h_complex = torch.complex(torch.tensor(hR), torch.tensor(hI))  # 복소수 채널 행렬 생성\n",
    "        V_MRT = h_complex.conj()  # 복소수 켤레 취함 (MRT 연산)\n",
    "\n",
    "        # 실수 및 허수 부분 분리\n",
    "        V_MRT_r = V_MRT.real\n",
    "        V_MRT_i = V_MRT.imag\n",
    "\n",
    "        # 전력 정규화 수행\n",
    "        norm_V_MRT = torch.sqrt(torch.sum(V_MRT_r**2 + V_MRT_i**2, dim=1, keepdim=True))\n",
    "        V_MRT_r = np.sqrt(self.P) * (V_MRT_r / norm_V_MRT)\n",
    "        V_MRT_i = np.sqrt(self.P) * (V_MRT_i / norm_V_MRT)\n",
    "\n",
    "        # 채널 용량(Rate) 계산\n",
    "        rate_UP = {}\n",
    "        for kk in range(self.K):\n",
    "            rate_UP[kk] = self.compute_rate(hR[:, :, kk], hI[:, :, kk], V_MRT_r, V_MRT_i, 2 * noise_std**2, self.K, self.M, kk)\n",
    "\n",
    "        return rate_UP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "pilot_train = DLTrainingPhase(P, noise_std_dl)\n",
    "ue_dnn = UE_DNN(L, B, K, annealing_rate)\n",
    "bs_dnn = BS_DNN(M, K, B, P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 학습하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loss function 정의\n",
    "class CustomLoss(nn.Module):\n",
    "    def __init__(self, K):\n",
    "        super(CustomLoss, self).__init__()\n",
    "        self.K = K\n",
    "    \n",
    "    def forward(self, rate, rate_UP):\n",
    "        rate_total = sum(rate[k] for k in range(self.K))\n",
    "        rate_UP_total = sum(rate_UP[k] for k in range(self.K))\n",
    "        \n",
    "        loss = torch.mean(rate_total)\n",
    "        loss_UP = torch.mean(rate_UP_total)\n",
    "        \n",
    "        return loss, loss_UP\n",
    "    \n",
    "Lossfunc = CustomLoss(K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Optimizer 설정\n",
    "optimizer = optim.Adam(list(pilot_train.parameters())+list(ue_dnn.parameters())+list(bs_dnn.parameters())\n",
    "                       , lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\unist\\AppData\\Local\\Temp\\ipykernel_28744\\1094127546.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  hR_test = torch.tensor(hR_test, dtype=torch.float32).to(device)\n",
      "C:\\Users\\unist\\AppData\\Local\\Temp\\ipykernel_28744\\1094127546.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  hI_test = torch.tensor(hI_test, dtype=torch.float32).to(device)\n"
     ]
    }
   ],
   "source": [
    "## Test set 생성\n",
    "h_test, hR_test, hI_test = generate_batch_data(test_size, M, K, Lp, LSF_UE, Mainlobe_UE, HalfBW_UE)\n",
    "\n",
    "# Tensor 변환 후 GPU 할당\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "hR_test = torch.tensor(hR_test, dtype=torch.float32).to(device)\n",
    "hI_test = torch.tensor(hI_test, dtype=torch.float32).to(device)\n",
    "noise_std_test = torch.tensor(noise_std_dl, dtype=torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final dataset\n",
    "AA = sio.loadmat('Data_test_K2M64Lp2L8_withParams.mat')\n",
    "hR_test_Final = AA['hR_act_test_Final']\n",
    "hI_test_Final = AA['hI_act_test_Final']\n",
    "\n",
    "hR_test_Final = torch.tensor(hR_test_Final, dtype=torch.float32).to(device)\n",
    "hI_test_Final = torch.tensor(hI_test_Final, dtype=torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 초기 모델 저장 경로 설정\n",
    "save_path = './params.pth'\n",
    "\n",
    "# 모델 불러오기 (처음 실행 여부 확인)\n",
    "initial_run = 1\n",
    "if initial_run == 0:\n",
    "    checkpoint = torch.load(save_path)\n",
    "    pilot_train.load_state_dict(checkpoint['pilot_train'])\n",
    "    bs_dnn.load_state_dict(checkpoint['bs_dnn'])\n",
    "    ue_dnn.load_state_dict(checkpoint['ue_dnn'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    best_loss = checkpoint['best_loss']\n",
    "    print(\"✅ 모델 파라미터 불러오기 완료!\")\n",
    "else:\n",
    "    best_loss = float('inf')  # 초기 Best Loss 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\unist\\AppData\\Local\\Temp\\ipykernel_28744\\279148727.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nom_denom = torch.zeros_like(torch.tensor(hr[:, :]).clone().detach()).to(device) + torch.tensor(noise_power).to(device)  # 초기화\n",
      "C:\\Users\\unist\\AppData\\Local\\Temp\\ipykernel_28744\\279148727.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  hrvr = torch.bmm(torch.tensor(hr).clone().unsqueeze(-1).permute(0, 2, 1), vr[:, :, kk].clone().unsqueeze(-1)).squeeze(-1)\n",
      "C:\\Users\\unist\\AppData\\Local\\Temp\\ipykernel_28744\\279148727.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  hivi = torch.bmm(torch.tensor(hi).clone().unsqueeze(-1).permute(0, 2, 1), vi[:, :, kk].clone().unsqueeze(-1)).squeeze(-1)\n",
      "C:\\Users\\unist\\AppData\\Local\\Temp\\ipykernel_28744\\279148727.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  hrvi = torch.bmm(torch.tensor(hr).clone().unsqueeze(-1).permute(0, 2, 1), vi[:, :, kk].clone().unsqueeze(-1)).squeeze(-1)\n",
      "C:\\Users\\unist\\AppData\\Local\\Temp\\ipykernel_28744\\279148727.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  hivr = torch.bmm(torch.tensor(hi).clone().unsqueeze(-1).permute(0, 2, 1), vr[:, :, kk].clone().unsqueeze(-1)).squeeze(-1)\n",
      "C:\\Users\\unist\\AppData\\Local\\Temp\\ipykernel_28744\\4181443490.py:74: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  h_complex = torch.complex(torch.tensor(hR), torch.tensor(hI))  # 복소수 채널 행렬 생성\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model saved at epoch 0, Loss: -2.09202\n",
      "epoch 0  anneal_param:1.0000\n",
      "         loss_test:2.09202   best_test:2.09202   best_possible:14.47989  Percentage::0.144\n",
      "✅ Model saved at epoch 10, Loss: -5.28314\n",
      "epoch 10  anneal_param:1.0000\n",
      "         loss_test:5.28314   best_test:5.28314   best_possible:14.47989  Percentage::0.365\n",
      "✅ Model saved at epoch 20, Loss: -6.62420\n",
      "epoch 20  anneal_param:1.0000\n",
      "         loss_test:6.62420   best_test:6.62420   best_possible:14.47989  Percentage::0.457\n",
      "✅ Model saved at epoch 30, Loss: -7.37153\n",
      "epoch 30  anneal_param:1.0000\n",
      "         loss_test:7.37153   best_test:7.37153   best_possible:14.47989  Percentage::0.509\n",
      "✅ Model saved at epoch 40, Loss: -8.01732\n",
      "epoch 40  anneal_param:1.0000\n",
      "         loss_test:8.01732   best_test:8.01732   best_possible:14.47989  Percentage::0.554\n",
      "✅ Model saved at epoch 50, Loss: -8.67364\n",
      "epoch 50  anneal_param:1.0000\n",
      "         loss_test:8.67364   best_test:8.67364   best_possible:14.47989  Percentage::0.599\n",
      "✅ Model saved at epoch 60, Loss: -9.20288\n",
      "epoch 60  anneal_param:1.0000\n",
      "         loss_test:9.20288   best_test:9.20288   best_possible:14.47989  Percentage::0.636\n",
      "✅ Model saved at epoch 70, Loss: -9.55726\n",
      "epoch 70  anneal_param:1.0000\n",
      "         loss_test:9.55726   best_test:9.55726   best_possible:14.47989  Percentage::0.660\n",
      "✅ Model saved at epoch 80, Loss: -9.80295\n",
      "epoch 80  anneal_param:1.0000\n",
      "         loss_test:9.80295   best_test:9.80295   best_possible:14.47989  Percentage::0.677\n",
      "✅ Model saved at epoch 90, Loss: -10.05657\n",
      "epoch 90  anneal_param:1.0000\n",
      "         loss_test:10.05657   best_test:10.05657   best_possible:14.47989  Percentage::0.695\n",
      "✅ Model saved at epoch 100, Loss: -10.24614\n",
      "epoch 100  anneal_param:1.0000\n",
      "         loss_test:10.24614   best_test:10.24614   best_possible:14.47989  Percentage::0.708\n",
      "✅ Model saved at epoch 110, Loss: -10.47447\n",
      "epoch 110  anneal_param:1.0000\n",
      "         loss_test:10.47447   best_test:10.47447   best_possible:14.47989  Percentage::0.723\n",
      "✅ Model saved at epoch 120, Loss: -10.63735\n",
      "epoch 120  anneal_param:1.0000\n",
      "         loss_test:10.63735   best_test:10.63735   best_possible:14.47989  Percentage::0.735\n",
      "✅ Model saved at epoch 130, Loss: -10.79183\n",
      "epoch 130  anneal_param:1.0000\n",
      "         loss_test:10.79183   best_test:10.79183   best_possible:14.47989  Percentage::0.745\n",
      "✅ Model saved at epoch 140, Loss: -10.92374\n",
      "epoch 140  anneal_param:1.0000\n",
      "         loss_test:10.92374   best_test:10.92374   best_possible:14.47989  Percentage::0.754\n",
      "✅ Model saved at epoch 150, Loss: -11.05479\n",
      "epoch 150  anneal_param:1.0000\n",
      "         loss_test:11.05479   best_test:11.05479   best_possible:14.47989  Percentage::0.763\n",
      "✅ Model saved at epoch 160, Loss: -11.17695\n",
      "epoch 160  anneal_param:1.0000\n",
      "         loss_test:11.17695   best_test:11.17695   best_possible:14.47989  Percentage::0.772\n",
      "✅ Model saved at epoch 170, Loss: -11.30030\n",
      "epoch 170  anneal_param:1.0000\n",
      "         loss_test:11.30030   best_test:11.30030   best_possible:14.47989  Percentage::0.780\n",
      "✅ Model saved at epoch 180, Loss: -11.41715\n",
      "epoch 180  anneal_param:1.0000\n",
      "         loss_test:11.41715   best_test:11.41715   best_possible:14.47989  Percentage::0.788\n",
      "✅ Model saved at epoch 190, Loss: -11.52281\n",
      "epoch 190  anneal_param:1.0000\n",
      "         loss_test:11.52281   best_test:11.52281   best_possible:14.47989  Percentage::0.796\n",
      "✅ Model saved at epoch 200, Loss: -11.63788\n",
      "epoch 200  anneal_param:1.0000\n",
      "         loss_test:11.63788   best_test:11.63788   best_possible:14.47989  Percentage::0.804\n",
      "✅ Model saved at epoch 210, Loss: -11.73314\n",
      "epoch 210  anneal_param:1.0000\n",
      "         loss_test:11.73314   best_test:11.73314   best_possible:14.47989  Percentage::0.810\n",
      "✅ Model saved at epoch 220, Loss: -11.81356\n",
      "epoch 220  anneal_param:1.0000\n",
      "         loss_test:11.81356   best_test:11.81356   best_possible:14.47989  Percentage::0.816\n",
      "✅ Model saved at epoch 230, Loss: -11.88408\n",
      "epoch 230  anneal_param:1.0000\n",
      "         loss_test:11.88408   best_test:11.88408   best_possible:14.47989  Percentage::0.821\n",
      "✅ Model saved at epoch 240, Loss: -11.97679\n",
      "epoch 240  anneal_param:1.0000\n",
      "         loss_test:11.97679   best_test:11.97679   best_possible:14.47989  Percentage::0.827\n",
      "✅ Model saved at epoch 250, Loss: -12.01340\n",
      "epoch 250  anneal_param:1.0000\n",
      "         loss_test:12.01340   best_test:12.01340   best_possible:14.47989  Percentage::0.830\n",
      "✅ Model saved at epoch 260, Loss: -12.10695\n",
      "epoch 260  anneal_param:1.0000\n",
      "         loss_test:12.10695   best_test:12.10695   best_possible:14.47989  Percentage::0.836\n",
      "✅ Model saved at epoch 270, Loss: -12.14129\n",
      "epoch 270  anneal_param:1.0000\n",
      "         loss_test:12.14129   best_test:12.14129   best_possible:14.47989  Percentage::0.838\n",
      "✅ Model saved at epoch 280, Loss: -12.18744\n",
      "epoch 280  anneal_param:1.0000\n",
      "         loss_test:12.18744   best_test:12.18744   best_possible:14.47989  Percentage::0.842\n",
      "✅ Model saved at epoch 290, Loss: -12.28574\n",
      "epoch 290  anneal_param:1.0000\n",
      "         loss_test:12.28574   best_test:12.28574   best_possible:14.47989  Percentage::0.848\n",
      "✅ Model saved at epoch 300, Loss: -12.33691\n",
      "epoch 300  anneal_param:1.0000\n",
      "         loss_test:12.33691   best_test:12.33691   best_possible:14.47989  Percentage::0.852\n",
      "✅ Model saved at epoch 310, Loss: -12.40342\n",
      "epoch 310  anneal_param:1.0000\n",
      "         loss_test:12.40342   best_test:12.40342   best_possible:14.47989  Percentage::0.857\n",
      "✅ Model saved at epoch 320, Loss: -12.45298\n",
      "epoch 320  anneal_param:1.0000\n",
      "         loss_test:12.45298   best_test:12.45298   best_possible:14.47989  Percentage::0.860\n",
      "✅ Model saved at epoch 330, Loss: -12.50124\n",
      "epoch 330  anneal_param:1.0000\n",
      "         loss_test:12.50124   best_test:12.50124   best_possible:14.47989  Percentage::0.863\n",
      "✅ Model saved at epoch 340, Loss: -12.54948\n",
      "epoch 340  anneal_param:1.0000\n",
      "         loss_test:12.54948   best_test:12.54948   best_possible:14.47989  Percentage::0.867\n",
      "✅ Model saved at epoch 350, Loss: -12.61722\n",
      "epoch 350  anneal_param:1.0000\n",
      "         loss_test:12.61722   best_test:12.61722   best_possible:14.47989  Percentage::0.871\n",
      "✅ Model saved at epoch 360, Loss: -12.67601\n",
      "epoch 360  anneal_param:1.0000\n",
      "         loss_test:12.67601   best_test:12.67601   best_possible:14.47989  Percentage::0.875\n",
      "✅ Model saved at epoch 370, Loss: -12.73613\n",
      "epoch 370  anneal_param:1.0000\n",
      "         loss_test:12.73613   best_test:12.73613   best_possible:14.47989  Percentage::0.880\n",
      "✅ Model saved at epoch 380, Loss: -12.77711\n",
      "epoch 380  anneal_param:1.0000\n",
      "         loss_test:12.77711   best_test:12.77711   best_possible:14.47989  Percentage::0.882\n",
      "✅ Model saved at epoch 390, Loss: -12.83659\n",
      "epoch 390  anneal_param:1.0000\n",
      "         loss_test:12.83659   best_test:12.83659   best_possible:14.47989  Percentage::0.887\n",
      "✅ Model saved at epoch 400, Loss: -12.88848\n",
      "epoch 400  anneal_param:1.0000\n",
      "         loss_test:12.88848   best_test:12.88848   best_possible:14.47989  Percentage::0.890\n",
      "✅ Model saved at epoch 410, Loss: -12.94701\n",
      "epoch 410  anneal_param:1.0000\n",
      "         loss_test:12.94701   best_test:12.94701   best_possible:14.47989  Percentage::0.894\n",
      "✅ Model saved at epoch 420, Loss: -12.98960\n",
      "epoch 420  anneal_param:1.0000\n",
      "         loss_test:12.98960   best_test:12.98960   best_possible:14.47989  Percentage::0.897\n",
      "✅ Model saved at epoch 430, Loss: -13.03412\n",
      "epoch 430  anneal_param:1.0000\n",
      "         loss_test:13.03412   best_test:13.03412   best_possible:14.47989  Percentage::0.900\n",
      "✅ Model saved at epoch 440, Loss: -13.06519\n",
      "epoch 440  anneal_param:1.0000\n",
      "         loss_test:13.06519   best_test:13.06519   best_possible:14.47989  Percentage::0.902\n",
      "✅ Model saved at epoch 450, Loss: -13.09811\n",
      "epoch 450  anneal_param:1.0000\n",
      "         loss_test:13.09811   best_test:13.09811   best_possible:14.47989  Percentage::0.905\n",
      "✅ Model saved at epoch 460, Loss: -13.14712\n",
      "epoch 460  anneal_param:1.0000\n",
      "         loss_test:13.14712   best_test:13.14712   best_possible:14.47989  Percentage::0.908\n",
      "✅ Model saved at epoch 470, Loss: -13.16706\n",
      "epoch 470  anneal_param:1.0000\n",
      "         loss_test:13.16706   best_test:13.16706   best_possible:14.47989  Percentage::0.909\n",
      "✅ Model saved at epoch 480, Loss: -13.20333\n",
      "epoch 480  anneal_param:1.0000\n",
      "         loss_test:13.20333   best_test:13.20333   best_possible:14.47989  Percentage::0.912\n",
      "✅ Model saved at epoch 490, Loss: -13.23379\n",
      "epoch 490  anneal_param:1.0000\n",
      "         loss_test:13.23379   best_test:13.23379   best_possible:14.47989  Percentage::0.914\n",
      "✅ Model saved at epoch 500, Loss: -13.25369\n",
      "epoch 500  anneal_param:1.0000\n",
      "         loss_test:13.25369   best_test:13.25369   best_possible:14.47989  Percentage::0.915\n",
      "✅ Model saved at epoch 510, Loss: -13.26913\n",
      "epoch 510  anneal_param:1.0000\n",
      "         loss_test:13.26913   best_test:13.26913   best_possible:14.47989  Percentage::0.916\n",
      "✅ Model saved at epoch 520, Loss: -13.29429\n",
      "epoch 520  anneal_param:1.0000\n",
      "         loss_test:13.29429   best_test:13.29429   best_possible:14.47989  Percentage::0.918\n",
      "✅ Model saved at epoch 530, Loss: -13.30755\n",
      "epoch 530  anneal_param:1.0000\n",
      "         loss_test:13.30755   best_test:13.30755   best_possible:14.47989  Percentage::0.919\n",
      "✅ Model saved at epoch 540, Loss: -13.32609\n",
      "epoch 540  anneal_param:1.0000\n",
      "         loss_test:13.32609   best_test:13.32609   best_possible:14.47989  Percentage::0.920\n",
      "✅ Model saved at epoch 550, Loss: -13.35879\n",
      "epoch 550  anneal_param:1.0000\n",
      "         loss_test:13.35879   best_test:13.35879   best_possible:14.47989  Percentage::0.923\n",
      "✅ Model saved at epoch 560, Loss: -13.37724\n",
      "epoch 560  anneal_param:1.0000\n",
      "         loss_test:13.37724   best_test:13.37724   best_possible:14.47989  Percentage::0.924\n",
      "✅ Model saved at epoch 570, Loss: -13.39469\n",
      "epoch 570  anneal_param:1.0000\n",
      "         loss_test:13.39469   best_test:13.39469   best_possible:14.47989  Percentage::0.925\n",
      "✅ Model saved at epoch 580, Loss: -13.40704\n",
      "epoch 580  anneal_param:1.0000\n",
      "         loss_test:13.40704   best_test:13.40704   best_possible:14.47989  Percentage::0.926\n",
      "✅ Model saved at epoch 590, Loss: -13.44164\n",
      "epoch 590  anneal_param:1.0000\n",
      "         loss_test:13.44164   best_test:13.44164   best_possible:14.47989  Percentage::0.928\n",
      "epoch 600  anneal_param:1.0010\n",
      "         loss_test:13.43474   best_test:13.44164   best_possible:14.47989  Percentage::0.928\n",
      "✅ Model saved at epoch 610, Loss: -13.45800\n",
      "epoch 610  anneal_param:1.0010\n",
      "         loss_test:13.45800   best_test:13.45800   best_possible:14.47989  Percentage::0.929\n",
      "✅ Model saved at epoch 620, Loss: -13.48345\n",
      "epoch 620  anneal_param:1.0010\n",
      "         loss_test:13.48345   best_test:13.48345   best_possible:14.47989  Percentage::0.931\n",
      "epoch 630  anneal_param:1.0020\n",
      "         loss_test:13.48140   best_test:13.48345   best_possible:14.47989  Percentage::0.931\n",
      "✅ Model saved at epoch 640, Loss: -13.51156\n",
      "epoch 640  anneal_param:1.0020\n",
      "         loss_test:13.51156   best_test:13.51156   best_possible:14.47989  Percentage::0.933\n",
      "✅ Model saved at epoch 650, Loss: -13.52528\n",
      "epoch 650  anneal_param:1.0020\n",
      "         loss_test:13.52528   best_test:13.52528   best_possible:14.47989  Percentage::0.934\n",
      "✅ Model saved at epoch 660, Loss: -13.54727\n",
      "epoch 660  anneal_param:1.0020\n",
      "         loss_test:13.54727   best_test:13.54727   best_possible:14.47989  Percentage::0.936\n",
      "✅ Model saved at epoch 670, Loss: -13.56340\n",
      "epoch 670  anneal_param:1.0020\n",
      "         loss_test:13.56340   best_test:13.56340   best_possible:14.47989  Percentage::0.937\n",
      "✅ Model saved at epoch 680, Loss: -13.59150\n",
      "epoch 680  anneal_param:1.0020\n",
      "         loss_test:13.59150   best_test:13.59150   best_possible:14.47989  Percentage::0.939\n",
      "epoch 690  anneal_param:1.0030\n",
      "         loss_test:13.58793   best_test:13.59150   best_possible:14.47989  Percentage::0.939\n",
      "✅ Model saved at epoch 700, Loss: -13.59515\n",
      "epoch 700  anneal_param:1.0030\n",
      "         loss_test:13.59515   best_test:13.59515   best_possible:14.47989  Percentage::0.939\n",
      "✅ Model saved at epoch 710, Loss: -13.62039\n",
      "epoch 710  anneal_param:1.0030\n",
      "         loss_test:13.62039   best_test:13.62039   best_possible:14.47989  Percentage::0.941\n",
      "✅ Model saved at epoch 720, Loss: -13.62268\n",
      "epoch 720  anneal_param:1.0030\n",
      "         loss_test:13.62268   best_test:13.62268   best_possible:14.47989  Percentage::0.941\n",
      "✅ Model saved at epoch 730, Loss: -13.63952\n",
      "epoch 730  anneal_param:1.0030\n",
      "         loss_test:13.63952   best_test:13.63952   best_possible:14.47989  Percentage::0.942\n",
      "✅ Model saved at epoch 740, Loss: -13.65882\n",
      "epoch 740  anneal_param:1.0030\n",
      "         loss_test:13.65882   best_test:13.65882   best_possible:14.47989  Percentage::0.943\n",
      "epoch 750  anneal_param:1.0040\n",
      "         loss_test:13.65606   best_test:13.65882   best_possible:14.47989  Percentage::0.943\n",
      "✅ Model saved at epoch 760, Loss: -13.66854\n",
      "epoch 760  anneal_param:1.0040\n",
      "         loss_test:13.66854   best_test:13.66854   best_possible:14.47989  Percentage::0.944\n",
      "✅ Model saved at epoch 770, Loss: -13.68697\n",
      "epoch 770  anneal_param:1.0040\n",
      "         loss_test:13.68697   best_test:13.68697   best_possible:14.47989  Percentage::0.945\n",
      "epoch 780  anneal_param:1.0050\n",
      "         loss_test:13.68130   best_test:13.68697   best_possible:14.47989  Percentage::0.945\n",
      "✅ Model saved at epoch 790, Loss: -13.69136\n",
      "epoch 790  anneal_param:1.0050\n",
      "         loss_test:13.69136   best_test:13.69136   best_possible:14.47989  Percentage::0.946\n",
      "✅ Model saved at epoch 800, Loss: -13.70555\n",
      "epoch 800  anneal_param:1.0050\n",
      "         loss_test:13.70555   best_test:13.70555   best_possible:14.47989  Percentage::0.947\n",
      "epoch 810  anneal_param:1.0060\n",
      "         loss_test:13.69706   best_test:13.70555   best_possible:14.47989  Percentage::0.947\n",
      "epoch 820  anneal_param:1.0070\n",
      "         loss_test:13.69478   best_test:13.70555   best_possible:14.47989  Percentage::0.947\n",
      "✅ Model saved at epoch 830, Loss: -13.70793\n",
      "epoch 830  anneal_param:1.0070\n",
      "         loss_test:13.70793   best_test:13.70793   best_possible:14.47989  Percentage::0.947\n",
      "✅ Model saved at epoch 840, Loss: -13.72023\n",
      "epoch 840  anneal_param:1.0070\n",
      "         loss_test:13.72023   best_test:13.72023   best_possible:14.47989  Percentage::0.948\n",
      "epoch 850  anneal_param:1.0080\n",
      "         loss_test:13.71700   best_test:13.72023   best_possible:14.47989  Percentage::0.948\n",
      "✅ Model saved at epoch 860, Loss: -13.74476\n",
      "epoch 860  anneal_param:1.0080\n",
      "         loss_test:13.74476   best_test:13.74476   best_possible:14.47989  Percentage::0.949\n",
      "epoch 870  anneal_param:1.0090\n",
      "         loss_test:13.73182   best_test:13.74476   best_possible:14.47989  Percentage::0.949\n",
      "epoch 880  anneal_param:1.0100\n",
      "         loss_test:13.74232   best_test:13.74476   best_possible:14.47989  Percentage::0.949\n",
      "epoch 890  anneal_param:1.0111\n",
      "         loss_test:13.73193   best_test:13.74476   best_possible:14.47989  Percentage::0.949\n",
      "✅ Model saved at epoch 900, Loss: -13.75480\n",
      "epoch 900  anneal_param:1.0111\n",
      "         loss_test:13.75480   best_test:13.75480   best_possible:14.47989  Percentage::0.950\n",
      "epoch 910  anneal_param:1.0121\n",
      "         loss_test:13.75023   best_test:13.75480   best_possible:14.47989  Percentage::0.950\n",
      "✅ Model saved at epoch 920, Loss: -13.76434\n",
      "epoch 920  anneal_param:1.0121\n",
      "         loss_test:13.76434   best_test:13.76434   best_possible:14.47989  Percentage::0.951\n",
      "✅ Model saved at epoch 930, Loss: -13.77120\n",
      "epoch 930  anneal_param:1.0121\n",
      "         loss_test:13.77120   best_test:13.77120   best_possible:14.47989  Percentage::0.951\n",
      "epoch 940  anneal_param:1.0131\n",
      "         loss_test:13.76992   best_test:13.77120   best_possible:14.47989  Percentage::0.951\n",
      "✅ Model saved at epoch 950, Loss: -13.78615\n",
      "epoch 950  anneal_param:1.0131\n",
      "         loss_test:13.78615   best_test:13.78615   best_possible:14.47989  Percentage::0.952\n",
      "epoch 960  anneal_param:1.0141\n",
      "         loss_test:13.78406   best_test:13.78615   best_possible:14.47989  Percentage::0.952\n",
      "✅ Model saved at epoch 970, Loss: -13.78702\n",
      "epoch 970  anneal_param:1.0141\n",
      "         loss_test:13.78702   best_test:13.78702   best_possible:14.47989  Percentage::0.952\n",
      "✅ Model saved at epoch 980, Loss: -13.79430\n",
      "epoch 980  anneal_param:1.0141\n",
      "         loss_test:13.79430   best_test:13.79430   best_possible:14.47989  Percentage::0.953\n",
      "✅ Model saved at epoch 990, Loss: -13.79541\n",
      "epoch 990  anneal_param:1.0141\n",
      "         loss_test:13.79541   best_test:13.79541   best_possible:14.47989  Percentage::0.953\n",
      "✅ Model saved at epoch 1000, Loss: -13.79588\n",
      "epoch 1000  anneal_param:1.0141\n",
      "         loss_test:13.79588   best_test:13.79588   best_possible:14.47989  Percentage::0.953\n",
      "✅ Model saved at epoch 1010, Loss: -13.81652\n",
      "epoch 1010  anneal_param:1.0141\n",
      "         loss_test:13.81652   best_test:13.81652   best_possible:14.47989  Percentage::0.954\n",
      "epoch 1020  anneal_param:1.0151\n",
      "         loss_test:13.81126   best_test:13.81652   best_possible:14.47989  Percentage::0.954\n",
      "epoch 1030  anneal_param:1.0161\n",
      "         loss_test:13.80928   best_test:13.81652   best_possible:14.47989  Percentage::0.954\n",
      "epoch 1040  anneal_param:1.0171\n",
      "         loss_test:13.80573   best_test:13.81652   best_possible:14.47989  Percentage::0.954\n",
      "✅ Model saved at epoch 1050, Loss: -13.82714\n",
      "epoch 1050  anneal_param:1.0171\n",
      "         loss_test:13.82714   best_test:13.82714   best_possible:14.47989  Percentage::0.955\n",
      "✅ Model saved at epoch 1060, Loss: -13.83564\n",
      "epoch 1060  anneal_param:1.0171\n",
      "         loss_test:13.83564   best_test:13.83564   best_possible:14.47989  Percentage::0.956\n",
      "epoch 1070  anneal_param:1.0182\n",
      "         loss_test:13.82117   best_test:13.83564   best_possible:14.47989  Percentage::0.956\n",
      "✅ Model saved at epoch 1080, Loss: -13.83926\n",
      "epoch 1080  anneal_param:1.0182\n",
      "         loss_test:13.83926   best_test:13.83926   best_possible:14.47989  Percentage::0.956\n",
      "✅ Model saved at epoch 1090, Loss: -13.85225\n",
      "epoch 1090  anneal_param:1.0182\n",
      "         loss_test:13.85225   best_test:13.85225   best_possible:14.47989  Percentage::0.957\n",
      "epoch 1100  anneal_param:1.0192\n",
      "         loss_test:13.84170   best_test:13.85225   best_possible:14.47989  Percentage::0.957\n",
      "epoch 1110  anneal_param:1.0202\n",
      "         loss_test:13.84501   best_test:13.85225   best_possible:14.47989  Percentage::0.957\n",
      "✅ Model saved at epoch 1120, Loss: -13.85294\n",
      "epoch 1120  anneal_param:1.0202\n",
      "         loss_test:13.85294   best_test:13.85294   best_possible:14.47989  Percentage::0.957\n",
      "epoch 1130  anneal_param:1.0212\n",
      "         loss_test:13.85119   best_test:13.85294   best_possible:14.47989  Percentage::0.957\n",
      "✅ Model saved at epoch 1140, Loss: -13.86590\n",
      "epoch 1140  anneal_param:1.0212\n",
      "         loss_test:13.86590   best_test:13.86590   best_possible:14.47989  Percentage::0.958\n",
      "epoch 1150  anneal_param:1.0222\n",
      "         loss_test:13.85522   best_test:13.86590   best_possible:14.47989  Percentage::0.958\n",
      "epoch 1160  anneal_param:1.0233\n",
      "         loss_test:13.86020   best_test:13.86590   best_possible:14.47989  Percentage::0.958\n",
      "✅ Model saved at epoch 1170, Loss: -13.87063\n",
      "epoch 1170  anneal_param:1.0233\n",
      "         loss_test:13.87063   best_test:13.87063   best_possible:14.47989  Percentage::0.958\n",
      "✅ Model saved at epoch 1180, Loss: -13.87525\n",
      "epoch 1180  anneal_param:1.0233\n",
      "         loss_test:13.87525   best_test:13.87525   best_possible:14.47989  Percentage::0.958\n",
      "epoch 1190  anneal_param:1.0243\n",
      "         loss_test:13.86088   best_test:13.87525   best_possible:14.47989  Percentage::0.958\n",
      "epoch 1200  anneal_param:1.0253\n",
      "         loss_test:13.87142   best_test:13.87525   best_possible:14.47989  Percentage::0.958\n",
      "✅ Model saved at epoch 1210, Loss: -13.89107\n",
      "epoch 1210  anneal_param:1.0253\n",
      "         loss_test:13.89107   best_test:13.89107   best_possible:14.47989  Percentage::0.959\n",
      "epoch 1220  anneal_param:1.0263\n",
      "         loss_test:13.88373   best_test:13.89107   best_possible:14.47989  Percentage::0.959\n",
      "epoch 1230  anneal_param:1.0274\n",
      "         loss_test:13.87451   best_test:13.89107   best_possible:14.47989  Percentage::0.959\n",
      "epoch 1240  anneal_param:1.0284\n",
      "         loss_test:13.88231   best_test:13.89107   best_possible:14.47989  Percentage::0.959\n",
      "epoch 1250  anneal_param:1.0294\n",
      "         loss_test:13.87967   best_test:13.89107   best_possible:14.47989  Percentage::0.959\n",
      "epoch 1260  anneal_param:1.0304\n",
      "         loss_test:13.88483   best_test:13.89107   best_possible:14.47989  Percentage::0.959\n",
      "✅ Model saved at epoch 1270, Loss: -13.89881\n",
      "epoch 1270  anneal_param:1.0304\n",
      "         loss_test:13.89881   best_test:13.89881   best_possible:14.47989  Percentage::0.960\n",
      "✅ Model saved at epoch 1280, Loss: -13.90494\n",
      "epoch 1280  anneal_param:1.0304\n",
      "         loss_test:13.90494   best_test:13.90494   best_possible:14.47989  Percentage::0.960\n",
      "epoch 1290  anneal_param:1.0315\n",
      "         loss_test:13.89677   best_test:13.90494   best_possible:14.47989  Percentage::0.960\n",
      "epoch 1300  anneal_param:1.0325\n",
      "         loss_test:13.89986   best_test:13.90494   best_possible:14.47989  Percentage::0.960\n",
      "epoch 1310  anneal_param:1.0335\n",
      "         loss_test:13.90482   best_test:13.90494   best_possible:14.47989  Percentage::0.960\n",
      "epoch 1320  anneal_param:1.0346\n",
      "         loss_test:13.90199   best_test:13.90494   best_possible:14.47989  Percentage::0.960\n",
      "✅ Model saved at epoch 1330, Loss: -13.90860\n",
      "epoch 1330  anneal_param:1.0346\n",
      "         loss_test:13.90860   best_test:13.90860   best_possible:14.47989  Percentage::0.961\n",
      "epoch 1340  anneal_param:1.0356\n",
      "         loss_test:13.90489   best_test:13.90860   best_possible:14.47989  Percentage::0.961\n",
      "✅ Model saved at epoch 1350, Loss: -13.91518\n",
      "epoch 1350  anneal_param:1.0356\n",
      "         loss_test:13.91518   best_test:13.91518   best_possible:14.47989  Percentage::0.961\n",
      "✅ Model saved at epoch 1360, Loss: -13.91732\n",
      "epoch 1360  anneal_param:1.0356\n",
      "         loss_test:13.91732   best_test:13.91732   best_possible:14.47989  Percentage::0.961\n",
      "✅ Model saved at epoch 1370, Loss: -13.92286\n",
      "epoch 1370  anneal_param:1.0356\n",
      "         loss_test:13.92286   best_test:13.92286   best_possible:14.47989  Percentage::0.962\n",
      "epoch 1380  anneal_param:1.0366\n",
      "         loss_test:13.91891   best_test:13.92286   best_possible:14.47989  Percentage::0.962\n",
      "✅ Model saved at epoch 1390, Loss: -13.93864\n",
      "epoch 1390  anneal_param:1.0366\n",
      "         loss_test:13.93864   best_test:13.93864   best_possible:14.47989  Percentage::0.963\n",
      "epoch 1400  anneal_param:1.0377\n",
      "         loss_test:13.92742   best_test:13.93864   best_possible:14.47989  Percentage::0.963\n",
      "epoch 1410  anneal_param:1.0387\n",
      "         loss_test:13.92069   best_test:13.93864   best_possible:14.47989  Percentage::0.963\n",
      "epoch 1420  anneal_param:1.0398\n",
      "         loss_test:13.92127   best_test:13.93864   best_possible:14.47989  Percentage::0.963\n",
      "✅ Model saved at epoch 1430, Loss: -13.93986\n",
      "epoch 1430  anneal_param:1.0398\n",
      "         loss_test:13.93986   best_test:13.93986   best_possible:14.47989  Percentage::0.963\n",
      "epoch 1440  anneal_param:1.0408\n",
      "         loss_test:13.93379   best_test:13.93986   best_possible:14.47989  Percentage::0.963\n",
      "epoch 1450  anneal_param:1.0418\n",
      "         loss_test:13.92269   best_test:13.93986   best_possible:14.47989  Percentage::0.963\n",
      "epoch 1460  anneal_param:1.0429\n",
      "         loss_test:13.92715   best_test:13.93986   best_possible:14.47989  Percentage::0.963\n",
      "epoch 1470  anneal_param:1.0439\n",
      "         loss_test:13.93765   best_test:13.93986   best_possible:14.47989  Percentage::0.963\n",
      "epoch 1480  anneal_param:1.0450\n",
      "         loss_test:13.93966   best_test:13.93986   best_possible:14.47989  Percentage::0.963\n",
      "epoch 1490  anneal_param:1.0460\n",
      "         loss_test:13.93582   best_test:13.93986   best_possible:14.47989  Percentage::0.963\n",
      "✅ Model saved at epoch 1500, Loss: -13.94100\n",
      "epoch 1500  anneal_param:1.0460\n",
      "         loss_test:13.94100   best_test:13.94100   best_possible:14.47989  Percentage::0.963\n",
      "✅ Model saved at epoch 1510, Loss: -13.94569\n",
      "epoch 1510  anneal_param:1.0460\n",
      "         loss_test:13.94569   best_test:13.94569   best_possible:14.47989  Percentage::0.963\n",
      "✅ Model saved at epoch 1520, Loss: -13.95266\n",
      "epoch 1520  anneal_param:1.0460\n",
      "         loss_test:13.95266   best_test:13.95266   best_possible:14.47989  Percentage::0.964\n",
      "epoch 1530  anneal_param:1.0471\n",
      "         loss_test:13.94247   best_test:13.95266   best_possible:14.47989  Percentage::0.964\n",
      "✅ Model saved at epoch 1540, Loss: -13.95878\n",
      "epoch 1540  anneal_param:1.0471\n",
      "         loss_test:13.95878   best_test:13.95878   best_possible:14.47989  Percentage::0.964\n",
      "epoch 1550  anneal_param:1.0481\n",
      "         loss_test:13.95692   best_test:13.95878   best_possible:14.47989  Percentage::0.964\n",
      "epoch 1560  anneal_param:1.0491\n",
      "         loss_test:13.94954   best_test:13.95878   best_possible:14.47989  Percentage::0.964\n",
      "✅ Model saved at epoch 1570, Loss: -13.96206\n",
      "epoch 1570  anneal_param:1.0491\n",
      "         loss_test:13.96206   best_test:13.96206   best_possible:14.47989  Percentage::0.964\n",
      "epoch 1580  anneal_param:1.0502\n",
      "         loss_test:13.95564   best_test:13.96206   best_possible:14.47989  Percentage::0.964\n",
      "epoch 1590  anneal_param:1.0512\n",
      "         loss_test:13.96174   best_test:13.96206   best_possible:14.47989  Percentage::0.964\n",
      "epoch 1600  anneal_param:1.0523\n",
      "         loss_test:13.95580   best_test:13.96206   best_possible:14.47989  Percentage::0.964\n",
      "✅ Model saved at epoch 1610, Loss: -13.96746\n",
      "epoch 1610  anneal_param:1.0523\n",
      "         loss_test:13.96746   best_test:13.96746   best_possible:14.47989  Percentage::0.965\n",
      "✅ Model saved at epoch 1620, Loss: -13.96967\n",
      "epoch 1620  anneal_param:1.0523\n",
      "         loss_test:13.96967   best_test:13.96967   best_possible:14.47989  Percentage::0.965\n",
      "epoch 1630  anneal_param:1.0533\n",
      "         loss_test:13.96632   best_test:13.96967   best_possible:14.47989  Percentage::0.965\n",
      "epoch 1640  anneal_param:1.0544\n",
      "         loss_test:13.96875   best_test:13.96967   best_possible:14.47989  Percentage::0.965\n",
      "epoch 1650  anneal_param:1.0555\n",
      "         loss_test:13.96488   best_test:13.96967   best_possible:14.47989  Percentage::0.965\n",
      "✅ Model saved at epoch 1660, Loss: -13.97633\n",
      "epoch 1660  anneal_param:1.0555\n",
      "         loss_test:13.97633   best_test:13.97633   best_possible:14.47989  Percentage::0.965\n",
      "epoch 1670  anneal_param:1.0565\n",
      "         loss_test:13.97235   best_test:13.97633   best_possible:14.47989  Percentage::0.965\n",
      "epoch 1680  anneal_param:1.0576\n",
      "         loss_test:13.96576   best_test:13.97633   best_possible:14.47989  Percentage::0.965\n",
      "✅ Model saved at epoch 1690, Loss: -13.98201\n",
      "epoch 1690  anneal_param:1.0576\n",
      "         loss_test:13.98201   best_test:13.98201   best_possible:14.47989  Percentage::0.966\n",
      "✅ Model saved at epoch 1700, Loss: -13.98227\n",
      "epoch 1700  anneal_param:1.0576\n",
      "         loss_test:13.98227   best_test:13.98227   best_possible:14.47989  Percentage::0.966\n",
      "✅ Model saved at epoch 1710, Loss: -13.98284\n",
      "epoch 1710  anneal_param:1.0576\n",
      "         loss_test:13.98284   best_test:13.98284   best_possible:14.47989  Percentage::0.966\n",
      "epoch 1720  anneal_param:1.0586\n",
      "         loss_test:13.97923   best_test:13.98284   best_possible:14.47989  Percentage::0.966\n",
      "✅ Model saved at epoch 1730, Loss: -13.98459\n",
      "epoch 1730  anneal_param:1.0586\n",
      "         loss_test:13.98459   best_test:13.98459   best_possible:14.47989  Percentage::0.966\n",
      "epoch 1740  anneal_param:1.0597\n",
      "         loss_test:13.98289   best_test:13.98459   best_possible:14.47989  Percentage::0.966\n",
      "epoch 1750  anneal_param:1.0607\n",
      "         loss_test:13.98399   best_test:13.98459   best_possible:14.47989  Percentage::0.966\n",
      "epoch 1760  anneal_param:1.0618\n",
      "         loss_test:13.98288   best_test:13.98459   best_possible:14.47989  Percentage::0.966\n",
      "✅ Model saved at epoch 1770, Loss: -14.00352\n",
      "epoch 1770  anneal_param:1.0618\n",
      "         loss_test:14.00352   best_test:14.00352   best_possible:14.47989  Percentage::0.967\n",
      "epoch 1780  anneal_param:1.0629\n",
      "         loss_test:13.99521   best_test:14.00352   best_possible:14.47989  Percentage::0.967\n",
      "epoch 1790  anneal_param:1.0639\n",
      "         loss_test:13.99698   best_test:14.00352   best_possible:14.47989  Percentage::0.967\n",
      "epoch 1800  anneal_param:1.0650\n",
      "         loss_test:13.99365   best_test:14.00352   best_possible:14.47989  Percentage::0.967\n",
      "epoch 1810  anneal_param:1.0661\n",
      "         loss_test:14.00092   best_test:14.00352   best_possible:14.47989  Percentage::0.967\n",
      "epoch 1820  anneal_param:1.0671\n",
      "         loss_test:13.99148   best_test:14.00352   best_possible:14.47989  Percentage::0.967\n",
      "✅ Model saved at epoch 1830, Loss: -14.00734\n",
      "epoch 1830  anneal_param:1.0671\n",
      "         loss_test:14.00734   best_test:14.00734   best_possible:14.47989  Percentage::0.967\n",
      "epoch 1840  anneal_param:1.0682\n",
      "         loss_test:14.00720   best_test:14.00734   best_possible:14.47989  Percentage::0.967\n",
      "epoch 1850  anneal_param:1.0693\n",
      "         loss_test:14.00035   best_test:14.00734   best_possible:14.47989  Percentage::0.967\n",
      "epoch 1860  anneal_param:1.0703\n",
      "         loss_test:13.99818   best_test:14.00734   best_possible:14.47989  Percentage::0.967\n",
      "✅ Model saved at epoch 1870, Loss: -14.01186\n",
      "epoch 1870  anneal_param:1.0703\n",
      "         loss_test:14.01186   best_test:14.01186   best_possible:14.47989  Percentage::0.968\n",
      "epoch 1880  anneal_param:1.0714\n",
      "         loss_test:13.99974   best_test:14.01186   best_possible:14.47989  Percentage::0.968\n",
      "epoch 1890  anneal_param:1.0725\n",
      "         loss_test:13.99580   best_test:14.01186   best_possible:14.47989  Percentage::0.968\n",
      "✅ Model saved at epoch 1900, Loss: -14.01408\n",
      "epoch 1900  anneal_param:1.0725\n",
      "         loss_test:14.01408   best_test:14.01408   best_possible:14.47989  Percentage::0.968\n",
      "epoch 1910  anneal_param:1.0735\n",
      "         loss_test:14.00534   best_test:14.01408   best_possible:14.47989  Percentage::0.968\n",
      "epoch 1920  anneal_param:1.0746\n",
      "         loss_test:14.01128   best_test:14.01408   best_possible:14.47989  Percentage::0.968\n",
      "epoch 1930  anneal_param:1.0757\n",
      "         loss_test:14.01384   best_test:14.01408   best_possible:14.47989  Percentage::0.968\n",
      "epoch 1940  anneal_param:1.0768\n",
      "         loss_test:14.01202   best_test:14.01408   best_possible:14.47989  Percentage::0.968\n",
      "✅ Model saved at epoch 1950, Loss: -14.01511\n",
      "epoch 1950  anneal_param:1.0768\n",
      "         loss_test:14.01511   best_test:14.01511   best_possible:14.47989  Percentage::0.968\n",
      "✅ Model saved at epoch 1960, Loss: -14.02872\n",
      "epoch 1960  anneal_param:1.0768\n",
      "         loss_test:14.02872   best_test:14.02872   best_possible:14.47989  Percentage::0.969\n",
      "epoch 1970  anneal_param:1.0778\n",
      "         loss_test:14.01678   best_test:14.02872   best_possible:14.47989  Percentage::0.969\n",
      "epoch 1980  anneal_param:1.0789\n",
      "         loss_test:14.02100   best_test:14.02872   best_possible:14.47989  Percentage::0.969\n",
      "✅ Model saved at epoch 1990, Loss: -14.02904\n",
      "epoch 1990  anneal_param:1.0789\n",
      "         loss_test:14.02904   best_test:14.02904   best_possible:14.47989  Percentage::0.969\n",
      "epoch 2000  anneal_param:1.0800\n",
      "         loss_test:14.02817   best_test:14.02904   best_possible:14.47989  Percentage::0.969\n",
      "epoch 2010  anneal_param:1.0811\n",
      "         loss_test:14.01887   best_test:14.02904   best_possible:14.47989  Percentage::0.969\n",
      "epoch 2020  anneal_param:1.0822\n",
      "         loss_test:14.02097   best_test:14.02904   best_possible:14.47989  Percentage::0.969\n",
      "epoch 2030  anneal_param:1.0832\n",
      "         loss_test:14.02739   best_test:14.02904   best_possible:14.47989  Percentage::0.969\n",
      "✅ Model saved at epoch 2040, Loss: -14.03379\n",
      "epoch 2040  anneal_param:1.0832\n",
      "         loss_test:14.03379   best_test:14.03379   best_possible:14.47989  Percentage::0.969\n",
      "✅ Model saved at epoch 2050, Loss: -14.03603\n",
      "epoch 2050  anneal_param:1.0832\n",
      "         loss_test:14.03603   best_test:14.03603   best_possible:14.47989  Percentage::0.969\n",
      "epoch 2060  anneal_param:1.0843\n",
      "         loss_test:14.02313   best_test:14.03603   best_possible:14.47989  Percentage::0.969\n",
      "epoch 2070  anneal_param:1.0854\n",
      "         loss_test:14.03201   best_test:14.03603   best_possible:14.47989  Percentage::0.969\n",
      "epoch 2080  anneal_param:1.0865\n",
      "         loss_test:14.02792   best_test:14.03603   best_possible:14.47989  Percentage::0.969\n",
      "epoch 2090  anneal_param:1.0876\n",
      "         loss_test:14.03180   best_test:14.03603   best_possible:14.47989  Percentage::0.969\n",
      "✅ Model saved at epoch 2100, Loss: -14.04268\n",
      "epoch 2100  anneal_param:1.0876\n",
      "         loss_test:14.04268   best_test:14.04268   best_possible:14.47989  Percentage::0.970\n",
      "epoch 2110  anneal_param:1.0887\n",
      "         loss_test:14.03701   best_test:14.04268   best_possible:14.47989  Percentage::0.970\n",
      "epoch 2120  anneal_param:1.0898\n",
      "         loss_test:14.03474   best_test:14.04268   best_possible:14.47989  Percentage::0.970\n",
      "epoch 2130  anneal_param:1.0908\n",
      "         loss_test:14.03466   best_test:14.04268   best_possible:14.47989  Percentage::0.970\n",
      "epoch 2140  anneal_param:1.0919\n",
      "         loss_test:14.03207   best_test:14.04268   best_possible:14.47989  Percentage::0.970\n",
      "epoch 2150  anneal_param:1.0930\n",
      "         loss_test:14.03575   best_test:14.04268   best_possible:14.47989  Percentage::0.970\n",
      "✅ Model saved at epoch 2160, Loss: -14.04882\n",
      "epoch 2160  anneal_param:1.0930\n",
      "         loss_test:14.04882   best_test:14.04882   best_possible:14.47989  Percentage::0.970\n",
      "epoch 2170  anneal_param:1.0941\n",
      "         loss_test:14.03585   best_test:14.04882   best_possible:14.47989  Percentage::0.970\n",
      "✅ Model saved at epoch 2180, Loss: -14.05507\n",
      "epoch 2180  anneal_param:1.0941\n",
      "         loss_test:14.05507   best_test:14.05507   best_possible:14.47989  Percentage::0.971\n",
      "epoch 2190  anneal_param:1.0952\n",
      "         loss_test:14.03827   best_test:14.05507   best_possible:14.47989  Percentage::0.971\n",
      "epoch 2200  anneal_param:1.0963\n",
      "         loss_test:14.05384   best_test:14.05507   best_possible:14.47989  Percentage::0.971\n",
      "✅ Model saved at epoch 2210, Loss: -14.05890\n",
      "epoch 2210  anneal_param:1.0963\n",
      "         loss_test:14.05890   best_test:14.05890   best_possible:14.47989  Percentage::0.971\n",
      "epoch 2220  anneal_param:1.0974\n",
      "         loss_test:14.04916   best_test:14.05890   best_possible:14.47989  Percentage::0.971\n",
      "epoch 2230  anneal_param:1.0985\n",
      "         loss_test:14.04684   best_test:14.05890   best_possible:14.47989  Percentage::0.971\n",
      "epoch 2240  anneal_param:1.0996\n",
      "         loss_test:14.05239   best_test:14.05890   best_possible:14.47989  Percentage::0.971\n",
      "✅ Model saved at epoch 2250, Loss: -14.06254\n",
      "epoch 2250  anneal_param:1.0996\n",
      "         loss_test:14.06254   best_test:14.06254   best_possible:14.47989  Percentage::0.971\n",
      "epoch 2260  anneal_param:1.1007\n",
      "         loss_test:14.05180   best_test:14.06254   best_possible:14.47989  Percentage::0.971\n",
      "epoch 2270  anneal_param:1.1018\n",
      "         loss_test:14.05818   best_test:14.06254   best_possible:14.47989  Percentage::0.971\n",
      "epoch 2280  anneal_param:1.1029\n",
      "         loss_test:14.06143   best_test:14.06254   best_possible:14.47989  Percentage::0.971\n",
      "✅ Model saved at epoch 2290, Loss: -14.07111\n",
      "epoch 2290  anneal_param:1.1029\n",
      "         loss_test:14.07111   best_test:14.07111   best_possible:14.47989  Percentage::0.972\n",
      "epoch 2300  anneal_param:1.1040\n",
      "         loss_test:14.05863   best_test:14.07111   best_possible:14.47989  Percentage::0.972\n",
      "epoch 2310  anneal_param:1.1051\n",
      "         loss_test:14.06605   best_test:14.07111   best_possible:14.47989  Percentage::0.972\n",
      "✅ Model saved at epoch 2320, Loss: -14.07829\n",
      "epoch 2320  anneal_param:1.1051\n",
      "         loss_test:14.07829   best_test:14.07829   best_possible:14.47989  Percentage::0.972\n",
      "epoch 2330  anneal_param:1.1062\n",
      "         loss_test:14.07302   best_test:14.07829   best_possible:14.47989  Percentage::0.972\n",
      "epoch 2340  anneal_param:1.1073\n",
      "         loss_test:14.06837   best_test:14.07829   best_possible:14.47989  Percentage::0.972\n",
      "epoch 2350  anneal_param:1.1084\n",
      "         loss_test:14.06573   best_test:14.07829   best_possible:14.47989  Percentage::0.972\n",
      "epoch 2360  anneal_param:1.1095\n",
      "         loss_test:14.06659   best_test:14.07829   best_possible:14.47989  Percentage::0.972\n",
      "✅ Model saved at epoch 2370, Loss: -14.08448\n",
      "epoch 2370  anneal_param:1.1095\n",
      "         loss_test:14.08448   best_test:14.08448   best_possible:14.47989  Percentage::0.973\n",
      "epoch 2380  anneal_param:1.1107\n",
      "         loss_test:14.07423   best_test:14.08448   best_possible:14.47989  Percentage::0.973\n",
      "epoch 2390  anneal_param:1.1118\n",
      "         loss_test:14.08231   best_test:14.08448   best_possible:14.47989  Percentage::0.973\n",
      "epoch 2400  anneal_param:1.1129\n",
      "         loss_test:14.07774   best_test:14.08448   best_possible:14.47989  Percentage::0.973\n",
      "epoch 2410  anneal_param:1.1140\n",
      "         loss_test:14.08292   best_test:14.08448   best_possible:14.47989  Percentage::0.973\n",
      "epoch 2420  anneal_param:1.1151\n",
      "         loss_test:14.08109   best_test:14.08448   best_possible:14.47989  Percentage::0.973\n",
      "✅ Model saved at epoch 2430, Loss: -14.09194\n",
      "epoch 2430  anneal_param:1.1151\n",
      "         loss_test:14.09194   best_test:14.09194   best_possible:14.47989  Percentage::0.973\n",
      "epoch 2440  anneal_param:1.1162\n",
      "         loss_test:14.09146   best_test:14.09194   best_possible:14.47989  Percentage::0.973\n",
      "epoch 2450  anneal_param:1.1173\n",
      "         loss_test:14.08754   best_test:14.09194   best_possible:14.47989  Percentage::0.973\n",
      "epoch 2460  anneal_param:1.1185\n",
      "         loss_test:14.09071   best_test:14.09194   best_possible:14.47989  Percentage::0.973\n",
      "epoch 2470  anneal_param:1.1196\n",
      "         loss_test:14.08604   best_test:14.09194   best_possible:14.47989  Percentage::0.973\n",
      "epoch 2480  anneal_param:1.1207\n",
      "         loss_test:14.08801   best_test:14.09194   best_possible:14.47989  Percentage::0.973\n",
      "✅ Model saved at epoch 2490, Loss: -14.09601\n",
      "epoch 2490  anneal_param:1.1207\n",
      "         loss_test:14.09601   best_test:14.09601   best_possible:14.47989  Percentage::0.973\n",
      "✅ Model saved at epoch 2500, Loss: -14.10113\n",
      "epoch 2500  anneal_param:1.1207\n",
      "         loss_test:14.10113   best_test:14.10113   best_possible:14.47989  Percentage::0.974\n",
      "✅ Model saved at epoch 2510, Loss: -14.10556\n",
      "epoch 2510  anneal_param:1.1207\n",
      "         loss_test:14.10556   best_test:14.10556   best_possible:14.47989  Percentage::0.974\n",
      "epoch 2520  anneal_param:1.1218\n",
      "         loss_test:14.09327   best_test:14.10556   best_possible:14.47989  Percentage::0.974\n",
      "epoch 2530  anneal_param:1.1229\n",
      "         loss_test:14.08268   best_test:14.10556   best_possible:14.47989  Percentage::0.974\n",
      "epoch 2540  anneal_param:1.1241\n",
      "         loss_test:14.10118   best_test:14.10556   best_possible:14.47989  Percentage::0.974\n",
      "epoch 2550  anneal_param:1.1252\n",
      "         loss_test:14.09198   best_test:14.10556   best_possible:14.47989  Percentage::0.974\n",
      "epoch 2560  anneal_param:1.1263\n",
      "         loss_test:14.07828   best_test:14.10556   best_possible:14.47989  Percentage::0.974\n",
      "epoch 2570  anneal_param:1.1274\n",
      "         loss_test:14.08208   best_test:14.10556   best_possible:14.47989  Percentage::0.974\n",
      "epoch 2580  anneal_param:1.1286\n",
      "         loss_test:14.10239   best_test:14.10556   best_possible:14.47989  Percentage::0.974\n",
      "epoch 2590  anneal_param:1.1297\n",
      "         loss_test:14.08608   best_test:14.10556   best_possible:14.47989  Percentage::0.974\n",
      "epoch 2600  anneal_param:1.1308\n",
      "         loss_test:14.09580   best_test:14.10556   best_possible:14.47989  Percentage::0.974\n",
      "✅ Model saved at epoch 2610, Loss: -14.11521\n",
      "epoch 2610  anneal_param:1.1308\n",
      "         loss_test:14.11521   best_test:14.11521   best_possible:14.47989  Percentage::0.975\n",
      "epoch 2620  anneal_param:1.1319\n",
      "         loss_test:14.10941   best_test:14.11521   best_possible:14.47989  Percentage::0.975\n",
      "epoch 2630  anneal_param:1.1331\n",
      "         loss_test:14.10479   best_test:14.11521   best_possible:14.47989  Percentage::0.975\n",
      "epoch 2640  anneal_param:1.1342\n",
      "         loss_test:14.10590   best_test:14.11521   best_possible:14.47989  Percentage::0.975\n",
      "epoch 2650  anneal_param:1.1353\n",
      "         loss_test:14.10349   best_test:14.11521   best_possible:14.47989  Percentage::0.975\n",
      "epoch 2660  anneal_param:1.1365\n",
      "         loss_test:14.11514   best_test:14.11521   best_possible:14.47989  Percentage::0.975\n",
      "✅ Model saved at epoch 2670, Loss: -14.12145\n",
      "epoch 2670  anneal_param:1.1365\n",
      "         loss_test:14.12145   best_test:14.12145   best_possible:14.47989  Percentage::0.975\n",
      "epoch 2680  anneal_param:1.1376\n",
      "         loss_test:14.11970   best_test:14.12145   best_possible:14.47989  Percentage::0.975\n",
      "epoch 2690  anneal_param:1.1388\n",
      "         loss_test:14.11526   best_test:14.12145   best_possible:14.47989  Percentage::0.975\n",
      "epoch 2700  anneal_param:1.1399\n",
      "         loss_test:14.10874   best_test:14.12145   best_possible:14.47989  Percentage::0.975\n",
      "epoch 2710  anneal_param:1.1410\n",
      "         loss_test:14.11164   best_test:14.12145   best_possible:14.47989  Percentage::0.975\n",
      "✅ Model saved at epoch 2720, Loss: -14.12256\n",
      "epoch 2720  anneal_param:1.1410\n",
      "         loss_test:14.12256   best_test:14.12256   best_possible:14.47989  Percentage::0.975\n",
      "✅ Model saved at epoch 2730, Loss: -14.12284\n",
      "epoch 2730  anneal_param:1.1410\n",
      "         loss_test:14.12284   best_test:14.12284   best_possible:14.47989  Percentage::0.975\n",
      "epoch 2740  anneal_param:1.1422\n",
      "         loss_test:14.11283   best_test:14.12284   best_possible:14.47989  Percentage::0.975\n",
      "epoch 2750  anneal_param:1.1433\n",
      "         loss_test:14.12021   best_test:14.12284   best_possible:14.47989  Percentage::0.975\n",
      "✅ Model saved at epoch 2760, Loss: -14.12366\n",
      "epoch 2760  anneal_param:1.1433\n",
      "         loss_test:14.12366   best_test:14.12366   best_possible:14.47989  Percentage::0.975\n",
      "epoch 2770  anneal_param:1.1445\n",
      "         loss_test:14.12123   best_test:14.12366   best_possible:14.47989  Percentage::0.975\n",
      "epoch 2780  anneal_param:1.1456\n",
      "         loss_test:14.11434   best_test:14.12366   best_possible:14.47989  Percentage::0.975\n",
      "epoch 2790  anneal_param:1.1467\n",
      "         loss_test:14.11899   best_test:14.12366   best_possible:14.47989  Percentage::0.975\n",
      "✅ Model saved at epoch 2800, Loss: -14.12460\n",
      "epoch 2800  anneal_param:1.1467\n",
      "         loss_test:14.12460   best_test:14.12460   best_possible:14.47989  Percentage::0.975\n",
      "epoch 2810  anneal_param:1.1479\n",
      "         loss_test:14.11291   best_test:14.12460   best_possible:14.47989  Percentage::0.975\n",
      "✅ Model saved at epoch 2820, Loss: -14.13254\n",
      "epoch 2820  anneal_param:1.1479\n",
      "         loss_test:14.13254   best_test:14.13254   best_possible:14.47989  Percentage::0.976\n",
      "epoch 2830  anneal_param:1.1490\n",
      "         loss_test:14.12162   best_test:14.13254   best_possible:14.47989  Percentage::0.976\n",
      "epoch 2840  anneal_param:1.1502\n",
      "         loss_test:14.13072   best_test:14.13254   best_possible:14.47989  Percentage::0.976\n",
      "✅ Model saved at epoch 2850, Loss: -14.14425\n",
      "epoch 2850  anneal_param:1.1502\n",
      "         loss_test:14.14425   best_test:14.14425   best_possible:14.47989  Percentage::0.977\n",
      "✅ Model saved at epoch 2860, Loss: -14.15051\n",
      "epoch 2860  anneal_param:1.1502\n",
      "         loss_test:14.15051   best_test:14.15051   best_possible:14.47989  Percentage::0.977\n",
      "epoch 2870  anneal_param:1.1513\n",
      "         loss_test:14.13943   best_test:14.15051   best_possible:14.47989  Percentage::0.977\n",
      "epoch 2880  anneal_param:1.1525\n",
      "         loss_test:14.14237   best_test:14.15051   best_possible:14.47989  Percentage::0.977\n",
      "✅ Model saved at epoch 2890, Loss: -14.15485\n",
      "epoch 2890  anneal_param:1.1525\n",
      "         loss_test:14.15485   best_test:14.15485   best_possible:14.47989  Percentage::0.978\n",
      "epoch 2900  anneal_param:1.1536\n",
      "         loss_test:14.13375   best_test:14.15485   best_possible:14.47989  Percentage::0.978\n",
      "epoch 2910  anneal_param:1.1548\n",
      "         loss_test:14.13545   best_test:14.15485   best_possible:14.47989  Percentage::0.978\n",
      "epoch 2920  anneal_param:1.1560\n",
      "         loss_test:14.12680   best_test:14.15485   best_possible:14.47989  Percentage::0.978\n",
      "epoch 2930  anneal_param:1.1571\n",
      "         loss_test:14.14239   best_test:14.15485   best_possible:14.47989  Percentage::0.978\n",
      "✅ Model saved at epoch 2940, Loss: -14.15533\n",
      "epoch 2940  anneal_param:1.1571\n",
      "         loss_test:14.15533   best_test:14.15533   best_possible:14.47989  Percentage::0.978\n",
      "epoch 2950  anneal_param:1.1583\n",
      "         loss_test:14.14796   best_test:14.15533   best_possible:14.47989  Percentage::0.978\n",
      "epoch 2960  anneal_param:1.1594\n",
      "         loss_test:14.14722   best_test:14.15533   best_possible:14.47989  Percentage::0.978\n",
      "epoch 2970  anneal_param:1.1606\n",
      "         loss_test:14.14754   best_test:14.15533   best_possible:14.47989  Percentage::0.978\n",
      "✅ Model saved at epoch 2980, Loss: -14.15588\n",
      "epoch 2980  anneal_param:1.1606\n",
      "         loss_test:14.15588   best_test:14.15588   best_possible:14.47989  Percentage::0.978\n",
      "epoch 2990  anneal_param:1.1617\n",
      "         loss_test:14.15587   best_test:14.15588   best_possible:14.47989  Percentage::0.978\n",
      "✅ Model saved at epoch 3000, Loss: -14.16439\n",
      "epoch 3000  anneal_param:1.1617\n",
      "         loss_test:14.16439   best_test:14.16439   best_possible:14.47989  Percentage::0.978\n",
      "✅ Model saved at epoch 3010, Loss: -14.16596\n",
      "epoch 3010  anneal_param:1.1617\n",
      "         loss_test:14.16596   best_test:14.16596   best_possible:14.47989  Percentage::0.978\n",
      "epoch 3020  anneal_param:1.1629\n",
      "         loss_test:14.16084   best_test:14.16596   best_possible:14.47989  Percentage::0.978\n",
      "epoch 3030  anneal_param:1.1641\n",
      "         loss_test:14.16315   best_test:14.16596   best_possible:14.47989  Percentage::0.978\n",
      "epoch 3040  anneal_param:1.1652\n",
      "         loss_test:14.14816   best_test:14.16596   best_possible:14.47989  Percentage::0.978\n",
      "epoch 3050  anneal_param:1.1664\n",
      "         loss_test:14.15636   best_test:14.16596   best_possible:14.47989  Percentage::0.978\n",
      "epoch 3060  anneal_param:1.1676\n",
      "         loss_test:14.16083   best_test:14.16596   best_possible:14.47989  Percentage::0.978\n",
      "✅ Model saved at epoch 3070, Loss: -14.16915\n",
      "epoch 3070  anneal_param:1.1676\n",
      "         loss_test:14.16915   best_test:14.16915   best_possible:14.47989  Percentage::0.979\n",
      "epoch 3080  anneal_param:1.1687\n",
      "         loss_test:14.16693   best_test:14.16915   best_possible:14.47989  Percentage::0.979\n",
      "✅ Model saved at epoch 3090, Loss: -14.17284\n",
      "epoch 3090  anneal_param:1.1687\n",
      "         loss_test:14.17284   best_test:14.17284   best_possible:14.47989  Percentage::0.979\n",
      "epoch 3100  anneal_param:1.1699\n",
      "         loss_test:14.15454   best_test:14.17284   best_possible:14.47989  Percentage::0.979\n",
      "epoch 3110  anneal_param:1.1711\n",
      "         loss_test:14.16792   best_test:14.17284   best_possible:14.47989  Percentage::0.979\n",
      "epoch 3120  anneal_param:1.1722\n",
      "         loss_test:14.16207   best_test:14.17284   best_possible:14.47989  Percentage::0.979\n",
      "epoch 3130  anneal_param:1.1734\n",
      "         loss_test:14.16429   best_test:14.17284   best_possible:14.47989  Percentage::0.979\n",
      "✅ Model saved at epoch 3140, Loss: -14.17936\n",
      "epoch 3140  anneal_param:1.1734\n",
      "         loss_test:14.17936   best_test:14.17936   best_possible:14.47989  Percentage::0.979\n",
      "✅ Model saved at epoch 3150, Loss: -14.18248\n",
      "epoch 3150  anneal_param:1.1734\n",
      "         loss_test:14.18248   best_test:14.18248   best_possible:14.47989  Percentage::0.979\n",
      "✅ Model saved at epoch 3160, Loss: -14.18894\n",
      "epoch 3160  anneal_param:1.1734\n",
      "         loss_test:14.18894   best_test:14.18894   best_possible:14.47989  Percentage::0.980\n",
      "epoch 3170  anneal_param:1.1746\n",
      "         loss_test:14.18194   best_test:14.18894   best_possible:14.47989  Percentage::0.980\n",
      "epoch 3180  anneal_param:1.1758\n",
      "         loss_test:14.17730   best_test:14.18894   best_possible:14.47989  Percentage::0.980\n",
      "epoch 3190  anneal_param:1.1769\n",
      "         loss_test:14.18260   best_test:14.18894   best_possible:14.47989  Percentage::0.980\n",
      "epoch 3200  anneal_param:1.1781\n",
      "         loss_test:14.18847   best_test:14.18894   best_possible:14.47989  Percentage::0.980\n",
      "✅ Model saved at epoch 3210, Loss: -14.19783\n",
      "epoch 3210  anneal_param:1.1781\n",
      "         loss_test:14.19783   best_test:14.19783   best_possible:14.47989  Percentage::0.981\n",
      "epoch 3220  anneal_param:1.1793\n",
      "         loss_test:14.17585   best_test:14.19783   best_possible:14.47989  Percentage::0.981\n",
      "epoch 3230  anneal_param:1.1805\n",
      "         loss_test:14.19742   best_test:14.19783   best_possible:14.47989  Percentage::0.981\n",
      "epoch 3240  anneal_param:1.1817\n",
      "         loss_test:14.18472   best_test:14.19783   best_possible:14.47989  Percentage::0.981\n",
      "epoch 3250  anneal_param:1.1828\n",
      "         loss_test:14.18821   best_test:14.19783   best_possible:14.47989  Percentage::0.981\n",
      "epoch 3260  anneal_param:1.1840\n",
      "         loss_test:14.19164   best_test:14.19783   best_possible:14.47989  Percentage::0.981\n",
      "epoch 3270  anneal_param:1.1852\n",
      "         loss_test:14.19071   best_test:14.19783   best_possible:14.47989  Percentage::0.981\n",
      "epoch 3280  anneal_param:1.1864\n",
      "         loss_test:14.19231   best_test:14.19783   best_possible:14.47989  Percentage::0.981\n",
      "epoch 3290  anneal_param:1.1876\n",
      "         loss_test:14.18520   best_test:14.19783   best_possible:14.47989  Percentage::0.981\n",
      "✅ Model saved at epoch 3300, Loss: -14.19826\n",
      "epoch 3300  anneal_param:1.1876\n",
      "         loss_test:14.19826   best_test:14.19826   best_possible:14.47989  Percentage::0.981\n",
      "✅ Model saved at epoch 3310, Loss: -14.20170\n",
      "epoch 3310  anneal_param:1.1876\n",
      "         loss_test:14.20170   best_test:14.20170   best_possible:14.47989  Percentage::0.981\n",
      "epoch 3320  anneal_param:1.1888\n",
      "         loss_test:14.18728   best_test:14.20170   best_possible:14.47989  Percentage::0.981\n",
      "epoch 3330  anneal_param:1.1900\n",
      "         loss_test:14.20149   best_test:14.20170   best_possible:14.47989  Percentage::0.981\n",
      "✅ Model saved at epoch 3340, Loss: -14.20804\n",
      "epoch 3340  anneal_param:1.1900\n",
      "         loss_test:14.20804   best_test:14.20804   best_possible:14.47989  Percentage::0.981\n",
      "epoch 3350  anneal_param:1.1911\n",
      "         loss_test:14.20545   best_test:14.20804   best_possible:14.47989  Percentage::0.981\n",
      "epoch 3360  anneal_param:1.1923\n",
      "         loss_test:14.20589   best_test:14.20804   best_possible:14.47989  Percentage::0.981\n",
      "✅ Model saved at epoch 3370, Loss: -14.21377\n",
      "epoch 3370  anneal_param:1.1923\n",
      "         loss_test:14.21377   best_test:14.21377   best_possible:14.47989  Percentage::0.982\n",
      "epoch 3380  anneal_param:1.1935\n",
      "         loss_test:14.20635   best_test:14.21377   best_possible:14.47989  Percentage::0.982\n",
      "✅ Model saved at epoch 3390, Loss: -14.21893\n",
      "epoch 3390  anneal_param:1.1935\n",
      "         loss_test:14.21893   best_test:14.21893   best_possible:14.47989  Percentage::0.982\n",
      "epoch 3400  anneal_param:1.1947\n",
      "         loss_test:14.21235   best_test:14.21893   best_possible:14.47989  Percentage::0.982\n",
      "✅ Model saved at epoch 3410, Loss: -14.21936\n",
      "epoch 3410  anneal_param:1.1947\n",
      "         loss_test:14.21936   best_test:14.21936   best_possible:14.47989  Percentage::0.982\n",
      "epoch 3420  anneal_param:1.1959\n",
      "         loss_test:14.21440   best_test:14.21936   best_possible:14.47989  Percentage::0.982\n",
      "epoch 3430  anneal_param:1.1971\n",
      "         loss_test:14.21640   best_test:14.21936   best_possible:14.47989  Percentage::0.982\n",
      "epoch 3440  anneal_param:1.1983\n",
      "         loss_test:14.21604   best_test:14.21936   best_possible:14.47989  Percentage::0.982\n",
      "epoch 3450  anneal_param:1.1995\n",
      "         loss_test:14.21343   best_test:14.21936   best_possible:14.47989  Percentage::0.982\n",
      "✅ Model saved at epoch 3460, Loss: -14.21961\n",
      "epoch 3460  anneal_param:1.1995\n",
      "         loss_test:14.21961   best_test:14.21961   best_possible:14.47989  Percentage::0.982\n",
      "✅ Model saved at epoch 3470, Loss: -14.22487\n",
      "epoch 3470  anneal_param:1.1995\n",
      "         loss_test:14.22487   best_test:14.22487   best_possible:14.47989  Percentage::0.982\n",
      "epoch 3480  anneal_param:1.2007\n",
      "         loss_test:14.22147   best_test:14.22487   best_possible:14.47989  Percentage::0.982\n",
      "epoch 3490  anneal_param:1.2019\n",
      "         loss_test:14.22162   best_test:14.22487   best_possible:14.47989  Percentage::0.982\n",
      "✅ Model saved at epoch 3500, Loss: -14.22962\n",
      "epoch 3500  anneal_param:1.2019\n",
      "         loss_test:14.22962   best_test:14.22962   best_possible:14.47989  Percentage::0.983\n",
      "epoch 3510  anneal_param:1.2031\n",
      "         loss_test:14.22778   best_test:14.22962   best_possible:14.47989  Percentage::0.983\n",
      "epoch 3520  anneal_param:1.2043\n",
      "         loss_test:14.22945   best_test:14.22962   best_possible:14.47989  Percentage::0.983\n",
      "✅ Model saved at epoch 3530, Loss: -14.23308\n",
      "epoch 3530  anneal_param:1.2043\n",
      "         loss_test:14.23308   best_test:14.23308   best_possible:14.47989  Percentage::0.983\n",
      "✅ Model saved at epoch 3540, Loss: -14.24239\n",
      "epoch 3540  anneal_param:1.2043\n",
      "         loss_test:14.24239   best_test:14.24239   best_possible:14.47989  Percentage::0.984\n",
      "epoch 3550  anneal_param:1.2055\n",
      "         loss_test:14.22503   best_test:14.24239   best_possible:14.47989  Percentage::0.984\n",
      "epoch 3560  anneal_param:1.2067\n",
      "         loss_test:14.23657   best_test:14.24239   best_possible:14.47989  Percentage::0.984\n",
      "epoch 3570  anneal_param:1.2079\n",
      "         loss_test:14.24128   best_test:14.24239   best_possible:14.47989  Percentage::0.984\n",
      "epoch 3580  anneal_param:1.2091\n",
      "         loss_test:14.23389   best_test:14.24239   best_possible:14.47989  Percentage::0.984\n",
      "epoch 3590  anneal_param:1.2103\n",
      "         loss_test:14.22796   best_test:14.24239   best_possible:14.47989  Percentage::0.984\n",
      "epoch 3600  anneal_param:1.2116\n",
      "         loss_test:14.24209   best_test:14.24239   best_possible:14.47989  Percentage::0.984\n",
      "✅ Model saved at epoch 3610, Loss: -14.24817\n",
      "epoch 3610  anneal_param:1.2116\n",
      "         loss_test:14.24817   best_test:14.24817   best_possible:14.47989  Percentage::0.984\n",
      "epoch 3620  anneal_param:1.2128\n",
      "         loss_test:14.24629   best_test:14.24817   best_possible:14.47989  Percentage::0.984\n",
      "epoch 3630  anneal_param:1.2140\n",
      "         loss_test:14.24341   best_test:14.24817   best_possible:14.47989  Percentage::0.984\n",
      "✅ Model saved at epoch 3640, Loss: -14.24858\n",
      "epoch 3640  anneal_param:1.2140\n",
      "         loss_test:14.24858   best_test:14.24858   best_possible:14.47989  Percentage::0.984\n",
      "✅ Model saved at epoch 3650, Loss: -14.24888\n",
      "epoch 3650  anneal_param:1.2140\n",
      "         loss_test:14.24888   best_test:14.24888   best_possible:14.47989  Percentage::0.984\n",
      "epoch 3660  anneal_param:1.2152\n",
      "         loss_test:14.24483   best_test:14.24888   best_possible:14.47989  Percentage::0.984\n",
      "epoch 3670  anneal_param:1.2164\n",
      "         loss_test:14.24481   best_test:14.24888   best_possible:14.47989  Percentage::0.984\n",
      "✅ Model saved at epoch 3680, Loss: -14.25556\n",
      "epoch 3680  anneal_param:1.2164\n",
      "         loss_test:14.25556   best_test:14.25556   best_possible:14.47989  Percentage::0.985\n",
      "✅ Model saved at epoch 3690, Loss: -14.26157\n",
      "epoch 3690  anneal_param:1.2164\n",
      "         loss_test:14.26157   best_test:14.26157   best_possible:14.47989  Percentage::0.985\n",
      "epoch 3700  anneal_param:1.2176\n",
      "         loss_test:14.24532   best_test:14.26157   best_possible:14.47989  Percentage::0.985\n",
      "epoch 3710  anneal_param:1.2188\n",
      "         loss_test:14.25044   best_test:14.26157   best_possible:14.47989  Percentage::0.985\n",
      "epoch 3720  anneal_param:1.2201\n",
      "         loss_test:14.25497   best_test:14.26157   best_possible:14.47989  Percentage::0.985\n",
      "epoch 3730  anneal_param:1.2213\n",
      "         loss_test:14.25433   best_test:14.26157   best_possible:14.47989  Percentage::0.985\n",
      "✅ Model saved at epoch 3740, Loss: -14.26438\n",
      "epoch 3740  anneal_param:1.2213\n",
      "         loss_test:14.26438   best_test:14.26438   best_possible:14.47989  Percentage::0.985\n",
      "✅ Model saved at epoch 3750, Loss: -14.26812\n",
      "epoch 3750  anneal_param:1.2213\n",
      "         loss_test:14.26812   best_test:14.26812   best_possible:14.47989  Percentage::0.985\n",
      "epoch 3760  anneal_param:1.2225\n",
      "         loss_test:14.26047   best_test:14.26812   best_possible:14.47989  Percentage::0.985\n",
      "epoch 3770  anneal_param:1.2237\n",
      "         loss_test:14.25931   best_test:14.26812   best_possible:14.47989  Percentage::0.985\n",
      "epoch 3780  anneal_param:1.2249\n",
      "         loss_test:14.26634   best_test:14.26812   best_possible:14.47989  Percentage::0.985\n",
      "✅ Model saved at epoch 3790, Loss: -14.28268\n",
      "epoch 3790  anneal_param:1.2249\n",
      "         loss_test:14.28268   best_test:14.28268   best_possible:14.47989  Percentage::0.986\n",
      "epoch 3800  anneal_param:1.2262\n",
      "         loss_test:14.27259   best_test:14.28268   best_possible:14.47989  Percentage::0.986\n",
      "epoch 3810  anneal_param:1.2274\n",
      "         loss_test:14.28129   best_test:14.28268   best_possible:14.47989  Percentage::0.986\n",
      "epoch 3820  anneal_param:1.2286\n",
      "         loss_test:14.28193   best_test:14.28268   best_possible:14.47989  Percentage::0.986\n",
      "✅ Model saved at epoch 3830, Loss: -14.28621\n",
      "epoch 3830  anneal_param:1.2286\n",
      "         loss_test:14.28621   best_test:14.28621   best_possible:14.47989  Percentage::0.987\n",
      "✅ Model saved at epoch 3840, Loss: -14.29447\n",
      "epoch 3840  anneal_param:1.2286\n",
      "         loss_test:14.29447   best_test:14.29447   best_possible:14.47989  Percentage::0.987\n",
      "✅ Model saved at epoch 3850, Loss: -14.29632\n",
      "epoch 3850  anneal_param:1.2286\n",
      "         loss_test:14.29632   best_test:14.29632   best_possible:14.47989  Percentage::0.987\n",
      "✅ Model saved at epoch 3860, Loss: -14.30548\n",
      "epoch 3860  anneal_param:1.2286\n",
      "         loss_test:14.30548   best_test:14.30548   best_possible:14.47989  Percentage::0.988\n",
      "epoch 3870  anneal_param:1.2299\n",
      "         loss_test:14.29757   best_test:14.30548   best_possible:14.47989  Percentage::0.988\n",
      "epoch 3880  anneal_param:1.2311\n",
      "         loss_test:14.29410   best_test:14.30548   best_possible:14.47989  Percentage::0.988\n",
      "epoch 3890  anneal_param:1.2323\n",
      "         loss_test:14.29578   best_test:14.30548   best_possible:14.47989  Percentage::0.988\n",
      "epoch 3900  anneal_param:1.2335\n",
      "         loss_test:14.30453   best_test:14.30548   best_possible:14.47989  Percentage::0.988\n",
      "✅ Model saved at epoch 3910, Loss: -14.30848\n",
      "epoch 3910  anneal_param:1.2335\n",
      "         loss_test:14.30848   best_test:14.30848   best_possible:14.47989  Percentage::0.988\n",
      "✅ Model saved at epoch 3920, Loss: -14.31530\n",
      "epoch 3920  anneal_param:1.2335\n",
      "         loss_test:14.31530   best_test:14.31530   best_possible:14.47989  Percentage::0.989\n",
      "epoch 3930  anneal_param:1.2348\n",
      "         loss_test:14.30418   best_test:14.31530   best_possible:14.47989  Percentage::0.989\n",
      "epoch 3940  anneal_param:1.2360\n",
      "         loss_test:14.31008   best_test:14.31530   best_possible:14.47989  Percentage::0.989\n",
      "epoch 3950  anneal_param:1.2373\n",
      "         loss_test:14.31330   best_test:14.31530   best_possible:14.47989  Percentage::0.989\n",
      "✅ Model saved at epoch 3960, Loss: -14.31692\n",
      "epoch 3960  anneal_param:1.2373\n",
      "         loss_test:14.31692   best_test:14.31692   best_possible:14.47989  Percentage::0.989\n",
      "✅ Model saved at epoch 3970, Loss: -14.32636\n",
      "epoch 3970  anneal_param:1.2373\n",
      "         loss_test:14.32636   best_test:14.32636   best_possible:14.47989  Percentage::0.989\n",
      "epoch 3980  anneal_param:1.2385\n",
      "         loss_test:14.32066   best_test:14.32636   best_possible:14.47989  Percentage::0.989\n",
      "✅ Model saved at epoch 3990, Loss: -14.32744\n",
      "epoch 3990  anneal_param:1.2385\n",
      "         loss_test:14.32744   best_test:14.32744   best_possible:14.47989  Percentage::0.989\n",
      "epoch 4000  anneal_param:1.2397\n",
      "         loss_test:14.32103   best_test:14.32744   best_possible:14.47989  Percentage::0.989\n",
      "epoch 4010  anneal_param:1.2410\n",
      "         loss_test:14.31722   best_test:14.32744   best_possible:14.47989  Percentage::0.989\n",
      "✅ Model saved at epoch 4020, Loss: -14.32849\n",
      "epoch 4020  anneal_param:1.2410\n",
      "         loss_test:14.32849   best_test:14.32849   best_possible:14.47989  Percentage::0.990\n",
      "✅ Model saved at epoch 4030, Loss: -14.34030\n",
      "epoch 4030  anneal_param:1.2410\n",
      "         loss_test:14.34030   best_test:14.34030   best_possible:14.47989  Percentage::0.990\n",
      "epoch 4040  anneal_param:1.2422\n",
      "         loss_test:14.33554   best_test:14.34030   best_possible:14.47989  Percentage::0.990\n",
      "epoch 4050  anneal_param:1.2435\n",
      "         loss_test:14.33526   best_test:14.34030   best_possible:14.47989  Percentage::0.990\n",
      "epoch 4060  anneal_param:1.2447\n",
      "         loss_test:14.32929   best_test:14.34030   best_possible:14.47989  Percentage::0.990\n",
      "epoch 4070  anneal_param:1.2459\n",
      "         loss_test:14.32777   best_test:14.34030   best_possible:14.47989  Percentage::0.990\n",
      "epoch 4080  anneal_param:1.2472\n",
      "         loss_test:14.33543   best_test:14.34030   best_possible:14.47989  Percentage::0.990\n",
      "epoch 4090  anneal_param:1.2484\n",
      "         loss_test:14.33598   best_test:14.34030   best_possible:14.47989  Percentage::0.990\n",
      "✅ Model saved at epoch 4100, Loss: -14.34137\n",
      "epoch 4100  anneal_param:1.2484\n",
      "         loss_test:14.34137   best_test:14.34137   best_possible:14.47989  Percentage::0.990\n",
      "✅ Model saved at epoch 4110, Loss: -14.35000\n",
      "epoch 4110  anneal_param:1.2484\n",
      "         loss_test:14.35000   best_test:14.35000   best_possible:14.47989  Percentage::0.991\n",
      "epoch 4120  anneal_param:1.2497\n",
      "         loss_test:14.33330   best_test:14.35000   best_possible:14.47989  Percentage::0.991\n",
      "epoch 4130  anneal_param:1.2509\n",
      "         loss_test:14.34883   best_test:14.35000   best_possible:14.47989  Percentage::0.991\n",
      "epoch 4140  anneal_param:1.2522\n",
      "         loss_test:14.33642   best_test:14.35000   best_possible:14.47989  Percentage::0.991\n",
      "epoch 4150  anneal_param:1.2534\n",
      "         loss_test:14.34642   best_test:14.35000   best_possible:14.47989  Percentage::0.991\n",
      "epoch 4160  anneal_param:1.2547\n",
      "         loss_test:14.33618   best_test:14.35000   best_possible:14.47989  Percentage::0.991\n",
      "✅ Model saved at epoch 4170, Loss: -14.35338\n",
      "epoch 4170  anneal_param:1.2547\n",
      "         loss_test:14.35338   best_test:14.35338   best_possible:14.47989  Percentage::0.991\n",
      "epoch 4180  anneal_param:1.2559\n",
      "         loss_test:14.34660   best_test:14.35338   best_possible:14.47989  Percentage::0.991\n",
      "✅ Model saved at epoch 4190, Loss: -14.35494\n",
      "epoch 4190  anneal_param:1.2559\n",
      "         loss_test:14.35494   best_test:14.35494   best_possible:14.47989  Percentage::0.991\n",
      "✅ Model saved at epoch 4200, Loss: -14.35813\n",
      "epoch 4200  anneal_param:1.2559\n",
      "         loss_test:14.35813   best_test:14.35813   best_possible:14.47989  Percentage::0.992\n",
      "epoch 4210  anneal_param:1.2572\n",
      "         loss_test:14.34377   best_test:14.35813   best_possible:14.47989  Percentage::0.992\n",
      "epoch 4220  anneal_param:1.2585\n",
      "         loss_test:14.34935   best_test:14.35813   best_possible:14.47989  Percentage::0.992\n",
      "epoch 4230  anneal_param:1.2597\n",
      "         loss_test:14.34691   best_test:14.35813   best_possible:14.47989  Percentage::0.992\n",
      "epoch 4240  anneal_param:1.2610\n",
      "         loss_test:14.35518   best_test:14.35813   best_possible:14.47989  Percentage::0.992\n",
      "✅ Model saved at epoch 4250, Loss: -14.36873\n",
      "epoch 4250  anneal_param:1.2610\n",
      "         loss_test:14.36873   best_test:14.36873   best_possible:14.47989  Percentage::0.992\n",
      "epoch 4260  anneal_param:1.2622\n",
      "         loss_test:14.36335   best_test:14.36873   best_possible:14.47989  Percentage::0.992\n",
      "✅ Model saved at epoch 4270, Loss: -14.37518\n",
      "epoch 4270  anneal_param:1.2622\n",
      "         loss_test:14.37518   best_test:14.37518   best_possible:14.47989  Percentage::0.993\n",
      "epoch 4280  anneal_param:1.2635\n",
      "         loss_test:14.37414   best_test:14.37518   best_possible:14.47989  Percentage::0.993\n",
      "epoch 4290  anneal_param:1.2648\n",
      "         loss_test:14.36922   best_test:14.37518   best_possible:14.47989  Percentage::0.993\n",
      "epoch 4300  anneal_param:1.2660\n",
      "         loss_test:14.36834   best_test:14.37518   best_possible:14.47989  Percentage::0.993\n",
      "epoch 4310  anneal_param:1.2673\n",
      "         loss_test:14.36060   best_test:14.37518   best_possible:14.47989  Percentage::0.993\n",
      "✅ Model saved at epoch 4320, Loss: -14.37676\n",
      "epoch 4320  anneal_param:1.2673\n",
      "         loss_test:14.37676   best_test:14.37676   best_possible:14.47989  Percentage::0.993\n",
      "✅ Model saved at epoch 4330, Loss: -14.37970\n",
      "epoch 4330  anneal_param:1.2673\n",
      "         loss_test:14.37970   best_test:14.37970   best_possible:14.47989  Percentage::0.993\n",
      "✅ Model saved at epoch 4340, Loss: -14.38060\n",
      "epoch 4340  anneal_param:1.2673\n",
      "         loss_test:14.38060   best_test:14.38060   best_possible:14.47989  Percentage::0.993\n",
      "✅ Model saved at epoch 4350, Loss: -14.39046\n",
      "epoch 4350  anneal_param:1.2673\n",
      "         loss_test:14.39046   best_test:14.39046   best_possible:14.47989  Percentage::0.994\n",
      "✅ Model saved at epoch 4360, Loss: -14.39096\n",
      "epoch 4360  anneal_param:1.2673\n",
      "         loss_test:14.39096   best_test:14.39096   best_possible:14.47989  Percentage::0.994\n",
      "epoch 4370  anneal_param:1.2686\n",
      "         loss_test:14.38901   best_test:14.39096   best_possible:14.47989  Percentage::0.994\n",
      "✅ Model saved at epoch 4380, Loss: -14.39099\n",
      "epoch 4380  anneal_param:1.2686\n",
      "         loss_test:14.39099   best_test:14.39099   best_possible:14.47989  Percentage::0.994\n",
      "epoch 4390  anneal_param:1.2698\n",
      "         loss_test:14.37504   best_test:14.39099   best_possible:14.47989  Percentage::0.994\n",
      "epoch 4400  anneal_param:1.2711\n",
      "         loss_test:14.38276   best_test:14.39099   best_possible:14.47989  Percentage::0.994\n",
      "epoch 4410  anneal_param:1.2724\n",
      "         loss_test:14.38564   best_test:14.39099   best_possible:14.47989  Percentage::0.994\n",
      "✅ Model saved at epoch 4420, Loss: -14.40456\n",
      "epoch 4420  anneal_param:1.2724\n",
      "         loss_test:14.40456   best_test:14.40456   best_possible:14.47989  Percentage::0.995\n",
      "epoch 4430  anneal_param:1.2736\n",
      "         loss_test:14.39565   best_test:14.40456   best_possible:14.47989  Percentage::0.995\n",
      "epoch 4440  anneal_param:1.2749\n",
      "         loss_test:14.39034   best_test:14.40456   best_possible:14.47989  Percentage::0.995\n",
      "✅ Model saved at epoch 4450, Loss: -14.40508\n",
      "epoch 4450  anneal_param:1.2749\n",
      "         loss_test:14.40508   best_test:14.40508   best_possible:14.47989  Percentage::0.995\n",
      "✅ Model saved at epoch 4460, Loss: -14.40821\n",
      "epoch 4460  anneal_param:1.2749\n",
      "         loss_test:14.40821   best_test:14.40821   best_possible:14.47989  Percentage::0.995\n",
      "epoch 4470  anneal_param:1.2762\n",
      "         loss_test:14.39820   best_test:14.40821   best_possible:14.47989  Percentage::0.995\n",
      "epoch 4480  anneal_param:1.2775\n",
      "         loss_test:14.40137   best_test:14.40821   best_possible:14.47989  Percentage::0.995\n",
      "epoch 4490  anneal_param:1.2787\n",
      "         loss_test:14.40646   best_test:14.40821   best_possible:14.47989  Percentage::0.995\n",
      "epoch 4500  anneal_param:1.2800\n",
      "         loss_test:14.39847   best_test:14.40821   best_possible:14.47989  Percentage::0.995\n",
      "epoch 4510  anneal_param:1.2813\n",
      "         loss_test:14.40764   best_test:14.40821   best_possible:14.47989  Percentage::0.995\n",
      "epoch 4520  anneal_param:1.2826\n",
      "         loss_test:14.40063   best_test:14.40821   best_possible:14.47989  Percentage::0.995\n",
      "✅ Model saved at epoch 4530, Loss: -14.41026\n",
      "epoch 4530  anneal_param:1.2826\n",
      "         loss_test:14.41026   best_test:14.41026   best_possible:14.47989  Percentage::0.995\n",
      "epoch 4540  anneal_param:1.2839\n",
      "         loss_test:14.40960   best_test:14.41026   best_possible:14.47989  Percentage::0.995\n",
      "epoch 4550  anneal_param:1.2851\n",
      "         loss_test:14.39501   best_test:14.41026   best_possible:14.47989  Percentage::0.995\n",
      "epoch 4560  anneal_param:1.2864\n",
      "         loss_test:14.40465   best_test:14.41026   best_possible:14.47989  Percentage::0.995\n",
      "epoch 4570  anneal_param:1.2877\n",
      "         loss_test:14.40859   best_test:14.41026   best_possible:14.47989  Percentage::0.995\n",
      "✅ Model saved at epoch 4580, Loss: -14.41376\n",
      "epoch 4580  anneal_param:1.2877\n",
      "         loss_test:14.41376   best_test:14.41376   best_possible:14.47989  Percentage::0.995\n",
      "✅ Model saved at epoch 4590, Loss: -14.41771\n",
      "epoch 4590  anneal_param:1.2877\n",
      "         loss_test:14.41771   best_test:14.41771   best_possible:14.47989  Percentage::0.996\n",
      "✅ Model saved at epoch 4600, Loss: -14.42163\n",
      "epoch 4600  anneal_param:1.2877\n",
      "         loss_test:14.42163   best_test:14.42163   best_possible:14.47989  Percentage::0.996\n",
      "epoch 4610  anneal_param:1.2890\n",
      "         loss_test:14.42069   best_test:14.42163   best_possible:14.47989  Percentage::0.996\n",
      "✅ Model saved at epoch 4620, Loss: -14.42447\n",
      "epoch 4620  anneal_param:1.2890\n",
      "         loss_test:14.42447   best_test:14.42447   best_possible:14.47989  Percentage::0.996\n",
      "epoch 4630  anneal_param:1.2903\n",
      "         loss_test:14.42377   best_test:14.42447   best_possible:14.47989  Percentage::0.996\n",
      "✅ Model saved at epoch 4640, Loss: -14.42549\n",
      "epoch 4640  anneal_param:1.2903\n",
      "         loss_test:14.42549   best_test:14.42549   best_possible:14.47989  Percentage::0.996\n",
      "epoch 4650  anneal_param:1.2916\n",
      "         loss_test:14.42031   best_test:14.42549   best_possible:14.47989  Percentage::0.996\n",
      "epoch 4660  anneal_param:1.2929\n",
      "         loss_test:14.42072   best_test:14.42549   best_possible:14.47989  Percentage::0.996\n",
      "epoch 4670  anneal_param:1.2942\n",
      "         loss_test:14.42200   best_test:14.42549   best_possible:14.47989  Percentage::0.996\n",
      "epoch 4680  anneal_param:1.2955\n",
      "         loss_test:14.42234   best_test:14.42549   best_possible:14.47989  Percentage::0.996\n",
      "epoch 4690  anneal_param:1.2968\n",
      "         loss_test:14.42000   best_test:14.42549   best_possible:14.47989  Percentage::0.996\n",
      "✅ Model saved at epoch 4700, Loss: -14.42704\n",
      "epoch 4700  anneal_param:1.2968\n",
      "         loss_test:14.42704   best_test:14.42704   best_possible:14.47989  Percentage::0.996\n",
      "✅ Model saved at epoch 4710, Loss: -14.44115\n",
      "epoch 4710  anneal_param:1.2968\n",
      "         loss_test:14.44115   best_test:14.44115   best_possible:14.47989  Percentage::0.997\n",
      "epoch 4720  anneal_param:1.2981\n",
      "         loss_test:14.42896   best_test:14.44115   best_possible:14.47989  Percentage::0.997\n",
      "epoch 4730  anneal_param:1.2994\n",
      "         loss_test:14.43593   best_test:14.44115   best_possible:14.47989  Percentage::0.997\n",
      "epoch 4740  anneal_param:1.3007\n",
      "         loss_test:14.43818   best_test:14.44115   best_possible:14.47989  Percentage::0.997\n",
      "epoch 4750  anneal_param:1.3020\n",
      "         loss_test:14.41875   best_test:14.44115   best_possible:14.47989  Percentage::0.997\n",
      "epoch 4760  anneal_param:1.3033\n",
      "         loss_test:14.42651   best_test:14.44115   best_possible:14.47989  Percentage::0.997\n",
      "epoch 4770  anneal_param:1.3046\n",
      "         loss_test:14.43362   best_test:14.44115   best_possible:14.47989  Percentage::0.997\n",
      "epoch 4780  anneal_param:1.3059\n",
      "         loss_test:14.43878   best_test:14.44115   best_possible:14.47989  Percentage::0.997\n",
      "epoch 4790  anneal_param:1.3072\n",
      "         loss_test:14.43651   best_test:14.44115   best_possible:14.47989  Percentage::0.997\n",
      "epoch 4800  anneal_param:1.3085\n",
      "         loss_test:14.43923   best_test:14.44115   best_possible:14.47989  Percentage::0.997\n",
      "✅ Model saved at epoch 4810, Loss: -14.44283\n",
      "epoch 4810  anneal_param:1.3085\n",
      "         loss_test:14.44283   best_test:14.44283   best_possible:14.47989  Percentage::0.997\n",
      "✅ Model saved at epoch 4820, Loss: -14.44476\n",
      "epoch 4820  anneal_param:1.3085\n",
      "         loss_test:14.44476   best_test:14.44476   best_possible:14.47989  Percentage::0.998\n",
      "✅ Model saved at epoch 4830, Loss: -14.44674\n",
      "epoch 4830  anneal_param:1.3085\n",
      "         loss_test:14.44674   best_test:14.44674   best_possible:14.47989  Percentage::0.998\n",
      "✅ Model saved at epoch 4840, Loss: -14.45306\n",
      "epoch 4840  anneal_param:1.3085\n",
      "         loss_test:14.45306   best_test:14.45306   best_possible:14.47989  Percentage::0.998\n",
      "✅ Model saved at epoch 4850, Loss: -14.45346\n",
      "epoch 4850  anneal_param:1.3085\n",
      "         loss_test:14.45346   best_test:14.45346   best_possible:14.47989  Percentage::0.998\n",
      "epoch 4860  anneal_param:1.3098\n",
      "         loss_test:14.44682   best_test:14.45346   best_possible:14.47989  Percentage::0.998\n",
      "epoch 4870  anneal_param:1.3111\n",
      "         loss_test:14.44638   best_test:14.45346   best_possible:14.47989  Percentage::0.998\n",
      "epoch 4880  anneal_param:1.3124\n",
      "         loss_test:14.45259   best_test:14.45346   best_possible:14.47989  Percentage::0.998\n",
      "✅ Model saved at epoch 4890, Loss: -14.45811\n",
      "epoch 4890  anneal_param:1.3124\n",
      "         loss_test:14.45811   best_test:14.45811   best_possible:14.47989  Percentage::0.998\n",
      "✅ Model saved at epoch 4900, Loss: -14.46029\n",
      "epoch 4900  anneal_param:1.3124\n",
      "         loss_test:14.46029   best_test:14.46029   best_possible:14.47989  Percentage::0.999\n",
      "epoch 4910  anneal_param:1.3137\n",
      "         loss_test:14.45722   best_test:14.46029   best_possible:14.47989  Percentage::0.999\n",
      "epoch 4920  anneal_param:1.3150\n",
      "         loss_test:14.44493   best_test:14.46029   best_possible:14.47989  Percentage::0.999\n",
      "epoch 4930  anneal_param:1.3163\n",
      "         loss_test:14.44839   best_test:14.46029   best_possible:14.47989  Percentage::0.999\n",
      "epoch 4940  anneal_param:1.3177\n",
      "         loss_test:14.44883   best_test:14.46029   best_possible:14.47989  Percentage::0.999\n",
      "epoch 4950  anneal_param:1.3190\n",
      "         loss_test:14.45368   best_test:14.46029   best_possible:14.47989  Percentage::0.999\n",
      "epoch 4960  anneal_param:1.3203\n",
      "         loss_test:14.44635   best_test:14.46029   best_possible:14.47989  Percentage::0.999\n",
      "epoch 4970  anneal_param:1.3216\n",
      "         loss_test:14.45104   best_test:14.46029   best_possible:14.47989  Percentage::0.999\n",
      "✅ Model saved at epoch 4980, Loss: -14.46225\n",
      "epoch 4980  anneal_param:1.3216\n",
      "         loss_test:14.46225   best_test:14.46225   best_possible:14.47989  Percentage::0.999\n",
      "epoch 4990  anneal_param:1.3229\n",
      "         loss_test:14.45654   best_test:14.46225   best_possible:14.47989  Percentage::0.999\n",
      "tensor(0.9994, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(14.4499, device='cuda:0')\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[125], line 46\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28mprint\u001b[39m(loss_test_Final\u001b[38;5;241m/\u001b[39mloss_UP_test_Final)    \n\u001b[0;32m     45\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;241m-\u001b[39mloss_UP_test_Final)\n\u001b[1;32m---> 46\u001b[0m \u001b[43msio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msavemat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mData_K2M64Lp2L8_resultB30.mat\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mloss_test_Final_B30\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_test_Final\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mloss_UP_test_Final\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_UP_test_Final\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m  \n",
      "File \u001b[1;32mc:\\Users\\unist\\anaconda3\\envs\\acnl\\Lib\\site-packages\\scipy\\io\\matlab\\_mio.py:314\u001b[0m, in \u001b[0;36msavemat\u001b[1;34m(file_name, mdict, appendmat, format, long_field_names, do_compression, oned_as)\u001b[0m\n\u001b[0;32m    312\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    313\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFormat should be \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m4\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m5\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 314\u001b[0m \u001b[43mMW\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mput_variables\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmdict\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\unist\\anaconda3\\envs\\acnl\\Lib\\site-packages\\scipy\\io\\matlab\\_mio5.py:895\u001b[0m, in \u001b[0;36mMatFile5Writer.put_variables\u001b[1;34m(self, mdict, write_header)\u001b[0m\n\u001b[0;32m    893\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_stream\u001b[38;5;241m.\u001b[39mwrite(out_str)\n\u001b[0;32m    894\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# not compressing\u001b[39;00m\n\u001b[1;32m--> 895\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_matrix_writer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_top\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlatin1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_global\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\unist\\anaconda3\\envs\\acnl\\Lib\\site-packages\\scipy\\io\\matlab\\_mio5.py:637\u001b[0m, in \u001b[0;36mVarWriter5.write_top\u001b[1;34m(self, arr, name, is_global)\u001b[0m\n\u001b[0;32m    635\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_var_name \u001b[38;5;241m=\u001b[39m name\n\u001b[0;32m    636\u001b[0m \u001b[38;5;66;03m# write the header and data\u001b[39;00m\n\u001b[1;32m--> 637\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\unist\\anaconda3\\envs\\acnl\\Lib\\site-packages\\scipy\\io\\matlab\\_mio5.py:655\u001b[0m, in \u001b[0;36mVarWriter5.write\u001b[1;34m(self, arr)\u001b[0m\n\u001b[0;32m    653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    654\u001b[0m \u001b[38;5;66;03m# Try to convert things that aren't arrays\u001b[39;00m\n\u001b[1;32m--> 655\u001b[0m narr \u001b[38;5;241m=\u001b[39m \u001b[43mto_writeable\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    656\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m narr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    657\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCould not convert \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(arr)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) to array\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\unist\\anaconda3\\envs\\acnl\\Lib\\site-packages\\scipy\\io\\matlab\\_mio5.py:469\u001b[0m, in \u001b[0;36mto_writeable\u001b[1;34m(source)\u001b[0m\n\u001b[0;32m    467\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    468\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(source, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__array__\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 469\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    470\u001b[0m \u001b[38;5;66;03m# Objects that implement mappings\u001b[39;00m\n\u001b[0;32m    471\u001b[0m is_mapping \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mhasattr\u001b[39m(source, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeys\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(source, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    472\u001b[0m               \u001b[38;5;28mhasattr\u001b[39m(source, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mitems\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\unist\\anaconda3\\envs\\acnl\\Lib\\site-packages\\torch\\_tensor.py:1149\u001b[0m, in \u001b[0;36mTensor.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   1147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[38;5;241m.\u001b[39m__array__, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m   1148\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1149\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1150\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead."
     ]
    }
   ],
   "source": [
    "## Loop\n",
    "for epoch in range(n_epochs):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    for _ in range(batch_per_epoch):\n",
    "        # tarin dataset 생성\n",
    "        h_batch, hR_batch, hI_batch = generate_batch_data(batch_size,M,K,Lp,LSF_UE,Mainlobe_UE,HalfBW_UE)\n",
    "        \n",
    "        y_pilot = pilot_train(hR_batch, hI_batch, K, M, L) # K user의 파일럿 수신 신호 리스트\n",
    "        UE_Feedback = ue_dnn(y_pilot)\n",
    "        rate, rate_UP = bs_dnn(UE_Feedback, hR_batch, hI_batch, noise_std_dl)\n",
    "        loss, loss_UP = Lossfunc(rate, rate_UP)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    if epoch%10==0:\n",
    "        y_pilot = pilot_train(hR_test, hI_test, K, M, L)\n",
    "        rate, rate_UP = bs_dnn(ue_dnn(y_pilot), hR_test, hI_test, noise_std_dl)\n",
    "        loss_test, loss_UP_test = Lossfunc(rate, rate_UP)\n",
    "        \n",
    "        if loss_test < best_loss:\n",
    "            best_loss = loss_test\n",
    "            \n",
    "            torch.save({\n",
    "                'pilot_train' : pilot_train.state_dict(),\n",
    "                'bs_dnn' : bs_dnn.state_dict(),\n",
    "                'ue_dnn' : ue_dnn.state_dict(),\n",
    "                'optimizer' : optimizer.state_dict(),\n",
    "                'best_loss' : best_loss\n",
    "            }, save_path)\n",
    "            \n",
    "            print(f\"✅ Model saved at epoch {epoch}, Loss: {best_loss:.5f}\")\n",
    "        else:\n",
    "            anneal_param = anneal_param*annealing_rate\n",
    "        print('epoch',epoch,' anneal_param:%4.4f'%anneal_param)\n",
    "        print('         loss_test:%2.5f'%-loss_test,'  best_test:%2.5f'%-best_loss,'  best_possible:%2.5f'%-loss_UP_test,\\\n",
    "                        ' Percentage::%1.3f'%(best_loss/loss_UP_test))\n",
    "        \n",
    "y_pilot = pilot_train(hR_test_Final, hI_test_Final, K, M, L)\n",
    "rate, rate_UP = bs_dnn(ue_dnn(y_pilot), hR_test_Final, hI_test_Final, noise_std_dl)\n",
    "loss_test_Final, loss_UP_test_Final = Lossfunc(rate, rate_UP)\n",
    "\n",
    "print(loss_test_Final/loss_UP_test_Final)    \n",
    "print(-loss_UP_test_Final)\n",
    "sio.savemat('Data_K2M64Lp2L8_resultB30.mat',dict(loss_test_Final_B30=loss_test_Final.to('cpu'),\\\n",
    "                                        loss_UP_test_Final=loss_UP_test_Final.to('cpu')))  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "acnl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
