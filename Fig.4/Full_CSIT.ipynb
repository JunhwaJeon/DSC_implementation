{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full CSIT : No feedback, No pilot sequence required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## System parameters\n",
    "M = 64 #Number of BS antennas\n",
    "P = 1 #Power\n",
    "K =  2 #Number of users\n",
    "L = 8 #Number of pilots\n",
    "Lp = 2 #Number of paths\n",
    "B = 30 #Number of feedback bits per user\n",
    "\n",
    "## Limited scattering channel parameters\n",
    "LSF_UE = np.array([0.0,0.0],dtype=np.float32) #Mean of path gains for K users\n",
    "Mainlobe_UE= np.array([0,0],dtype=np.float32) #Center of the AoD range for K users\n",
    "HalfBW_UE = np.array([30.0,30.0],dtype=np.float32) #Half of the AoD range for K users\n",
    "\n",
    "# SNR\n",
    "snr_dl = 10 #SNR in dB\n",
    "noise_std_dl = np.float32(np.sqrt(1/2)*np.sqrt(P/10**(snr_dl/10))) #STD of the Gaussian noise (per real dim.)\n",
    "\n",
    "# Number of Monte-Carlo similations -> batch_size = N_experiment\n",
    "iter = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch data 생성 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 리스트 인덱싱은 [층, 행, 열], [행, 열]임!\n",
    "def generate_batch_data(batch_size,M,K,\n",
    "                        Lp,#number of paths\n",
    "                        LSF_UE #Mean of path gains for K users\n",
    "                        ,Mainlobe_UE #Center of the AoD range for K users\n",
    "                        ,HalfBW_UE #Half of the AoD range for K users\n",
    "                        ):\n",
    "    alphaR_input = np.zeros((batch_size,Lp,K))\n",
    "    alphaI_input = np.zeros((batch_size,Lp,K))\n",
    "    theta_input = np.zeros((batch_size,Lp,K))\n",
    "    for kk in range(K): # for the number of users\n",
    "        alphaR_input[:,:,kk] = np.random.normal(loc=LSF_UE[kk], scale=1.0/np.sqrt(2), size=[batch_size,Lp])\n",
    "        alphaI_input[:,:,kk] = np.random.normal(loc=LSF_UE[kk], scale=1.0/np.sqrt(2), size=[batch_size,Lp])\n",
    "        theta_input[:,:,kk] = np.random.uniform(low=Mainlobe_UE[kk]-HalfBW_UE[kk], high=Mainlobe_UE[kk]+HalfBW_UE[kk], size=[batch_size,Lp])\n",
    " \n",
    "    #### Actual Channel\n",
    "    from0toM = np.float32(np.arange(0, M, 1))\n",
    "    alpha_act = alphaR_input + 1j*alphaI_input\n",
    "    theta_act = (np.pi/180)*theta_input\n",
    "    \n",
    "    h_act = np.complex128(np.zeros((batch_size,M,K)))\n",
    "    hR_act = np.float32(np.zeros((batch_size,M,K)))\n",
    "    hI_act = np.float32(np.zeros((batch_size,M,K)))\n",
    "    \n",
    "    for kk in range(K):\n",
    "        for ll in range(Lp):\n",
    "            theta_act_expanded_temp = np.tile(np.reshape(theta_act[:,ll,kk],[-1,1]),(1,M))\n",
    "            response_temp = np.exp(1j*np.pi*np.multiply(np.sin(theta_act_expanded_temp),from0toM))\n",
    "            alpha_temp = np.reshape(alpha_act[:,ll,kk],[-1,1])\n",
    "            h_act[:,:,kk] += (1/np.sqrt(Lp))*alpha_temp*response_temp\n",
    "        hR_act[:,:,kk] = np.real(h_act[:,:,kk])\n",
    "        hI_act[:,:,kk] = np.imag(h_act[:,:,kk])\n",
    "        \n",
    "    h_act = torch.tensor(h_act, dtype = torch.complex64).to(device)\n",
    "    hR_act = torch.tensor(hR_act).to(device)\n",
    "    hI_act = torch.tensor(hI_act).to(device)\n",
    "        \n",
    "    return(h_act, hR_act, hI_act)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precoder, Rate 계산 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Precoder\n",
    "def ZF_Precoding(h_act):\n",
    "    H_act = h_act\n",
    "    V = torch.zeros((H_act.shape[0], H_act.shape[1], H_act.shape[2]), dtype=torch.complex64)\n",
    "    \n",
    "    for i in range(H_act.shape[0]):\n",
    "        V[i, :, :] = torch.linalg.pinv(H_act[i, :, :].T)\n",
    "        V[i, :, :] = V[i, :, :] / torch.sqrt(torch.trace(V[i, :, :] @ (V[i, :, :].H)))\n",
    "    \n",
    "    return V.to(device)\n",
    "    \n",
    "def MRT_Precoding(h_act):\n",
    "    H_act = h_act\n",
    "    V = torch.zeros((H_act.shape[0], H_act.shape[1], H_act.shape[2]), dtype=torch.complex64)\n",
    "    \n",
    "    for i in range(H_act.shape[0]):\n",
    "        V[i, :, :] = H_act[i, :, :].conj()\n",
    "        V[i, :, :] = V[i, :, :] / torch.sqrt(torch.trace(V[i, :, :] @ (V[i, :, :].H)))\n",
    "    \n",
    "    return V.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rate_calc(h_act_user, M, K, k_idx, V, noise_std):\n",
    "    H_act = h_act_user\n",
    "    nom_plus_denom = torch.zeros((H_act.shape[0], 1)).to(device) + torch.tensor(2 * noise_std ** 2).to(device)\n",
    "    \n",
    "    for kk in range(K):\n",
    "        product = torch.bmm(H_act.clone().unsqueeze(-1).permute(0, 2, 1), V[:, :, kk].clone().unsqueeze(-1)).squeeze(-1)\n",
    "        norm2 = torch.abs(product) ** 2\n",
    "        norm2.to(device)\n",
    "        \n",
    "        if kk == k_idx:\n",
    "            nom = norm2 # Wanted signal power\n",
    "        nom_plus_denom += norm2\n",
    "        \n",
    "    denom = nom_plus_denom - nom\n",
    "    rate = torch.mean(torch.log2(1 + (nom / denom)))\n",
    "    \n",
    "    return rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monte-Carlo Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actual channel generation\n",
    "h_act, _, _ = generate_batch_data(iter, M, K, Lp, LSF_UE, Mainlobe_UE, HalfBW_UE)\n",
    "rate_MRT, rate_ZF = 0, 0\n",
    "for kk in range(K):\n",
    "      rate_MRT += rate_calc(h_act[: ,:, kk], M, K, kk, MRT_Precoding(h_act), noise_std_dl)\n",
    "      rate_ZF += rate_calc(h_act[: ,:, kk], M, K, kk, ZF_Precoding(h_act), noise_std_dl)\n",
    "      \n",
    "# print('MRT rate : '+ rate_MRT + 'bps/Hz, ZF rate : '+ rate_ZF +'bps/Hz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000, 64, 2])\n"
     ]
    }
   ],
   "source": [
    "print(h_act.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(13.1916, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(rate_MRT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(15.3562, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(rate_ZF)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "acnl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
