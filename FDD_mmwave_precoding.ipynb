{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "import scipy.linalg as sci\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "## System parameters\n",
    "M = 64 #Number of BS antennas\n",
    "P = 1 #Power\n",
    "K =  2 #Number of users\n",
    "L = 8 #Number of pilots\n",
    "Lp = 2 #Number of paths\n",
    "B = 30 #Number of feedback bits per user\n",
    "\n",
    "## Limited scattering channel parameters\n",
    "LSF_UE = np.array([0.0,0.0],dtype=np.float32) #Mean of path gains for K users\n",
    "Mainlobe_UE= np.array([0,0],dtype=np.float32) #Center of the AoD range for K users\n",
    "HalfBW_UE = np.array([30.0,30.0],dtype=np.float32) #Half of the AoD range for K users\n",
    "\n",
    "# SNR\n",
    "snr_dl = 10 #SNR in dB\n",
    "snr_max_train = 10 #max training SNR in dB\n",
    "snr_min_train = 10 #min training SNR in dB\n",
    "noise_std_dl = np.float32(np.sqrt(1/2)*np.sqrt(P/10**(snr_dl/10))) #STD of the Gaussian noise (per real dim.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Learning parameters\n",
    "initial_run = 1 #1: starts training from scratch; 0: resumes training \n",
    "n_epochs = 10000 #Number of training epochs, for observing the current performance set it to 0\n",
    "learning_rate = 0.0001 #Learning rate\n",
    "batch_size = 1024 #Mini-batch size\n",
    "test_size = 10000 #Size of the validation/test set\n",
    "batch_per_epoch = 20 #Numbers of mini-batches per epoch\n",
    "anneal_param = 1.0 #Initial annealing parmeter\n",
    "annealing_rate = 1.001 #Annealing rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pilot Sequence 초기화 -- DFT Matrix 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DFT_Matrix = sci.dft(M) \n",
    "X_init = DFT_Matrix[0::int(np.ceil(M/L)),:] \n",
    "Xp_init = np.sqrt(P/M)*X_init\n",
    "Xp_r_init = torch.Tensor(np.float32(np.real(Xp_init))).to(device)\n",
    "Xp_i_init = torch.Tensor(np.float32(np.imag(Xp_init))).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix 연산 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mult_mod(M, N, left_right):\n",
    "    tensor_shape = M.shape\n",
    "    dims = N.shape \n",
    "\n",
    "    if left_right == 'r':\n",
    "        # M: (batch_size, n, m) N: (m, p)\n",
    "        n = tensor_shape[1]\n",
    "        m = dims[0]\n",
    "        p = dims[1]\n",
    "\n",
    "        # PyTorch의 행렬 곱\n",
    "        y = torch.reshape(torch.matmul(M.view(-1, m), N), (-1, n, p))\n",
    "\n",
    "    elif left_right == 'l':\n",
    "        # M: (batch_size, n, m)\n",
    "        # N: (p, n)\n",
    "        m = tensor_shape[2]\n",
    "        p = dims[0]\n",
    "        n = dims[1]\n",
    "\n",
    "        # PyTorch에서는 `permute()`로 전치 가능\n",
    "        MT = torch.Tensor(M).permute(0, 2, 1)  # (batch_size, m, n)\n",
    "        NT = N.T  # (n, p)\n",
    "\n",
    "        MTNT = torch.reshape(torch.matmul(MT.view(-1, n), NT), (-1, m, p))\n",
    "        y = MTNT.permute(0, 2, 1)  # (batch_size, n, p)로 변환\n",
    "\n",
    "    return y.to(device)\n",
    "\n",
    "def mult_mod_complex(Mr, Mi, Nr, Ni, left_right):\n",
    "    yr = mult_mod(Mr, Nr, left_right) - mult_mod(Mi, Ni, left_right)\n",
    "    yi = mult_mod(Mr, Ni, left_right) + mult_mod(Mi, Nr, left_right)\n",
    "    return yr.to(device), yi.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch data 생성 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 리스트 인덱싱은 [층, 행, 열], [행, 열]임!\n",
    "def generate_batch_data(batch_size,M,K,L,#number of paths\n",
    "                        LSF_UE #\n",
    "                        ,Mainlobe_UE,HalfBW_UE):\n",
    "    alphaR_input = np.zeros((batch_size,L,K))\n",
    "    alphaI_input = np.zeros((batch_size,L,K))\n",
    "    theta_input = np.zeros((batch_size,L,K))\n",
    "    for kk in range(K): # for the number of users\n",
    "        alphaR_input[:,:,kk] = np.random.normal(loc=LSF_UE[kk], scale=1.0/np.sqrt(2), size=[batch_size,L])\n",
    "        alphaI_input[:,:,kk] = np.random.normal(loc=LSF_UE[kk], scale=1.0/np.sqrt(2), size=[batch_size,L])\n",
    "        theta_input[:,:,kk] = np.random.uniform(low=Mainlobe_UE[kk]-HalfBW_UE[kk], high=Mainlobe_UE[kk]+HalfBW_UE[kk], size=[batch_size,L])\n",
    " \n",
    "    #### Actual Channel\n",
    "    from0toM = np.float32(np.arange(0, M, 1))\n",
    "    alpha_act = alphaR_input + 1j*alphaI_input\n",
    "    theta_act = (np.pi/180)*theta_input\n",
    "    \n",
    "    h_act = np.complex128(np.zeros((batch_size,M,K)))\n",
    "    hR_act = np.float32(np.zeros((batch_size,M,K)))\n",
    "    hI_act = np.float32(np.zeros((batch_size,M,K)))\n",
    "    for kk in range(K):\n",
    "        for ll in range(L):\n",
    "            theta_act_expanded_temp = np.tile(np.reshape(theta_act[:,ll,kk],[-1,1]),(1,M))\n",
    "            response_temp = np.exp(1j*np.pi*np.multiply(np.sin(theta_act_expanded_temp),from0toM))\n",
    "            alpha_temp = np.reshape(alpha_act[:,ll,kk],[-1,1])\n",
    "            h_act[:,:,kk] += (1/np.sqrt(L))*alpha_temp*response_temp\n",
    "        hR_act[:,:,kk] = np.real(h_act[:,:,kk])\n",
    "        hI_act[:,:,kk] = np.imag(h_act[:,:,kk])\n",
    "        \n",
    "    h_act = torch.tensor(h_act).to(device)\n",
    "    hR_act = torch.tensor(hR_act).to(device)\n",
    "    hI_act = torch.tensor(hI_act).to(device)\n",
    "        \n",
    "    return(h_act, hR_act, hI_act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가중치 초기화 함수 정의 (He 초기화)\n",
    "def he_init(tensor):\n",
    "    init.kaiming_normal_(tensor, mode='fan_in', nonlinearity='relu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력 데이터 텐서\n",
    "hR = torch.randn((batch_size, M, K), dtype=torch.float32)  # 실수 채널 행렬\n",
    "hI = torch.randn((batch_size, M, K), dtype=torch.float32)  # 허수 채널 행렬"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rate 계산 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rate_func(hr, hi, vr, vi, noise_power, K, M, k_index): # 실제 사용 시 k번째 루프 값에 대한 값 입력\n",
    "    vr = vr.reshape(-1, K, M).permute(0, 2, 1)  # 입력의 형태가 다를 수도 있어 변환을 두 번 해 줌\n",
    "    vi = vi.reshape(-1, K, M).permute(0, 2, 1)\n",
    "    \n",
    "    nom_denom = torch.zeros_like(torch.tensor(hr[:, :])).to(device) + noise_power.to(device)  # 초기화\n",
    "\n",
    "    for kk in range(K): # k번째 user에 대한 power 계산\n",
    "        hrvr = torch.bmm(vr[:, :, kk].unsqueeze(-1).permute(0, 2, 1), torch.tensor(hr).unsqueeze(-1)).squeeze(-1)\n",
    "        hivi = torch.bmm(vi[:, :, kk].unsqueeze(-1).permute(0, 2, 1), torch.tensor(hi).unsqueeze(-1)).squeeze(-1)\n",
    "        hrvi = torch.bmm(vi[:, :, kk].unsqueeze(-1).permute(0, 2, 1), torch.tensor(hr).unsqueeze(-1)).squeeze(-1)\n",
    "        hivr = torch.bmm(vr[:, :, kk].unsqueeze(-1).permute(0, 2, 1), torch.tensor(hi).unsqueeze(-1)).squeeze(-1)\n",
    "\n",
    "        real_part = hrvr - hivi \n",
    "        imag_part = hrvi + hivr\n",
    "        norm2_hv = real_part.abs()**2 + imag_part.abs()**2 \n",
    "\n",
    "        if kk == k_index:\n",
    "            nom = norm2_hv  # Wanted signal power\n",
    "        nom_denom += norm2_hv # Unwanted signal power\n",
    "\n",
    "    denom = nom_denom - nom\n",
    "    rate = torch.log2(1 + (nom / denom))\n",
    "    \n",
    "    return -rate.to(device)  # 손실 최소화를 위해 음수 처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downlink Pilot Training -- Pilot Sequence as DNN parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DLTrainingPhase(nn.Module):\n",
    "    def __init__(self, P, noise_std_dl):\n",
    "        super(DLTrainingPhase, self).__init__()\n",
    "        \n",
    "        # noise/annealing parameter\n",
    "        self.noise_std = torch.tensor(noise_std_dl, dtype=torch.float32).to(device)\n",
    "        self.aneal = torch.tensor(1.0, dtype=torch.float32).to(device)\n",
    "        \n",
    "        # Pilot sequence - Use pre-initialized values\n",
    "        self.Xp_r = nn.Parameter(Xp_r_init.clone().to(device))\n",
    "        self.Xp_i = nn.Parameter(Xp_i_init.clone().to(device))\n",
    "        \n",
    "        # Power normalizing\n",
    "        self.P = P\n",
    "        self.normalize_pilot()\n",
    "        \n",
    "    def normalize_pilot(self):\n",
    "        # Function : Normalizing the pilot sequence vectors\n",
    "        norm_X = torch.sqrt(torch.sum(self.Xp_r**2 + self.Xp_i**2, dim = 1, keepdim = True)) # (. , * , . ) *에 대해 sum 수행\n",
    "        self.Xp_r.data = torch.sqrt(torch.tensor(self.P)) * (self.Xp_r / norm_X)   \n",
    "        self.Xp_i.data = torch.sqrt(torch.tensor(self.P)) * (self.Xp_i / norm_X)\n",
    "        \n",
    "    def forward(self, hR, hI, K, M, L):\n",
    "        y_nless = {}\n",
    "        y_noisy = {}\n",
    "        \n",
    "        for kk in range(K):\n",
    "            hR_temp = hR[:, :, kk].reshape(-1, M, 1) # 차원 (batch_size, M)\n",
    "            hI_temp = hI[:, :, kk].reshape(-1, M, 1)\n",
    "\n",
    "            # 복소수 행렬 곱 수행\n",
    "            y_nless_r, y_nless_i = mult_mod_complex(hR_temp, hI_temp, self.Xp_r, self.Xp_i, 'l')\n",
    "\n",
    "            # 실수 및 허수 결합 -> 복소수로 결합 아니고 real representation\n",
    "            y_nless[kk] = torch.cat([y_nless_r.view(-1, L), y_nless_i.view(-1, L)], dim=1)\n",
    "\n",
    "            # 가우시안 노이즈 추가\n",
    "            noise = torch.randn_like(y_nless[kk]) * self.noise_std\n",
    "            y_noisy[kk] = y_nless[kk] + noise\n",
    "        \n",
    "        return y_noisy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UE side DNN - Quantizer for CSI feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UE_DNN(nn.Module):\n",
    "    def __init__(self, L, B, K, anneal = 1.0):\n",
    "        super(UE_DNN, self).__init__()\n",
    "        self.anneal = anneal\n",
    "        self.input_dim = 2*L\n",
    "        self.K=K\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            nn.BatchNorm1d(self.input_dim),\n",
    "            nn.Linear(self.input_dim, 1024),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Linear(256, B)\n",
    "        )\n",
    "        self.model.to(device)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        InfoBits = {0:0}\n",
    "        for kk in range(self.K):\n",
    "            InfoBits_linear = self.model(x[kk])  # 신경망을 통과한 값\n",
    "\n",
    "            # Straight-Through Estimator (STE) 적용\n",
    "            InfoBits_tanh = torch.tanh(self.anneal * InfoBits_linear)\n",
    "            InfoBits_sign = torch.sign(InfoBits_linear)\n",
    "\n",
    "            # Forward: Sign 값을 사용, Backward: Tanh gradient 사용\n",
    "            InfoBits[kk] = InfoBits_tanh + (InfoBits_sign - InfoBits_tanh).detach()\n",
    "        \n",
    "        return InfoBits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BS side DNN - Precoder network of DSC structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BS_DNN(nn.Module):\n",
    "    def __init__(self, M, K, B, P):\n",
    "        super(BS_DNN, self).__init__()\n",
    "        self.M = M\n",
    "        self.K = K\n",
    "        self.B = B\n",
    "        self.P = P\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(K * B, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Linear(512, 2* M * K)  # Precoder 출력 (실수 및 허수 파트)\n",
    "        )\n",
    "        \n",
    "        self.model.to(device)\n",
    "    \n",
    "    def forward(self, DNN_input_BS, hR, hI, noise_std):\n",
    "        # DNN_input_BS : UE에서 생성한 정보 입력 - (batch_size, K * B)\n",
    "        # hR, hI : channel matrix - (batch_size, M, K) - real/imag part\n",
    "        \n",
    "        #batch_size = DNN_input_BS[0].shape()\n",
    "        \n",
    "        # 0. Precoder input 생성\n",
    "        for kk in range(self.K):\n",
    "            if kk == 0:\n",
    "                precoder_input = DNN_input_BS[0]\n",
    "            else:\n",
    "                precoder_input = torch.concat((precoder_input, DNN_input_BS[kk]), dim = 1)\n",
    "        \n",
    "        # 1. Generate the precoder\n",
    "        precoder_output = self.model(precoder_input) # (batch_size, 2*M*K)\n",
    "        \n",
    "        # 2. seperate real/imag part\n",
    "        V_r, V_i = torch.chunk(precoder_output, 2, dim=1)\n",
    "        \n",
    "        # 3. power normalization\n",
    "        norm_V = torch.sqrt(torch.sum(V_r**2 + V_i**2, dim=1, keepdim=True))\n",
    "        V_r = np.sqrt(self.P) * (V_r / norm_V)\n",
    "        V_i = np.sqrt(self.P) * (V_i / norm_V)\n",
    "        \n",
    "        # 4. calculate sum rate\n",
    "        rate = {}\n",
    "        for kk in range(self.K):\n",
    "            rate[kk] = self.compute_rate(hR[:, :, kk], hI[:, :, kk], V_r, V_i, 2*noise_std**2, K, M, kk)\n",
    "            \n",
    "        # 5. MRT (Maximum Ratio Transmission) 기반 Baseline 계산\n",
    "        rate_UP = self.compute_mrt_baseline(hR, hI, noise_std)\n",
    "\n",
    "        return rate, rate_UP\n",
    "    \n",
    "    def compute_rate(self, hR_kk, hI_kk, V_r, V_i, noise_power, K, M, kk):\n",
    "        \n",
    "        # 채널 용량(Rate) 계산을 위한 함수\n",
    "        # hR_kk, hI_kk: 특정 사용자 kk에 대한 채널 정보\n",
    "        # V_r, V_i: Precoder의 실수 및 허수 부분\n",
    "        \n",
    "        # 여기에 Rate_func을 PyTorch로 변환하여 사용 가능\n",
    "        return rate_func(hR_kk, hI_kk, V_r, V_i, noise_power, K, M, kk)\n",
    "\n",
    "    def compute_mrt_baseline(self, hR, hI, noise_std):\n",
    "        \"\"\"\n",
    "        MRT (Maximum Ratio Transmission) 기반 Precoder 계산\n",
    "        \"\"\"\n",
    "        #batch_size = hR.shape[0]\n",
    "\n",
    "        # MRT Precoder 계산\n",
    "        h_complex = torch.complex(torch.tensor(hR), torch.tensor(hI))  # 복소수 채널 행렬 생성\n",
    "        V_MRT = h_complex.conj()  # 복소수 켤레 취함 (MRT 연산)\n",
    "\n",
    "        # 실수 및 허수 부분 분리\n",
    "        V_MRT_r = V_MRT.real\n",
    "        V_MRT_i = V_MRT.imag\n",
    "\n",
    "        # 전력 정규화 수행\n",
    "        norm_V_MRT = torch.sqrt(torch.sum(V_MRT_r**2 + V_MRT_i**2, dim=1, keepdim=True))\n",
    "        V_MRT_r = np.sqrt(self.P) * (V_MRT_r / norm_V_MRT)\n",
    "        V_MRT_i = np.sqrt(self.P) * (V_MRT_i / norm_V_MRT)\n",
    "\n",
    "        # 채널 용량(Rate) 계산\n",
    "        rate_UP = {}\n",
    "        for kk in range(self.K):\n",
    "            rate_UP[kk] = self.compute_rate(hR[:, :, kk], hI[:, :, kk], V_MRT_r, V_MRT_i, 2 * noise_std**2, self.K, self.M, kk)\n",
    "\n",
    "        return rate_UP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [],
   "source": [
    "pilot_train = DLTrainingPhase(P, noise_std_dl)\n",
    "ue_dnn = UE_DNN(L, B, K, annealing_rate)\n",
    "bs_dnn = BS_DNN(M, K, B, P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 학습하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Loss function 정의\n",
    "class CustomLoss(nn.Module):\n",
    "    def __init__(self, K):\n",
    "        super(CustomLoss, self).__init__()\n",
    "        self.K = K\n",
    "    \n",
    "    def forward(self, rate, rate_UP):\n",
    "        rate_total = sum(rate[k] for k in range(self.K))\n",
    "        rate_UP_total = sum(rate_UP[k] for k in range(self.K))\n",
    "        \n",
    "        loss = torch.mean(rate_total)\n",
    "        loss_UP = torch.mean(rate_UP_total)\n",
    "        \n",
    "        return loss, loss_UP\n",
    "    \n",
    "Lossfunc = CustomLoss(K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Optimizer 설정\n",
    "optimizer = optim.Adam(list(pilot_train.parameters())+list(ue_dnn.parameters())+list(bs_dnn.parameters())\n",
    "                       , lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\unist\\AppData\\Local\\Temp\\ipykernel_32040\\855499944.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  hR_test = torch.tensor(hR_test, dtype=torch.float32).to(device)\n",
      "C:\\Users\\unist\\AppData\\Local\\Temp\\ipykernel_32040\\855499944.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  hI_test = torch.tensor(hI_test, dtype=torch.float32).to(device)\n"
     ]
    }
   ],
   "source": [
    "## Test set 생성\n",
    "\n",
    "h_test, hR_test, hI_test = generate_batch_data(test_size, M, K, Lp, LSF_UE, Mainlobe_UE, HalfBW_UE)\n",
    "\n",
    "# Tensor 변환 후 GPU 할당\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "hR_test = torch.tensor(hR_test, dtype=torch.float32).to(device)\n",
    "hI_test = torch.tensor(hI_test, dtype=torch.float32).to(device)\n",
    "noise_std_test = torch.tensor(noise_std_dl, dtype=torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final dataset\n",
    "AA = sio.loadmat('Data_test_K2M64Lp2L8_withParams.mat')\n",
    "hR_test_Final = AA['hR_act_test_Final']\n",
    "hI_test_Final = AA['hI_act_test_Final']\n",
    "\n",
    "hR_test_Final = torch.tensor(hR_test_Final, dtype=torch.float32).to(device)\n",
    "hI_test_Final = torch.tensor(hI_test_Final, dtype=torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000, 64, 2])\n"
     ]
    }
   ],
   "source": [
    "print(hR_test.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 초기 모델 저장 경로 설정\n",
    "save_path = './params.pth'\n",
    "\n",
    "# 모델 불러오기 (처음 실행 여부 확인)\n",
    "initial_run = 1\n",
    "if initial_run == 0:\n",
    "    checkpoint = torch.load(save_path)\n",
    "    pilot_train.load_state_dict(checkpoint['pilot_train'])\n",
    "    bs_dnn.load_state_dict(checkpoint['bs_dnn'])\n",
    "    ue_dnn.load_state_dict(checkpoint['ue_dnn'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    best_loss = checkpoint['best_loss']\n",
    "    print(\"✅ 모델 파라미터 불러오기 완료!\")\n",
    "else:\n",
    "    best_loss = float('inf')  # 초기 Best Loss 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\unist\\AppData\\Local\\Temp\\ipykernel_32040\\1907439036.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nom_denom = torch.zeros_like(torch.tensor(hr[:, :])).to(device) + noise_power.to(device)  # 초기화\n",
      "C:\\Users\\unist\\AppData\\Local\\Temp\\ipykernel_32040\\1907439036.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  hrvr = torch.bmm(vr[:, :, kk].unsqueeze(-1).permute(0, 2, 1), torch.tensor(hr).unsqueeze(-1)).squeeze(-1)\n",
      "C:\\Users\\unist\\AppData\\Local\\Temp\\ipykernel_32040\\1907439036.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  hivi = torch.bmm(vi[:, :, kk].unsqueeze(-1).permute(0, 2, 1), torch.tensor(hi).unsqueeze(-1)).squeeze(-1)\n",
      "C:\\Users\\unist\\AppData\\Local\\Temp\\ipykernel_32040\\1907439036.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  hrvi = torch.bmm(vi[:, :, kk].unsqueeze(-1).permute(0, 2, 1), torch.tensor(hr).unsqueeze(-1)).squeeze(-1)\n",
      "C:\\Users\\unist\\AppData\\Local\\Temp\\ipykernel_32040\\1907439036.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  hivr = torch.bmm(vr[:, :, kk].unsqueeze(-1).permute(0, 2, 1), torch.tensor(hi).unsqueeze(-1)).squeeze(-1)\n",
      "C:\\Users\\unist\\AppData\\Local\\Temp\\ipykernel_32040\\4181443490.py:74: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  h_complex = torch.complex(torch.tensor(hR), torch.tensor(hI))  # 복소수 채널 행렬 생성\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model saved at epoch 0, Loss: -10.76688\n",
      "epoch 0  anneal_param:1.0000\n",
      "         loss_test:10.76688   best_test:10.76688   best_possible:1.27808  Percentage::8.424\n",
      "✅ Model saved at epoch 10, Loss: -10.91945\n",
      "epoch 10  anneal_param:1.0000\n",
      "         loss_test:10.91945   best_test:10.91945   best_possible:1.27808  Percentage::8.544\n",
      "✅ Model saved at epoch 20, Loss: -11.09061\n",
      "epoch 20  anneal_param:1.0000\n",
      "         loss_test:11.09061   best_test:11.09061   best_possible:1.27808  Percentage::8.678\n",
      "✅ Model saved at epoch 30, Loss: -11.22384\n",
      "epoch 30  anneal_param:1.0000\n",
      "         loss_test:11.22384   best_test:11.22384   best_possible:1.27808  Percentage::8.782\n",
      "✅ Model saved at epoch 40, Loss: -11.33687\n",
      "epoch 40  anneal_param:1.0000\n",
      "         loss_test:11.33687   best_test:11.33687   best_possible:1.27808  Percentage::8.870\n",
      "✅ Model saved at epoch 50, Loss: -11.46800\n",
      "epoch 50  anneal_param:1.0000\n",
      "         loss_test:11.46800   best_test:11.46800   best_possible:1.27808  Percentage::8.973\n",
      "✅ Model saved at epoch 60, Loss: -11.58441\n",
      "epoch 60  anneal_param:1.0000\n",
      "         loss_test:11.58441   best_test:11.58441   best_possible:1.27808  Percentage::9.064\n",
      "✅ Model saved at epoch 70, Loss: -11.71828\n",
      "epoch 70  anneal_param:1.0000\n",
      "         loss_test:11.71828   best_test:11.71828   best_possible:1.27808  Percentage::9.169\n",
      "✅ Model saved at epoch 80, Loss: -11.84036\n",
      "epoch 80  anneal_param:1.0000\n",
      "         loss_test:11.84036   best_test:11.84036   best_possible:1.27808  Percentage::9.264\n",
      "✅ Model saved at epoch 90, Loss: -11.96681\n",
      "epoch 90  anneal_param:1.0000\n",
      "         loss_test:11.96681   best_test:11.96681   best_possible:1.27808  Percentage::9.363\n",
      "✅ Model saved at epoch 100, Loss: -12.08265\n",
      "epoch 100  anneal_param:1.0000\n",
      "         loss_test:12.08265   best_test:12.08265   best_possible:1.27808  Percentage::9.454\n",
      "✅ Model saved at epoch 110, Loss: -12.17038\n",
      "epoch 110  anneal_param:1.0000\n",
      "         loss_test:12.17038   best_test:12.17038   best_possible:1.27808  Percentage::9.522\n",
      "✅ Model saved at epoch 120, Loss: -12.26963\n",
      "epoch 120  anneal_param:1.0000\n",
      "         loss_test:12.26963   best_test:12.26963   best_possible:1.27808  Percentage::9.600\n",
      "✅ Model saved at epoch 130, Loss: -12.33488\n",
      "epoch 130  anneal_param:1.0000\n",
      "         loss_test:12.33488   best_test:12.33488   best_possible:1.27808  Percentage::9.651\n",
      "✅ Model saved at epoch 140, Loss: -12.41357\n",
      "epoch 140  anneal_param:1.0000\n",
      "         loss_test:12.41357   best_test:12.41357   best_possible:1.27808  Percentage::9.713\n",
      "✅ Model saved at epoch 150, Loss: -12.47887\n",
      "epoch 150  anneal_param:1.0000\n",
      "         loss_test:12.47887   best_test:12.47887   best_possible:1.27808  Percentage::9.764\n",
      "✅ Model saved at epoch 160, Loss: -12.57103\n",
      "epoch 160  anneal_param:1.0000\n",
      "         loss_test:12.57103   best_test:12.57103   best_possible:1.27808  Percentage::9.836\n",
      "✅ Model saved at epoch 170, Loss: -12.63574\n",
      "epoch 170  anneal_param:1.0000\n",
      "         loss_test:12.63574   best_test:12.63574   best_possible:1.27808  Percentage::9.887\n",
      "✅ Model saved at epoch 180, Loss: -12.73149\n",
      "epoch 180  anneal_param:1.0000\n",
      "         loss_test:12.73149   best_test:12.73149   best_possible:1.27808  Percentage::9.961\n",
      "✅ Model saved at epoch 190, Loss: -12.81129\n",
      "epoch 190  anneal_param:1.0000\n",
      "         loss_test:12.81129   best_test:12.81129   best_possible:1.27808  Percentage::10.024\n",
      "✅ Model saved at epoch 200, Loss: -12.89287\n",
      "epoch 200  anneal_param:1.0000\n",
      "         loss_test:12.89287   best_test:12.89287   best_possible:1.27808  Percentage::10.088\n",
      "✅ Model saved at epoch 210, Loss: -12.93859\n",
      "epoch 210  anneal_param:1.0000\n",
      "         loss_test:12.93859   best_test:12.93859   best_possible:1.27808  Percentage::10.123\n",
      "✅ Model saved at epoch 220, Loss: -12.98704\n",
      "epoch 220  anneal_param:1.0000\n",
      "         loss_test:12.98704   best_test:12.98704   best_possible:1.27808  Percentage::10.161\n",
      "✅ Model saved at epoch 230, Loss: -13.05233\n",
      "epoch 230  anneal_param:1.0000\n",
      "         loss_test:13.05233   best_test:13.05233   best_possible:1.27808  Percentage::10.212\n",
      "✅ Model saved at epoch 240, Loss: -13.10685\n",
      "epoch 240  anneal_param:1.0000\n",
      "         loss_test:13.10685   best_test:13.10685   best_possible:1.27808  Percentage::10.255\n",
      "✅ Model saved at epoch 250, Loss: -13.13815\n",
      "epoch 250  anneal_param:1.0000\n",
      "         loss_test:13.13815   best_test:13.13815   best_possible:1.27808  Percentage::10.280\n",
      "✅ Model saved at epoch 260, Loss: -13.18305\n",
      "epoch 260  anneal_param:1.0000\n",
      "         loss_test:13.18305   best_test:13.18305   best_possible:1.27808  Percentage::10.315\n",
      "✅ Model saved at epoch 270, Loss: -13.20344\n",
      "epoch 270  anneal_param:1.0000\n",
      "         loss_test:13.20344   best_test:13.20344   best_possible:1.27808  Percentage::10.331\n",
      "✅ Model saved at epoch 280, Loss: -13.23064\n",
      "epoch 280  anneal_param:1.0000\n",
      "         loss_test:13.23064   best_test:13.23064   best_possible:1.27808  Percentage::10.352\n",
      "✅ Model saved at epoch 290, Loss: -13.26753\n",
      "epoch 290  anneal_param:1.0000\n",
      "         loss_test:13.26753   best_test:13.26753   best_possible:1.27808  Percentage::10.381\n",
      "✅ Model saved at epoch 300, Loss: -13.30641\n",
      "epoch 300  anneal_param:1.0000\n",
      "         loss_test:13.30641   best_test:13.30641   best_possible:1.27808  Percentage::10.411\n",
      "✅ Model saved at epoch 310, Loss: -13.32699\n",
      "epoch 310  anneal_param:1.0000\n",
      "         loss_test:13.32699   best_test:13.32699   best_possible:1.27808  Percentage::10.427\n",
      "✅ Model saved at epoch 320, Loss: -13.34467\n",
      "epoch 320  anneal_param:1.0000\n",
      "         loss_test:13.34467   best_test:13.34467   best_possible:1.27808  Percentage::10.441\n",
      "✅ Model saved at epoch 330, Loss: -13.36636\n",
      "epoch 330  anneal_param:1.0000\n",
      "         loss_test:13.36636   best_test:13.36636   best_possible:1.27808  Percentage::10.458\n",
      "✅ Model saved at epoch 340, Loss: -13.40092\n",
      "epoch 340  anneal_param:1.0000\n",
      "         loss_test:13.40092   best_test:13.40092   best_possible:1.27808  Percentage::10.485\n",
      "✅ Model saved at epoch 350, Loss: -13.40770\n",
      "epoch 350  anneal_param:1.0000\n",
      "         loss_test:13.40770   best_test:13.40770   best_possible:1.27808  Percentage::10.491\n",
      "✅ Model saved at epoch 360, Loss: -13.44103\n",
      "epoch 360  anneal_param:1.0000\n",
      "         loss_test:13.44103   best_test:13.44103   best_possible:1.27808  Percentage::10.517\n",
      "epoch 370  anneal_param:1.0010\n",
      "         loss_test:13.43948   best_test:13.44103   best_possible:1.27808  Percentage::10.517\n",
      "✅ Model saved at epoch 380, Loss: -13.45861\n",
      "epoch 380  anneal_param:1.0010\n",
      "         loss_test:13.45861   best_test:13.45861   best_possible:1.27808  Percentage::10.530\n",
      "✅ Model saved at epoch 390, Loss: -13.47550\n",
      "epoch 390  anneal_param:1.0010\n",
      "         loss_test:13.47550   best_test:13.47550   best_possible:1.27808  Percentage::10.544\n",
      "✅ Model saved at epoch 400, Loss: -13.48844\n",
      "epoch 400  anneal_param:1.0010\n",
      "         loss_test:13.48844   best_test:13.48844   best_possible:1.27808  Percentage::10.554\n",
      "epoch 410  anneal_param:1.0020\n",
      "         loss_test:13.47517   best_test:13.48844   best_possible:1.27808  Percentage::10.554\n",
      "✅ Model saved at epoch 420, Loss: -13.51433\n",
      "epoch 420  anneal_param:1.0020\n",
      "         loss_test:13.51433   best_test:13.51433   best_possible:1.27808  Percentage::10.574\n",
      "✅ Model saved at epoch 430, Loss: -13.53394\n",
      "epoch 430  anneal_param:1.0020\n",
      "         loss_test:13.53394   best_test:13.53394   best_possible:1.27808  Percentage::10.589\n",
      "epoch 440  anneal_param:1.0030\n",
      "         loss_test:13.53038   best_test:13.53394   best_possible:1.27808  Percentage::10.589\n",
      "epoch 450  anneal_param:1.0040\n",
      "         loss_test:13.52658   best_test:13.53394   best_possible:1.27808  Percentage::10.589\n",
      "✅ Model saved at epoch 460, Loss: -13.55157\n",
      "epoch 460  anneal_param:1.0040\n",
      "         loss_test:13.55157   best_test:13.55157   best_possible:1.27808  Percentage::10.603\n",
      "✅ Model saved at epoch 470, Loss: -13.55227\n",
      "epoch 470  anneal_param:1.0040\n",
      "         loss_test:13.55227   best_test:13.55227   best_possible:1.27808  Percentage::10.604\n",
      "✅ Model saved at epoch 480, Loss: -13.57572\n",
      "epoch 480  anneal_param:1.0040\n",
      "         loss_test:13.57572   best_test:13.57572   best_possible:1.27808  Percentage::10.622\n",
      "✅ Model saved at epoch 490, Loss: -13.57889\n",
      "epoch 490  anneal_param:1.0040\n",
      "         loss_test:13.57889   best_test:13.57889   best_possible:1.27808  Percentage::10.624\n",
      "✅ Model saved at epoch 500, Loss: -13.58151\n",
      "epoch 500  anneal_param:1.0040\n",
      "         loss_test:13.58151   best_test:13.58151   best_possible:1.27808  Percentage::10.627\n",
      "✅ Model saved at epoch 510, Loss: -13.59209\n",
      "epoch 510  anneal_param:1.0040\n",
      "         loss_test:13.59209   best_test:13.59209   best_possible:1.27808  Percentage::10.635\n",
      "✅ Model saved at epoch 520, Loss: -13.59917\n",
      "epoch 520  anneal_param:1.0040\n",
      "         loss_test:13.59917   best_test:13.59917   best_possible:1.27808  Percentage::10.640\n",
      "✅ Model saved at epoch 530, Loss: -13.59931\n",
      "epoch 530  anneal_param:1.0040\n",
      "         loss_test:13.59931   best_test:13.59931   best_possible:1.27808  Percentage::10.640\n",
      "✅ Model saved at epoch 540, Loss: -13.61183\n",
      "epoch 540  anneal_param:1.0040\n",
      "         loss_test:13.61183   best_test:13.61183   best_possible:1.27808  Percentage::10.650\n",
      "epoch 550  anneal_param:1.0050\n",
      "         loss_test:13.60174   best_test:13.61183   best_possible:1.27808  Percentage::10.650\n",
      "✅ Model saved at epoch 560, Loss: -13.62740\n",
      "epoch 560  anneal_param:1.0050\n",
      "         loss_test:13.62740   best_test:13.62740   best_possible:1.27808  Percentage::10.662\n",
      "epoch 570  anneal_param:1.0060\n",
      "         loss_test:13.60949   best_test:13.62740   best_possible:1.27808  Percentage::10.662\n",
      "✅ Model saved at epoch 580, Loss: -13.63513\n",
      "epoch 580  anneal_param:1.0060\n",
      "         loss_test:13.63513   best_test:13.63513   best_possible:1.27808  Percentage::10.668\n",
      "✅ Model saved at epoch 590, Loss: -13.65208\n",
      "epoch 590  anneal_param:1.0060\n",
      "         loss_test:13.65208   best_test:13.65208   best_possible:1.27808  Percentage::10.682\n",
      "✅ Model saved at epoch 600, Loss: -13.65314\n",
      "epoch 600  anneal_param:1.0060\n",
      "         loss_test:13.65314   best_test:13.65314   best_possible:1.27808  Percentage::10.683\n",
      "epoch 610  anneal_param:1.0070\n",
      "         loss_test:13.64883   best_test:13.65314   best_possible:1.27808  Percentage::10.683\n",
      "epoch 620  anneal_param:1.0080\n",
      "         loss_test:13.64303   best_test:13.65314   best_possible:1.27808  Percentage::10.683\n",
      "✅ Model saved at epoch 630, Loss: -13.66165\n",
      "epoch 630  anneal_param:1.0080\n",
      "         loss_test:13.66165   best_test:13.66165   best_possible:1.27808  Percentage::10.689\n",
      "✅ Model saved at epoch 640, Loss: -13.66176\n",
      "epoch 640  anneal_param:1.0080\n",
      "         loss_test:13.66176   best_test:13.66176   best_possible:1.27808  Percentage::10.689\n",
      "epoch 650  anneal_param:1.0090\n",
      "         loss_test:13.65902   best_test:13.66176   best_possible:1.27808  Percentage::10.689\n",
      "✅ Model saved at epoch 660, Loss: -13.67358\n",
      "epoch 660  anneal_param:1.0090\n",
      "         loss_test:13.67358   best_test:13.67358   best_possible:1.27808  Percentage::10.699\n",
      "epoch 670  anneal_param:1.0100\n",
      "         loss_test:13.66509   best_test:13.67358   best_possible:1.27808  Percentage::10.699\n",
      "✅ Model saved at epoch 680, Loss: -13.69250\n",
      "epoch 680  anneal_param:1.0100\n",
      "         loss_test:13.69250   best_test:13.69250   best_possible:1.27808  Percentage::10.713\n",
      "epoch 690  anneal_param:1.0111\n",
      "         loss_test:13.68119   best_test:13.69250   best_possible:1.27808  Percentage::10.713\n",
      "epoch 700  anneal_param:1.0121\n",
      "         loss_test:13.67833   best_test:13.69250   best_possible:1.27808  Percentage::10.713\n",
      "✅ Model saved at epoch 710, Loss: -13.69683\n",
      "epoch 710  anneal_param:1.0121\n",
      "         loss_test:13.69683   best_test:13.69683   best_possible:1.27808  Percentage::10.717\n",
      "epoch 720  anneal_param:1.0131\n",
      "         loss_test:13.68880   best_test:13.69683   best_possible:1.27808  Percentage::10.717\n",
      "epoch 730  anneal_param:1.0141\n",
      "         loss_test:13.68764   best_test:13.69683   best_possible:1.27808  Percentage::10.717\n",
      "epoch 740  anneal_param:1.0151\n",
      "         loss_test:13.69165   best_test:13.69683   best_possible:1.27808  Percentage::10.717\n",
      "✅ Model saved at epoch 750, Loss: -13.70160\n",
      "epoch 750  anneal_param:1.0151\n",
      "         loss_test:13.70160   best_test:13.70160   best_possible:1.27808  Percentage::10.720\n",
      "epoch 760  anneal_param:1.0161\n",
      "         loss_test:13.69854   best_test:13.70160   best_possible:1.27808  Percentage::10.720\n",
      "✅ Model saved at epoch 770, Loss: -13.72496\n",
      "epoch 770  anneal_param:1.0161\n",
      "         loss_test:13.72496   best_test:13.72496   best_possible:1.27808  Percentage::10.739\n",
      "epoch 780  anneal_param:1.0171\n",
      "         loss_test:13.71077   best_test:13.72496   best_possible:1.27808  Percentage::10.739\n",
      "epoch 790  anneal_param:1.0182\n",
      "         loss_test:13.71735   best_test:13.72496   best_possible:1.27808  Percentage::10.739\n",
      "epoch 800  anneal_param:1.0192\n",
      "         loss_test:13.71741   best_test:13.72496   best_possible:1.27808  Percentage::10.739\n",
      "epoch 810  anneal_param:1.0202\n",
      "         loss_test:13.72242   best_test:13.72496   best_possible:1.27808  Percentage::10.739\n",
      "✅ Model saved at epoch 820, Loss: -13.73112\n",
      "epoch 820  anneal_param:1.0202\n",
      "         loss_test:13.73112   best_test:13.73112   best_possible:1.27808  Percentage::10.744\n",
      "epoch 830  anneal_param:1.0212\n",
      "         loss_test:13.71902   best_test:13.73112   best_possible:1.27808  Percentage::10.744\n",
      "epoch 840  anneal_param:1.0222\n",
      "         loss_test:13.72811   best_test:13.73112   best_possible:1.27808  Percentage::10.744\n",
      "✅ Model saved at epoch 850, Loss: -13.75706\n",
      "epoch 850  anneal_param:1.0222\n",
      "         loss_test:13.75706   best_test:13.75706   best_possible:1.27808  Percentage::10.764\n",
      "epoch 860  anneal_param:1.0233\n",
      "         loss_test:13.74789   best_test:13.75706   best_possible:1.27808  Percentage::10.764\n",
      "✅ Model saved at epoch 870, Loss: -13.75776\n",
      "epoch 870  anneal_param:1.0233\n",
      "         loss_test:13.75776   best_test:13.75776   best_possible:1.27808  Percentage::10.764\n",
      "epoch 880  anneal_param:1.0243\n",
      "         loss_test:13.74854   best_test:13.75776   best_possible:1.27808  Percentage::10.764\n",
      "epoch 890  anneal_param:1.0253\n",
      "         loss_test:13.75451   best_test:13.75776   best_possible:1.27808  Percentage::10.764\n",
      "epoch 900  anneal_param:1.0263\n",
      "         loss_test:13.75552   best_test:13.75776   best_possible:1.27808  Percentage::10.764\n",
      "epoch 910  anneal_param:1.0274\n",
      "         loss_test:13.75776   best_test:13.75776   best_possible:1.27808  Percentage::10.764\n",
      "epoch 920  anneal_param:1.0284\n",
      "         loss_test:13.74826   best_test:13.75776   best_possible:1.27808  Percentage::10.764\n",
      "✅ Model saved at epoch 930, Loss: -13.76306\n",
      "epoch 930  anneal_param:1.0284\n",
      "         loss_test:13.76306   best_test:13.76306   best_possible:1.27808  Percentage::10.769\n",
      "✅ Model saved at epoch 940, Loss: -13.77761\n",
      "epoch 940  anneal_param:1.0284\n",
      "         loss_test:13.77761   best_test:13.77761   best_possible:1.27808  Percentage::10.780\n",
      "✅ Model saved at epoch 950, Loss: -13.78380\n",
      "epoch 950  anneal_param:1.0284\n",
      "         loss_test:13.78380   best_test:13.78380   best_possible:1.27808  Percentage::10.785\n",
      "epoch 960  anneal_param:1.0294\n",
      "         loss_test:13.78133   best_test:13.78380   best_possible:1.27808  Percentage::10.785\n",
      "✅ Model saved at epoch 970, Loss: -13.78674\n",
      "epoch 970  anneal_param:1.0294\n",
      "         loss_test:13.78674   best_test:13.78674   best_possible:1.27808  Percentage::10.787\n",
      "epoch 980  anneal_param:1.0304\n",
      "         loss_test:13.78608   best_test:13.78674   best_possible:1.27808  Percentage::10.787\n",
      "✅ Model saved at epoch 990, Loss: -13.80179\n",
      "epoch 990  anneal_param:1.0304\n",
      "         loss_test:13.80179   best_test:13.80179   best_possible:1.27808  Percentage::10.799\n",
      "epoch 1000  anneal_param:1.0315\n",
      "         loss_test:13.78505   best_test:13.80179   best_possible:1.27808  Percentage::10.799\n",
      "epoch 1010  anneal_param:1.0325\n",
      "         loss_test:13.78556   best_test:13.80179   best_possible:1.27808  Percentage::10.799\n",
      "epoch 1020  anneal_param:1.0335\n",
      "         loss_test:13.78984   best_test:13.80179   best_possible:1.27808  Percentage::10.799\n",
      "epoch 1030  anneal_param:1.0346\n",
      "         loss_test:13.79466   best_test:13.80179   best_possible:1.27808  Percentage::10.799\n",
      "epoch 1040  anneal_param:1.0356\n",
      "         loss_test:13.80177   best_test:13.80179   best_possible:1.27808  Percentage::10.799\n",
      "epoch 1050  anneal_param:1.0366\n",
      "         loss_test:13.79925   best_test:13.80179   best_possible:1.27808  Percentage::10.799\n",
      "epoch 1060  anneal_param:1.0377\n",
      "         loss_test:13.80134   best_test:13.80179   best_possible:1.27808  Percentage::10.799\n",
      "✅ Model saved at epoch 1070, Loss: -13.80633\n",
      "epoch 1070  anneal_param:1.0377\n",
      "         loss_test:13.80633   best_test:13.80633   best_possible:1.27808  Percentage::10.802\n",
      "✅ Model saved at epoch 1080, Loss: -13.81589\n",
      "epoch 1080  anneal_param:1.0377\n",
      "         loss_test:13.81589   best_test:13.81589   best_possible:1.27808  Percentage::10.810\n",
      "✅ Model saved at epoch 1090, Loss: -13.81624\n",
      "epoch 1090  anneal_param:1.0377\n",
      "         loss_test:13.81624   best_test:13.81624   best_possible:1.27808  Percentage::10.810\n",
      "epoch 1100  anneal_param:1.0387\n",
      "         loss_test:13.81120   best_test:13.81624   best_possible:1.27808  Percentage::10.810\n",
      "epoch 1110  anneal_param:1.0398\n",
      "         loss_test:13.81095   best_test:13.81624   best_possible:1.27808  Percentage::10.810\n",
      "✅ Model saved at epoch 1120, Loss: -13.81850\n",
      "epoch 1120  anneal_param:1.0398\n",
      "         loss_test:13.81850   best_test:13.81850   best_possible:1.27808  Percentage::10.812\n",
      "✅ Model saved at epoch 1130, Loss: -13.82824\n",
      "epoch 1130  anneal_param:1.0398\n",
      "         loss_test:13.82824   best_test:13.82824   best_possible:1.27808  Percentage::10.820\n",
      "epoch 1140  anneal_param:1.0408\n",
      "         loss_test:13.82135   best_test:13.82824   best_possible:1.27808  Percentage::10.820\n",
      "✅ Model saved at epoch 1150, Loss: -13.84235\n",
      "epoch 1150  anneal_param:1.0408\n",
      "         loss_test:13.84235   best_test:13.84235   best_possible:1.27808  Percentage::10.831\n",
      "epoch 1160  anneal_param:1.0418\n",
      "         loss_test:13.83128   best_test:13.84235   best_possible:1.27808  Percentage::10.831\n",
      "epoch 1170  anneal_param:1.0429\n",
      "         loss_test:13.83427   best_test:13.84235   best_possible:1.27808  Percentage::10.831\n",
      "epoch 1180  anneal_param:1.0439\n",
      "         loss_test:13.83764   best_test:13.84235   best_possible:1.27808  Percentage::10.831\n",
      "✅ Model saved at epoch 1190, Loss: -13.84785\n",
      "epoch 1190  anneal_param:1.0439\n",
      "         loss_test:13.84785   best_test:13.84785   best_possible:1.27808  Percentage::10.835\n",
      "epoch 1200  anneal_param:1.0450\n",
      "         loss_test:13.84004   best_test:13.84785   best_possible:1.27808  Percentage::10.835\n",
      "epoch 1210  anneal_param:1.0460\n",
      "         loss_test:13.84302   best_test:13.84785   best_possible:1.27808  Percentage::10.835\n",
      "epoch 1220  anneal_param:1.0471\n",
      "         loss_test:13.83861   best_test:13.84785   best_possible:1.27808  Percentage::10.835\n",
      "epoch 1230  anneal_param:1.0481\n",
      "         loss_test:13.84323   best_test:13.84785   best_possible:1.27808  Percentage::10.835\n",
      "✅ Model saved at epoch 1240, Loss: -13.84811\n",
      "epoch 1240  anneal_param:1.0481\n",
      "         loss_test:13.84811   best_test:13.84811   best_possible:1.27808  Percentage::10.835\n",
      "✅ Model saved at epoch 1250, Loss: -13.85193\n",
      "epoch 1250  anneal_param:1.0481\n",
      "         loss_test:13.85193   best_test:13.85193   best_possible:1.27808  Percentage::10.838\n",
      "epoch 1260  anneal_param:1.0491\n",
      "         loss_test:13.84784   best_test:13.85193   best_possible:1.27808  Percentage::10.838\n",
      "epoch 1270  anneal_param:1.0502\n",
      "         loss_test:13.84792   best_test:13.85193   best_possible:1.27808  Percentage::10.838\n",
      "epoch 1280  anneal_param:1.0512\n",
      "         loss_test:13.84707   best_test:13.85193   best_possible:1.27808  Percentage::10.838\n",
      "✅ Model saved at epoch 1290, Loss: -13.85483\n",
      "epoch 1290  anneal_param:1.0512\n",
      "         loss_test:13.85483   best_test:13.85483   best_possible:1.27808  Percentage::10.840\n",
      "✅ Model saved at epoch 1300, Loss: -13.86667\n",
      "epoch 1300  anneal_param:1.0512\n",
      "         loss_test:13.86667   best_test:13.86667   best_possible:1.27808  Percentage::10.850\n",
      "epoch 1310  anneal_param:1.0523\n",
      "         loss_test:13.85192   best_test:13.86667   best_possible:1.27808  Percentage::10.850\n",
      "✅ Model saved at epoch 1320, Loss: -13.86901\n",
      "epoch 1320  anneal_param:1.0523\n",
      "         loss_test:13.86901   best_test:13.86901   best_possible:1.27808  Percentage::10.851\n",
      "✅ Model saved at epoch 1330, Loss: -13.88052\n",
      "epoch 1330  anneal_param:1.0523\n",
      "         loss_test:13.88052   best_test:13.88052   best_possible:1.27808  Percentage::10.860\n",
      "epoch 1340  anneal_param:1.0533\n",
      "         loss_test:13.86867   best_test:13.88052   best_possible:1.27808  Percentage::10.860\n",
      "epoch 1350  anneal_param:1.0544\n",
      "         loss_test:13.85454   best_test:13.88052   best_possible:1.27808  Percentage::10.860\n",
      "epoch 1360  anneal_param:1.0555\n",
      "         loss_test:13.87700   best_test:13.88052   best_possible:1.27808  Percentage::10.860\n",
      "epoch 1370  anneal_param:1.0565\n",
      "         loss_test:13.87528   best_test:13.88052   best_possible:1.27808  Percentage::10.860\n",
      "epoch 1380  anneal_param:1.0576\n",
      "         loss_test:13.86972   best_test:13.88052   best_possible:1.27808  Percentage::10.860\n",
      "epoch 1390  anneal_param:1.0586\n",
      "         loss_test:13.87589   best_test:13.88052   best_possible:1.27808  Percentage::10.860\n",
      "✅ Model saved at epoch 1400, Loss: -13.88067\n",
      "epoch 1400  anneal_param:1.0586\n",
      "         loss_test:13.88067   best_test:13.88067   best_possible:1.27808  Percentage::10.861\n",
      "epoch 1410  anneal_param:1.0597\n",
      "         loss_test:13.87173   best_test:13.88067   best_possible:1.27808  Percentage::10.861\n",
      "✅ Model saved at epoch 1420, Loss: -13.88298\n",
      "epoch 1420  anneal_param:1.0597\n",
      "         loss_test:13.88298   best_test:13.88298   best_possible:1.27808  Percentage::10.862\n",
      "✅ Model saved at epoch 1430, Loss: -13.88493\n",
      "epoch 1430  anneal_param:1.0597\n",
      "         loss_test:13.88493   best_test:13.88493   best_possible:1.27808  Percentage::10.864\n",
      "epoch 1440  anneal_param:1.0607\n",
      "         loss_test:13.87723   best_test:13.88493   best_possible:1.27808  Percentage::10.864\n",
      "epoch 1450  anneal_param:1.0618\n",
      "         loss_test:13.87330   best_test:13.88493   best_possible:1.27808  Percentage::10.864\n",
      "epoch 1460  anneal_param:1.0629\n",
      "         loss_test:13.87049   best_test:13.88493   best_possible:1.27808  Percentage::10.864\n",
      "✅ Model saved at epoch 1470, Loss: -13.88586\n",
      "epoch 1470  anneal_param:1.0629\n",
      "         loss_test:13.88586   best_test:13.88586   best_possible:1.27808  Percentage::10.865\n",
      "✅ Model saved at epoch 1480, Loss: -13.89078\n",
      "epoch 1480  anneal_param:1.0629\n",
      "         loss_test:13.89078   best_test:13.89078   best_possible:1.27808  Percentage::10.868\n",
      "✅ Model saved at epoch 1490, Loss: -13.90443\n",
      "epoch 1490  anneal_param:1.0629\n",
      "         loss_test:13.90443   best_test:13.90443   best_possible:1.27808  Percentage::10.879\n",
      "epoch 1500  anneal_param:1.0639\n",
      "         loss_test:13.88870   best_test:13.90443   best_possible:1.27808  Percentage::10.879\n",
      "epoch 1510  anneal_param:1.0650\n",
      "         loss_test:13.89675   best_test:13.90443   best_possible:1.27808  Percentage::10.879\n",
      "epoch 1520  anneal_param:1.0661\n",
      "         loss_test:13.88837   best_test:13.90443   best_possible:1.27808  Percentage::10.879\n",
      "epoch 1530  anneal_param:1.0671\n",
      "         loss_test:13.90370   best_test:13.90443   best_possible:1.27808  Percentage::10.879\n",
      "✅ Model saved at epoch 1540, Loss: -13.91031\n",
      "epoch 1540  anneal_param:1.0671\n",
      "         loss_test:13.91031   best_test:13.91031   best_possible:1.27808  Percentage::10.884\n",
      "✅ Model saved at epoch 1550, Loss: -13.91768\n",
      "epoch 1550  anneal_param:1.0671\n",
      "         loss_test:13.91768   best_test:13.91768   best_possible:1.27808  Percentage::10.890\n",
      "epoch 1560  anneal_param:1.0682\n",
      "         loss_test:13.91211   best_test:13.91768   best_possible:1.27808  Percentage::10.890\n",
      "epoch 1570  anneal_param:1.0693\n",
      "         loss_test:13.91028   best_test:13.91768   best_possible:1.27808  Percentage::10.890\n",
      "epoch 1580  anneal_param:1.0703\n",
      "         loss_test:13.91365   best_test:13.91768   best_possible:1.27808  Percentage::10.890\n",
      "epoch 1590  anneal_param:1.0714\n",
      "         loss_test:13.91110   best_test:13.91768   best_possible:1.27808  Percentage::10.890\n",
      "✅ Model saved at epoch 1600, Loss: -13.92850\n",
      "epoch 1600  anneal_param:1.0714\n",
      "         loss_test:13.92850   best_test:13.92850   best_possible:1.27808  Percentage::10.898\n",
      "epoch 1610  anneal_param:1.0725\n",
      "         loss_test:13.92111   best_test:13.92850   best_possible:1.27808  Percentage::10.898\n",
      "epoch 1620  anneal_param:1.0735\n",
      "         loss_test:13.91424   best_test:13.92850   best_possible:1.27808  Percentage::10.898\n",
      "epoch 1630  anneal_param:1.0746\n",
      "         loss_test:13.91620   best_test:13.92850   best_possible:1.27808  Percentage::10.898\n",
      "epoch 1640  anneal_param:1.0757\n",
      "         loss_test:13.92430   best_test:13.92850   best_possible:1.27808  Percentage::10.898\n",
      "epoch 1650  anneal_param:1.0768\n",
      "         loss_test:13.92739   best_test:13.92850   best_possible:1.27808  Percentage::10.898\n",
      "✅ Model saved at epoch 1660, Loss: -13.93112\n",
      "epoch 1660  anneal_param:1.0768\n",
      "         loss_test:13.93112   best_test:13.93112   best_possible:1.27808  Percentage::10.900\n",
      "epoch 1670  anneal_param:1.0778\n",
      "         loss_test:13.92103   best_test:13.93112   best_possible:1.27808  Percentage::10.900\n",
      "epoch 1680  anneal_param:1.0789\n",
      "         loss_test:13.92313   best_test:13.93112   best_possible:1.27808  Percentage::10.900\n",
      "✅ Model saved at epoch 1690, Loss: -13.93281\n",
      "epoch 1690  anneal_param:1.0789\n",
      "         loss_test:13.93281   best_test:13.93281   best_possible:1.27808  Percentage::10.901\n",
      "✅ Model saved at epoch 1700, Loss: -13.93668\n",
      "epoch 1700  anneal_param:1.0789\n",
      "         loss_test:13.93668   best_test:13.93668   best_possible:1.27808  Percentage::10.904\n",
      "epoch 1710  anneal_param:1.0800\n",
      "         loss_test:13.92828   best_test:13.93668   best_possible:1.27808  Percentage::10.904\n",
      "✅ Model saved at epoch 1720, Loss: -13.94054\n",
      "epoch 1720  anneal_param:1.0800\n",
      "         loss_test:13.94054   best_test:13.94054   best_possible:1.27808  Percentage::10.907\n",
      "epoch 1730  anneal_param:1.0811\n",
      "         loss_test:13.93832   best_test:13.94054   best_possible:1.27808  Percentage::10.907\n",
      "✅ Model saved at epoch 1740, Loss: -13.94459\n",
      "epoch 1740  anneal_param:1.0811\n",
      "         loss_test:13.94459   best_test:13.94459   best_possible:1.27808  Percentage::10.911\n",
      "✅ Model saved at epoch 1750, Loss: -13.94916\n",
      "epoch 1750  anneal_param:1.0811\n",
      "         loss_test:13.94916   best_test:13.94916   best_possible:1.27808  Percentage::10.914\n",
      "✅ Model saved at epoch 1760, Loss: -13.95122\n",
      "epoch 1760  anneal_param:1.0811\n",
      "         loss_test:13.95122   best_test:13.95122   best_possible:1.27808  Percentage::10.916\n",
      "epoch 1770  anneal_param:1.0822\n",
      "         loss_test:13.94719   best_test:13.95122   best_possible:1.27808  Percentage::10.916\n",
      "✅ Model saved at epoch 1780, Loss: -13.95152\n",
      "epoch 1780  anneal_param:1.0822\n",
      "         loss_test:13.95152   best_test:13.95152   best_possible:1.27808  Percentage::10.916\n",
      "✅ Model saved at epoch 1790, Loss: -13.95820\n",
      "epoch 1790  anneal_param:1.0822\n",
      "         loss_test:13.95820   best_test:13.95820   best_possible:1.27808  Percentage::10.921\n",
      "epoch 1800  anneal_param:1.0832\n",
      "         loss_test:13.95713   best_test:13.95820   best_possible:1.27808  Percentage::10.921\n",
      "epoch 1810  anneal_param:1.0843\n",
      "         loss_test:13.95164   best_test:13.95820   best_possible:1.27808  Percentage::10.921\n",
      "epoch 1820  anneal_param:1.0854\n",
      "         loss_test:13.94242   best_test:13.95820   best_possible:1.27808  Percentage::10.921\n",
      "epoch 1830  anneal_param:1.0865\n",
      "         loss_test:13.95131   best_test:13.95820   best_possible:1.27808  Percentage::10.921\n",
      "✅ Model saved at epoch 1840, Loss: -13.96010\n",
      "epoch 1840  anneal_param:1.0865\n",
      "         loss_test:13.96010   best_test:13.96010   best_possible:1.27808  Percentage::10.923\n",
      "✅ Model saved at epoch 1850, Loss: -13.96082\n",
      "epoch 1850  anneal_param:1.0865\n",
      "         loss_test:13.96082   best_test:13.96082   best_possible:1.27808  Percentage::10.923\n",
      "✅ Model saved at epoch 1860, Loss: -13.96382\n",
      "epoch 1860  anneal_param:1.0865\n",
      "         loss_test:13.96382   best_test:13.96382   best_possible:1.27808  Percentage::10.926\n",
      "epoch 1870  anneal_param:1.0876\n",
      "         loss_test:13.96378   best_test:13.96382   best_possible:1.27808  Percentage::10.926\n",
      "✅ Model saved at epoch 1880, Loss: -13.96737\n",
      "epoch 1880  anneal_param:1.0876\n",
      "         loss_test:13.96737   best_test:13.96737   best_possible:1.27808  Percentage::10.928\n",
      "epoch 1890  anneal_param:1.0887\n",
      "         loss_test:13.95992   best_test:13.96737   best_possible:1.27808  Percentage::10.928\n",
      "epoch 1900  anneal_param:1.0898\n",
      "         loss_test:13.96198   best_test:13.96737   best_possible:1.27808  Percentage::10.928\n",
      "✅ Model saved at epoch 1910, Loss: -13.96822\n",
      "epoch 1910  anneal_param:1.0898\n",
      "         loss_test:13.96822   best_test:13.96822   best_possible:1.27808  Percentage::10.929\n",
      "epoch 1920  anneal_param:1.0908\n",
      "         loss_test:13.96340   best_test:13.96822   best_possible:1.27808  Percentage::10.929\n",
      "✅ Model saved at epoch 1930, Loss: -13.97327\n",
      "epoch 1930  anneal_param:1.0908\n",
      "         loss_test:13.97327   best_test:13.97327   best_possible:1.27808  Percentage::10.933\n",
      "epoch 1940  anneal_param:1.0919\n",
      "         loss_test:13.96410   best_test:13.97327   best_possible:1.27808  Percentage::10.933\n",
      "✅ Model saved at epoch 1950, Loss: -13.97548\n",
      "epoch 1950  anneal_param:1.0919\n",
      "         loss_test:13.97548   best_test:13.97548   best_possible:1.27808  Percentage::10.935\n",
      "✅ Model saved at epoch 1960, Loss: -13.98318\n",
      "epoch 1960  anneal_param:1.0919\n",
      "         loss_test:13.98318   best_test:13.98318   best_possible:1.27808  Percentage::10.941\n",
      "✅ Model saved at epoch 1970, Loss: -13.98899\n",
      "epoch 1970  anneal_param:1.0919\n",
      "         loss_test:13.98899   best_test:13.98899   best_possible:1.27808  Percentage::10.945\n",
      "epoch 1980  anneal_param:1.0930\n",
      "         loss_test:13.98762   best_test:13.98899   best_possible:1.27808  Percentage::10.945\n",
      "epoch 1990  anneal_param:1.0941\n",
      "         loss_test:13.97523   best_test:13.98899   best_possible:1.27808  Percentage::10.945\n",
      "✅ Model saved at epoch 2000, Loss: -13.99007\n",
      "epoch 2000  anneal_param:1.0941\n",
      "         loss_test:13.99007   best_test:13.99007   best_possible:1.27808  Percentage::10.946\n",
      "epoch 2010  anneal_param:1.0952\n",
      "         loss_test:13.98550   best_test:13.99007   best_possible:1.27808  Percentage::10.946\n",
      "epoch 2020  anneal_param:1.0963\n",
      "         loss_test:13.98200   best_test:13.99007   best_possible:1.27808  Percentage::10.946\n",
      "✅ Model saved at epoch 2030, Loss: -13.99377\n",
      "epoch 2030  anneal_param:1.0963\n",
      "         loss_test:13.99377   best_test:13.99377   best_possible:1.27808  Percentage::10.949\n",
      "epoch 2040  anneal_param:1.0974\n",
      "         loss_test:13.98984   best_test:13.99377   best_possible:1.27808  Percentage::10.949\n",
      "epoch 2050  anneal_param:1.0985\n",
      "         loss_test:13.98811   best_test:13.99377   best_possible:1.27808  Percentage::10.949\n",
      "epoch 2060  anneal_param:1.0996\n",
      "         loss_test:13.98704   best_test:13.99377   best_possible:1.27808  Percentage::10.949\n",
      "epoch 2070  anneal_param:1.1007\n",
      "         loss_test:13.99233   best_test:13.99377   best_possible:1.27808  Percentage::10.949\n",
      "epoch 2080  anneal_param:1.1018\n",
      "         loss_test:13.98553   best_test:13.99377   best_possible:1.27808  Percentage::10.949\n",
      "✅ Model saved at epoch 2090, Loss: -14.00245\n",
      "epoch 2090  anneal_param:1.1018\n",
      "         loss_test:14.00245   best_test:14.00245   best_possible:1.27808  Percentage::10.956\n",
      "epoch 2100  anneal_param:1.1029\n",
      "         loss_test:13.98783   best_test:14.00245   best_possible:1.27808  Percentage::10.956\n",
      "epoch 2110  anneal_param:1.1040\n",
      "         loss_test:13.98748   best_test:14.00245   best_possible:1.27808  Percentage::10.956\n",
      "epoch 2120  anneal_param:1.1051\n",
      "         loss_test:13.99506   best_test:14.00245   best_possible:1.27808  Percentage::10.956\n",
      "epoch 2130  anneal_param:1.1062\n",
      "         loss_test:13.99689   best_test:14.00245   best_possible:1.27808  Percentage::10.956\n",
      "epoch 2140  anneal_param:1.1073\n",
      "         loss_test:13.99650   best_test:14.00245   best_possible:1.27808  Percentage::10.956\n",
      "epoch 2150  anneal_param:1.1084\n",
      "         loss_test:14.00209   best_test:14.00245   best_possible:1.27808  Percentage::10.956\n",
      "✅ Model saved at epoch 2160, Loss: -14.00641\n",
      "epoch 2160  anneal_param:1.1084\n",
      "         loss_test:14.00641   best_test:14.00641   best_possible:1.27808  Percentage::10.959\n",
      "epoch 2170  anneal_param:1.1095\n",
      "         loss_test:14.00140   best_test:14.00641   best_possible:1.27808  Percentage::10.959\n",
      "✅ Model saved at epoch 2180, Loss: -14.01595\n",
      "epoch 2180  anneal_param:1.1095\n",
      "         loss_test:14.01595   best_test:14.01595   best_possible:1.27808  Percentage::10.966\n",
      "epoch 2190  anneal_param:1.1107\n",
      "         loss_test:14.00876   best_test:14.01595   best_possible:1.27808  Percentage::10.966\n",
      "epoch 2200  anneal_param:1.1118\n",
      "         loss_test:14.01500   best_test:14.01595   best_possible:1.27808  Percentage::10.966\n",
      "epoch 2210  anneal_param:1.1129\n",
      "         loss_test:13.99831   best_test:14.01595   best_possible:1.27808  Percentage::10.966\n",
      "epoch 2220  anneal_param:1.1140\n",
      "         loss_test:14.00369   best_test:14.01595   best_possible:1.27808  Percentage::10.966\n",
      "epoch 2230  anneal_param:1.1151\n",
      "         loss_test:14.00198   best_test:14.01595   best_possible:1.27808  Percentage::10.966\n",
      "epoch 2240  anneal_param:1.1162\n",
      "         loss_test:14.01411   best_test:14.01595   best_possible:1.27808  Percentage::10.966\n",
      "epoch 2250  anneal_param:1.1173\n",
      "         loss_test:14.01120   best_test:14.01595   best_possible:1.27808  Percentage::10.966\n",
      "epoch 2260  anneal_param:1.1185\n",
      "         loss_test:14.01329   best_test:14.01595   best_possible:1.27808  Percentage::10.966\n",
      "✅ Model saved at epoch 2270, Loss: -14.01728\n",
      "epoch 2270  anneal_param:1.1185\n",
      "         loss_test:14.01728   best_test:14.01728   best_possible:1.27808  Percentage::10.967\n",
      "✅ Model saved at epoch 2280, Loss: -14.02594\n",
      "epoch 2280  anneal_param:1.1185\n",
      "         loss_test:14.02594   best_test:14.02594   best_possible:1.27808  Percentage::10.974\n",
      "epoch 2290  anneal_param:1.1196\n",
      "         loss_test:14.02166   best_test:14.02594   best_possible:1.27808  Percentage::10.974\n",
      "epoch 2300  anneal_param:1.1207\n",
      "         loss_test:14.01707   best_test:14.02594   best_possible:1.27808  Percentage::10.974\n",
      "✅ Model saved at epoch 2310, Loss: -14.02740\n",
      "epoch 2310  anneal_param:1.1207\n",
      "         loss_test:14.02740   best_test:14.02740   best_possible:1.27808  Percentage::10.975\n",
      "epoch 2320  anneal_param:1.1218\n",
      "         loss_test:14.01355   best_test:14.02740   best_possible:1.27808  Percentage::10.975\n",
      "epoch 2330  anneal_param:1.1229\n",
      "         loss_test:14.00868   best_test:14.02740   best_possible:1.27808  Percentage::10.975\n",
      "epoch 2340  anneal_param:1.1241\n",
      "         loss_test:14.02600   best_test:14.02740   best_possible:1.27808  Percentage::10.975\n",
      "epoch 2350  anneal_param:1.1252\n",
      "         loss_test:14.02631   best_test:14.02740   best_possible:1.27808  Percentage::10.975\n",
      "✅ Model saved at epoch 2360, Loss: -14.03253\n",
      "epoch 2360  anneal_param:1.1252\n",
      "         loss_test:14.03253   best_test:14.03253   best_possible:1.27808  Percentage::10.979\n",
      "✅ Model saved at epoch 2370, Loss: -14.03982\n",
      "epoch 2370  anneal_param:1.1252\n",
      "         loss_test:14.03982   best_test:14.03982   best_possible:1.27808  Percentage::10.985\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[480], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m h_batch, hR_batch, hI_batch \u001b[38;5;241m=\u001b[39m generate_batch_data(batch_size,M,K,Lp,LSF_UE,Mainlobe_UE,HalfBW_UE)\n\u001b[0;32m     13\u001b[0m y_pilot \u001b[38;5;241m=\u001b[39m pilot_train(hR_batch, hI_batch, K, M, L) \u001b[38;5;66;03m# K user의 파일럿 수신 신호 리스트\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m UE_Feedback \u001b[38;5;241m=\u001b[39m \u001b[43mue_dnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pilot\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m rate, rate_UP \u001b[38;5;241m=\u001b[39m bs_dnn(UE_Feedback, hR_batch, hI_batch, noise_std_temp)\n\u001b[0;32m     16\u001b[0m loss, loss_UP \u001b[38;5;241m=\u001b[39m Lossfunc(rate, rate_UP)\n",
      "File \u001b[1;32mc:\\Users\\unist\\anaconda3\\envs\\acnl\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\unist\\anaconda3\\envs\\acnl\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[467], line 29\u001b[0m, in \u001b[0;36mUE_DNN.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     27\u001b[0m InfoBits \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m0\u001b[39m}\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m kk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mK):\n\u001b[1;32m---> 29\u001b[0m     InfoBits_linear \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# 신경망을 통과한 값\u001b[39;00m\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;66;03m# Straight-Through Estimator (STE) 적용\u001b[39;00m\n\u001b[0;32m     32\u001b[0m     InfoBits_tanh \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtanh(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39manneal \u001b[38;5;241m*\u001b[39m InfoBits_linear)\n",
      "File \u001b[1;32mc:\\Users\\unist\\anaconda3\\envs\\acnl\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\unist\\anaconda3\\envs\\acnl\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\unist\\anaconda3\\envs\\acnl\\Lib\\site-packages\\torch\\nn\\modules\\container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\unist\\anaconda3\\envs\\acnl\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\unist\\anaconda3\\envs\\acnl\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\unist\\anaconda3\\envs\\acnl\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    186\u001b[0m     bn_training \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_mean \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_var \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    188\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;124;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[0;32m    190\u001b[0m \u001b[38;5;124;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;124;03mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[0;32m    192\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 193\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    195\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[0;32m    196\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_mean\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_var\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbn_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    203\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexponential_average_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    204\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    205\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\unist\\anaconda3\\envs\\acnl\\Lib\\site-packages\\torch\\nn\\functional.py:2812\u001b[0m, in \u001b[0;36mbatch_norm\u001b[1;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[0;32m   2809\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m training:\n\u001b[0;32m   2810\u001b[0m     _verify_batch_size(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize())\n\u001b[1;32m-> 2812\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2813\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2814\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2815\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2816\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrunning_mean\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2817\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrunning_var\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2818\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2819\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2820\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2821\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcudnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menabled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2822\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## Loop\n",
    "for epoch in range(n_epochs):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    for _ in range(batch_per_epoch):\n",
    "        \n",
    "        snr_temp = torch.FloatTensor(1).uniform_(snr_min_train, snr_max_train)\n",
    "        noise_std_temp = torch.sqrt(0.5 * P / (10 ** (snr_temp / 10)))\n",
    "        \n",
    "        # tarin dataset 생성\n",
    "        h_batch, hR_batch, hI_batch = generate_batch_data(batch_size,M,K,Lp,LSF_UE,Mainlobe_UE,HalfBW_UE)\n",
    "        \n",
    "        y_pilot = pilot_train(hR_batch, hI_batch, K, M, L) # K user의 파일럿 수신 신호 리스트\n",
    "        UE_Feedback = ue_dnn(y_pilot)\n",
    "        rate, rate_UP = bs_dnn(UE_Feedback, hR_batch, hI_batch, noise_std_temp)\n",
    "        loss, loss_UP = Lossfunc(rate, rate_UP)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    if epoch%10==0:\n",
    "        y_pilot = pilot_train(hR_test, hI_test, K, M, L)\n",
    "        rate, rate_UP = bs_dnn(ue_dnn(y_pilot), hR_test, hI_test, noise_std_temp)\n",
    "        loss_test, loss_UP_test = Lossfunc(rate, rate_UP)\n",
    "        \n",
    "        if loss_test < best_loss:\n",
    "            best_loss = loss_test\n",
    "            \n",
    "            torch.save({\n",
    "                'pilot_train' : pilot_train.state_dict(),\n",
    "                'bs_dnn' : bs_dnn.state_dict(),\n",
    "                'ue_dnn' : ue_dnn.state_dict(),\n",
    "                'optimizer' : optimizer.state_dict(),\n",
    "                'best_loss' : best_loss\n",
    "            }, save_path)\n",
    "            \n",
    "            print(f\"✅ Model saved at epoch {epoch}, Loss: {best_loss:.5f}\")\n",
    "        else:\n",
    "            anneal_param = anneal_param*annealing_rate\n",
    "        print('epoch',epoch,' anneal_param:%4.4f'%anneal_param)\n",
    "        print('         loss_test:%2.5f'%-loss_test,'  best_test:%2.5f'%-best_loss,'  best_possible:%2.5f'%-loss_UP_test,\\\n",
    "                        ' Percentage::%1.3f'%(best_loss/loss_UP_test))\n",
    "        \n",
    "y_pilot = pilot_train(hR_test_Final, hI_test_Final, K, M, L)\n",
    "rate, rate_UP = bs_dnn(ue_dnn(y_pilot), hR_test_Final, hI_test_Final, noise_std_temp)\n",
    "loss_test_Final, loss_UP_test_Final = Lossfunc(rate, rate_UP)\n",
    "\n",
    "print(loss_test_Final/loss_UP_test_Final)    \n",
    "print(-loss_UP_test_Final)\n",
    "sio.savemat('Data_K2M64Lp2L8_resultB30.mat',dict(loss_test_Final_B30=loss_test_Final.to('cpu'),\\\n",
    "                                        loss_UP_test_Final=loss_UP_test_Final.to('cpu')))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_pilot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.3705, -0.2549,  0.1679,  ..., -0.3743, -0.1163,  0.0321],\n",
      "        [ 0.2722,  0.0618,  0.0117,  ..., -0.0148, -0.0339,  0.7882],\n",
      "        [ 0.2554, -0.0811, -0.0335,  ..., -0.0116,  0.1086, -0.0784],\n",
      "        ...,\n",
      "        [-0.1375, -1.3135, -0.1369,  ...,  0.3758, -0.0178,  0.3231],\n",
      "        [-0.1273, -0.7651,  0.6741,  ...,  0.0849,  0.4323,  0.2293],\n",
      "        [ 0.4104, -0.0453, -0.0227,  ...,  0.2508,  0.1226,  3.4819]],\n",
      "       grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(y_pilot[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1024, 16])\n"
     ]
    }
   ],
   "source": [
    "print((y_pilot[0].size()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1024, 64, 2)\n"
     ]
    }
   ],
   "source": [
    "print(hR_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: tensor([[-1., -1., -1.,  ..., -1.,  1.,  1.],\n",
      "        [ 1.,  1.,  1.,  ..., -1.,  1., -1.],\n",
      "        [-1.,  1., -1.,  ..., -1., -1., -1.],\n",
      "        ...,\n",
      "        [-1., -1.,  1.,  ...,  1.,  1., -1.],\n",
      "        [-1., -1., -1.,  ...,  1.,  1., -1.],\n",
      "        [-1.,  1.,  1.,  ..., -1., -1., -1.]], grad_fn=<AddBackward0>), 1: tensor([[ 1.,  1., -1.,  ..., -1.,  1.,  1.],\n",
      "        [ 1., -1.,  1.,  ...,  1., -1., -1.],\n",
      "        [-1., -1., -1.,  ..., -1., -1.,  1.],\n",
      "        ...,\n",
      "        [-1.,  1., -1.,  ..., -1., -1.,  1.],\n",
      "        [-1.,  1., -1.,  ...,  1.,  1., -1.],\n",
      "        [-1., -1., -1.,  ...,  1.,  1., -1.]], grad_fn=<AddBackward0>)}\n"
     ]
    }
   ],
   "source": [
    "print(UE_Feedback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1024, 30])\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "print(UE_Feedback[0].size())\n",
    "print(type(UE_Feedback[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[478], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43msio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msavemat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mData_K2M64Lp2L8_resultB30.mat\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mloss_test_Final_B30\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_test_Final\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mloss_UP_test_Final\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_UP_test_Final\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m  \n",
      "File \u001b[1;32mc:\\Users\\unist\\anaconda3\\envs\\acnl\\Lib\\site-packages\\scipy\\io\\matlab\\_mio.py:314\u001b[0m, in \u001b[0;36msavemat\u001b[1;34m(file_name, mdict, appendmat, format, long_field_names, do_compression, oned_as)\u001b[0m\n\u001b[0;32m    312\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    313\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFormat should be \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m4\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m5\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 314\u001b[0m \u001b[43mMW\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mput_variables\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmdict\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\unist\\anaconda3\\envs\\acnl\\Lib\\site-packages\\scipy\\io\\matlab\\_mio5.py:895\u001b[0m, in \u001b[0;36mMatFile5Writer.put_variables\u001b[1;34m(self, mdict, write_header)\u001b[0m\n\u001b[0;32m    893\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_stream\u001b[38;5;241m.\u001b[39mwrite(out_str)\n\u001b[0;32m    894\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# not compressing\u001b[39;00m\n\u001b[1;32m--> 895\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_matrix_writer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_top\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlatin1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_global\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\unist\\anaconda3\\envs\\acnl\\Lib\\site-packages\\scipy\\io\\matlab\\_mio5.py:637\u001b[0m, in \u001b[0;36mVarWriter5.write_top\u001b[1;34m(self, arr, name, is_global)\u001b[0m\n\u001b[0;32m    635\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_var_name \u001b[38;5;241m=\u001b[39m name\n\u001b[0;32m    636\u001b[0m \u001b[38;5;66;03m# write the header and data\u001b[39;00m\n\u001b[1;32m--> 637\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\unist\\anaconda3\\envs\\acnl\\Lib\\site-packages\\scipy\\io\\matlab\\_mio5.py:655\u001b[0m, in \u001b[0;36mVarWriter5.write\u001b[1;34m(self, arr)\u001b[0m\n\u001b[0;32m    653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    654\u001b[0m \u001b[38;5;66;03m# Try to convert things that aren't arrays\u001b[39;00m\n\u001b[1;32m--> 655\u001b[0m narr \u001b[38;5;241m=\u001b[39m \u001b[43mto_writeable\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    656\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m narr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    657\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCould not convert \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(arr)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) to array\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\unist\\anaconda3\\envs\\acnl\\Lib\\site-packages\\scipy\\io\\matlab\\_mio5.py:469\u001b[0m, in \u001b[0;36mto_writeable\u001b[1;34m(source)\u001b[0m\n\u001b[0;32m    467\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    468\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(source, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__array__\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 469\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    470\u001b[0m \u001b[38;5;66;03m# Objects that implement mappings\u001b[39;00m\n\u001b[0;32m    471\u001b[0m is_mapping \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mhasattr\u001b[39m(source, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeys\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(source, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    472\u001b[0m               \u001b[38;5;28mhasattr\u001b[39m(source, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mitems\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\unist\\anaconda3\\envs\\acnl\\Lib\\site-packages\\torch\\_tensor.py:1149\u001b[0m, in \u001b[0;36mTensor.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   1147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[38;5;241m.\u001b[39m__array__, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m   1148\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1149\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1150\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead."
     ]
    }
   ],
   "source": [
    "sio.savemat('Data_K2M64Lp2L8_resultB30.mat',dict(loss_test_Final_B30=loss_test_Final.to('cpu'),\\\n",
    "                                        loss_UP_test_Final=loss_UP_test_Final.to('cpu')))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "acnl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
